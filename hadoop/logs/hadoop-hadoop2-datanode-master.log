2019-01-08 19:57:44,367 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = master/132.72.109.20
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.9.1
STARTUP_MSG:   classpath = /usr/local/hadoop/etc/hadoop:/usr/local/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-lang-2.6.jar:/usr/local/hadoop/share/hadoop/common/lib/json-smart-1.3.1.jar:/usr/local/hadoop/share/hadoop/common/lib/curator-framework-2.7.1.jar:/usr/local/hadoop/share/hadoop/common/lib/gson-2.2.4.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-net-3.1.jar:/usr/local/hadoop/share/hadoop/common/lib/jetty-sslengine-6.1.26.jar:/usr/local/hadoop/share/hadoop/common/lib/jcip-annotations-1.0-1.jar:/usr/local/hadoop/share/hadoop/common/lib/activation-1.1.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-configuration-1.6.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-digester-1.8.jar:/usr/local/hadoop/share/hadoop/common/lib/xmlenc-0.52.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/usr/local/hadoop/share/hadoop/common/lib/stax-api-1.0-2.jar:/usr/local/hadoop/share/hadoop/common/lib/woodstox-core-5.0.3.jar:/usr/local/hadoop/share/hadoop/common/lib/slf4j-api-1.7.25.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-collections-3.2.2.jar:/usr/local/hadoop/share/hadoop/common/lib/jsch-0.1.54.jar:/usr/local/hadoop/share/hadoop/common/lib/avro-1.7.7.jar:/usr/local/hadoop/share/hadoop/common/lib/netty-3.6.2.Final.jar:/usr/local/hadoop/share/hadoop/common/lib/hadoop-annotations-2.9.1.jar:/usr/local/hadoop/share/hadoop/common/lib/stax2-api-3.1.4.jar:/usr/local/hadoop/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/usr/local/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/usr/local/hadoop/share/hadoop/common/lib/jersey-core-1.9.jar:/usr/local/hadoop/share/hadoop/common/lib/httpcore-4.4.4.jar:/usr/local/hadoop/share/hadoop/common/lib/junit-4.11.jar:/usr/local/hadoop/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/usr/local/hadoop/share/hadoop/common/lib/zookeeper-3.4.6.jar:/usr/local/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-io-2.4.jar:/usr/local/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.25.jar:/usr/local/hadoop/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/local/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/usr/local/hadoop/share/hadoop/common/lib/mockito-all-1.8.5.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-codec-1.4.jar:/usr/local/hadoop/share/hadoop/common/lib/xz-1.0.jar:/usr/local/hadoop/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/usr/local/hadoop/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/usr/local/hadoop/share/hadoop/common/lib/asm-3.2.jar:/usr/local/hadoop/share/hadoop/common/lib/nimbus-jose-jwt-4.41.1.jar:/usr/local/hadoop/share/hadoop/common/lib/jsr305-3.0.0.jar:/usr/local/hadoop/share/hadoop/common/lib/snappy-java-1.0.5.jar:/usr/local/hadoop/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop/share/hadoop/common/lib/curator-client-2.7.1.jar:/usr/local/hadoop/share/hadoop/common/lib/jetty-6.1.26.jar:/usr/local/hadoop/share/hadoop/common/lib/htrace-core4-4.1.0-incubating.jar:/usr/local/hadoop/share/hadoop/common/lib/jets3t-0.9.0.jar:/usr/local/hadoop/share/hadoop/common/lib/guava-11.0.2.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/usr/local/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/usr/local/hadoop/share/hadoop/common/lib/jersey-json-1.9.jar:/usr/local/hadoop/share/hadoop/common/lib/httpclient-4.5.2.jar:/usr/local/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-lang3-3.4.jar:/usr/local/hadoop/share/hadoop/common/lib/hamcrest-core-1.3.jar:/usr/local/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/usr/local/hadoop/share/hadoop/common/lib/jetty-util-6.1.26.jar:/usr/local/hadoop/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-compress-1.4.1.jar:/usr/local/hadoop/share/hadoop/common/lib/servlet-api-2.5.jar:/usr/local/hadoop/share/hadoop/common/lib/hadoop-auth-2.9.1.jar:/usr/local/hadoop/share/hadoop/common/lib/jersey-server-1.9.jar:/usr/local/hadoop/share/hadoop/common/hadoop-common-2.9.1.jar:/usr/local/hadoop/share/hadoop/common/hadoop-common-2.9.1-tests.jar:/usr/local/hadoop/share/hadoop/common/hadoop-nfs-2.9.1.jar:/usr/local/hadoop/share/hadoop/hdfs:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/okio-1.6.0.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jackson-databind-2.7.8.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jackson-annotations-2.7.8.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-io-2.4.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/asm-3.2.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/htrace-core4-4.1.0-incubating.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jackson-core-2.7.8.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/guava-11.0.2.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/hadoop-hdfs-client-2.9.1.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/okhttp-2.7.5.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-native-client-2.9.1.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-2.9.1.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-rbf-2.9.1.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.9.1-tests.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-native-client-2.9.1-tests.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-rbf-2.9.1-tests.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-client-2.9.1.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.9.1.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-client-2.9.1-tests.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jsp-api-2.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-lang-2.6.jar:/usr/local/hadoop/share/hadoop/yarn/lib/json-smart-1.3.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/curator-framework-2.7.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/gson-2.2.4.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-cli-1.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-net-3.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jetty-sslengine-6.1.26.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jcip-annotations-1.0-1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/fst-2.50.jar:/usr/local/hadoop/share/hadoop/yarn/lib/activation-1.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/ehcache-3.3.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-configuration-1.6.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-digester-1.8.jar:/usr/local/hadoop/share/hadoop/yarn/lib/xmlenc-0.52.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-beanutils-1.7.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/json-io-2.5.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/woodstox-core-5.0.3.jar:/usr/local/hadoop/share/hadoop/yarn/lib/mssql-jdbc-6.2.1.jre7.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jsch-0.1.54.jar:/usr/local/hadoop/share/hadoop/yarn/lib/avro-1.7.7.jar:/usr/local/hadoop/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/usr/local/hadoop/share/hadoop/yarn/lib/stax2-api-3.1.4.jar:/usr/local/hadoop/share/hadoop/yarn/lib/guice-3.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/curator-recipes-2.7.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-beanutils-core-1.8.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-core-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/geronimo-jcache_1.0_spec-1.0-alpha-1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/httpcore-4.4.4.jar:/usr/local/hadoop/share/hadoop/yarn/lib/java-util-1.9.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/api-util-1.0.0-M20.jar:/usr/local/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop/share/hadoop/yarn/lib/metrics-core-3.0.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-io-2.4.jar:/usr/local/hadoop/share/hadoop/yarn/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jettison-1.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-codec-1.4.jar:/usr/local/hadoop/share/hadoop/yarn/lib/xz-1.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/api-asn1-api-1.0.0-M20.jar:/usr/local/hadoop/share/hadoop/yarn/lib/apacheds-i18n-2.0.0-M15.jar:/usr/local/hadoop/share/hadoop/yarn/lib/asm-3.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/nimbus-jose-jwt-4.41.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-client-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/snappy-java-1.0.5.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/curator-client-2.7.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jetty-6.1.26.jar:/usr/local/hadoop/share/hadoop/yarn/lib/htrace-core4-4.1.0-incubating.jar:/usr/local/hadoop/share/hadoop/yarn/lib/HikariCP-java7-2.4.12.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jets3t-0.9.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/guava-11.0.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/usr/local/hadoop/share/hadoop/yarn/lib/paranamer-2.3.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-math3-3.1.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-json-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/httpclient-4.5.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-lang3-3.4.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop/share/hadoop/yarn/lib/log4j-1.2.17.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/usr/local/hadoop/share/hadoop/yarn/lib/java-xmlbuilder-0.4.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/servlet-api-2.5.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-server-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.9.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.9.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-router-2.9.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-2.9.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.9.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.9.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-client-2.9.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-api-2.9.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.9.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.9.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.9.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-registry-2.9.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-2.9.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.9.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-2.9.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/avro-1.7.7.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/hadoop-annotations-2.9.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/guice-3.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/javax.inject-1.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/junit-4.11.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/xz-1.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/asm-3.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/snappy-java-1.0.5.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.9.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.9.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.9.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.9.1-tests.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.9.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.9.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.9.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.9.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.9.1.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://github.com/razo7/hadoop-2.9.1-OR2.git -r ef46505203318032151d4f27c5bbb6d9e7cda417; compiled by 'hadoop2' on 2019-01-08T16:41Z
STARTUP_MSG:   java = 1.8.0_181
************************************************************/
2019-01-08 19:57:44,378 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2019-01-08 19:57:45,059 INFO org.apache.hadoop.hdfs.server.datanode.checker.ThrottledAsyncChecker: Scheduling a check for [DISK]file:/usr/local/hadoop/data/hadoop-data/dn/
2019-01-08 19:57:45,329 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2019-01-08 19:57:45,434 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2019-01-08 19:57:45,434 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2019-01-08 19:57:45,443 INFO org.apache.hadoop.hdfs.server.common.Util: dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2019-01-08 19:57:45,446 INFO org.apache.hadoop.hdfs.server.datanode.BlockScanner: Initialized block scanner with targetBytesPerSec 1048576
2019-01-08 19:57:45,450 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is master
2019-01-08 19:57:45,451 INFO org.apache.hadoop.hdfs.server.common.Util: dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2019-01-08 19:57:45,451 WARN org.apache.hadoop.conf.Configuration: No unit for dfs.datanode.outliers.report.interval(1800000) assuming MILLISECONDS
2019-01-08 19:57:45,455 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2019-01-08 19:57:45,486 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened streaming server at /0.0.0.0:50010
2019-01-08 19:57:45,558 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwidth is 10485760 bytes/s
2019-01-08 19:57:45,558 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Number threads for balancing is 50
2019-01-08 19:57:45,683 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2019-01-08 19:57:45,694 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-01-08 19:57:45,716 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.datanode is not defined
2019-01-08 19:57:45,723 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-01-08 19:57:45,725 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2019-01-08 19:57:45,725 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-01-08 19:57:45,725 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-01-08 19:57:45,742 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 41735
2019-01-08 19:57:45,742 INFO org.mortbay.log: jetty-6.1.26
2019-01-08 19:57:46,065 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@localhost:41735
2019-01-08 19:57:46,391 INFO org.apache.hadoop.hdfs.server.datanode.web.DatanodeHttpServer: Listening HTTP traffic on /0.0.0.0:50075
2019-01-08 19:57:46,397 INFO org.apache.hadoop.util.JvmPauseMonitor: Starting JVM pause monitor
2019-01-08 19:57:46,720 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnUserName = hadoop2
2019-01-08 19:57:46,720 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: supergroup = supergroup
2019-01-08 19:57:46,778 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2019-01-08 19:57:46,804 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 50020
2019-01-08 19:57:46,997 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened IPC server at /0.0.0.0:50020
2019-01-08 19:57:47,010 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Refresh request received for nameservices: null
2019-01-08 19:57:47,025 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting BPOfferServices for nameservices: <default>
2019-01-08 19:57:47,064 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to master/132.72.109.20:9000 starting to offer service
2019-01-08 19:57:47,074 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2019-01-08 19:57:47,075 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2019-01-08 19:57:48,169 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 19:57:49,170 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 19:57:50,170 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 19:57:51,171 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 19:57:52,172 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 19:57:53,173 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 19:57:54,173 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 19:57:55,174 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 19:57:56,175 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 19:57:57,175 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 19:57:57,177 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: master/132.72.109.20:9000
2019-01-08 19:58:03,179 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 19:58:04,179 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 19:58:05,180 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 19:58:06,181 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 19:58:07,182 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 19:58:08,182 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 19:58:09,184 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 19:58:10,185 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 19:58:11,185 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 19:58:12,186 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 19:58:12,188 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: master/132.72.109.20:9000
2019-01-08 19:58:18,189 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 19:58:19,190 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 19:58:20,191 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 19:58:21,192 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 19:58:22,193 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 19:58:23,194 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 19:58:24,194 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 19:58:25,195 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 19:58:26,196 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 19:58:27,196 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 19:58:27,197 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: master/132.72.109.20:9000
2019-01-08 19:58:33,198 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 19:58:34,199 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 19:58:35,200 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 19:58:36,201 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 19:58:37,201 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 19:58:38,202 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 19:58:39,203 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 19:58:40,204 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 19:58:41,204 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 19:58:42,205 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 19:58:42,206 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: master/132.72.109.20:9000
2019-01-08 19:58:48,207 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 19:58:49,208 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 19:58:50,209 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 19:58:51,210 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 19:58:52,210 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 19:58:53,211 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 19:58:54,212 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 19:58:55,213 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 19:58:56,213 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 19:58:57,214 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 19:58:57,215 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: master/132.72.109.20:9000
2019-01-08 19:59:03,216 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 19:59:04,217 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 19:59:05,218 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 19:59:06,218 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 19:59:07,219 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 19:59:08,220 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 19:59:09,221 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 19:59:10,221 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 19:59:11,222 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 19:59:12,223 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 19:59:12,224 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: master/132.72.109.20:9000
2019-01-08 19:59:18,225 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 19:59:19,226 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 19:59:20,226 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 19:59:21,227 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 19:59:22,228 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 19:59:23,229 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 19:59:24,230 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 19:59:25,231 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 19:59:26,231 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 19:59:27,232 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 19:59:27,233 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: master/132.72.109.20:9000
2019-01-08 19:59:33,234 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 19:59:34,235 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 19:59:35,236 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 19:59:36,236 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 19:59:37,237 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 19:59:38,238 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 19:59:39,239 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 19:59:40,240 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 19:59:41,240 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 19:59:42,241 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 19:59:42,242 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: master/132.72.109.20:9000
2019-01-08 19:59:48,243 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 19:59:49,244 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 19:59:50,245 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 19:59:51,247 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 19:59:52,248 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 19:59:53,248 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 19:59:54,249 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 19:59:55,250 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 19:59:56,251 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 19:59:57,252 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 19:59:57,253 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: master/132.72.109.20:9000
2019-01-08 20:00:03,254 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 20:00:04,255 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 20:00:05,255 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 20:00:06,256 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 20:00:07,257 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 20:00:08,257 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 20:00:09,259 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 20:00:10,259 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 20:00:11,260 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 20:00:12,261 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 20:00:12,262 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: master/132.72.109.20:9000
2019-01-08 20:00:18,263 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 20:00:19,264 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 20:00:20,265 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 20:00:21,265 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 20:00:22,266 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 20:00:23,267 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 20:00:24,268 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 20:00:25,268 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 20:00:26,269 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 20:00:27,270 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 20:00:27,271 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: master/132.72.109.20:9000
2019-01-08 20:00:33,272 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 20:00:34,273 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 20:00:35,274 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 20:00:36,275 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 20:00:37,275 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 20:00:38,276 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 20:00:39,277 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 20:00:40,278 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 20:00:41,278 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 20:00:42,279 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 20:00:42,280 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: master/132.72.109.20:9000
2019-01-08 20:00:48,281 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 20:00:49,283 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 20:00:50,284 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 20:00:51,284 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 20:00:52,285 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 20:00:53,286 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 20:00:54,286 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 20:00:55,287 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 20:00:56,288 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 20:00:57,289 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 20:00:57,289 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: master/132.72.109.20:9000
2019-01-08 20:01:03,290 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 20:01:04,291 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 20:01:05,292 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 20:01:06,292 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 20:01:07,293 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 20:01:08,294 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 20:01:09,295 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 20:01:10,295 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 20:01:11,296 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 20:01:12,297 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 20:01:12,297 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: master/132.72.109.20:9000
2019-01-08 20:01:18,299 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 20:01:19,299 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 20:01:20,300 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 20:01:21,301 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 20:01:22,301 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 20:01:23,302 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 20:01:24,303 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 20:01:25,304 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 20:01:26,304 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 20:01:27,305 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 20:01:27,306 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: master/132.72.109.20:9000
2019-01-08 20:01:33,307 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 20:01:34,308 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 20:01:35,308 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 20:01:36,309 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 20:01:37,310 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 20:01:38,310 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 20:01:39,311 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 20:01:40,312 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 20:01:41,313 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 20:01:42,313 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 20:01:42,315 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: master/132.72.109.20:9000
2019-01-08 20:01:48,316 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 20:01:49,317 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 20:01:50,318 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 20:01:51,318 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 20:01:52,319 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 20:01:53,320 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 20:01:54,321 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 20:01:55,322 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 20:01:56,323 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 20:01:57,323 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 20:01:57,324 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: master/132.72.109.20:9000
2019-01-08 20:02:03,325 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 20:02:04,326 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 20:02:05,327 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 20:02:06,327 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 20:02:07,329 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 20:02:08,330 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 20:02:09,330 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 20:02:10,331 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 20:02:11,332 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 20:02:12,332 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 20:02:12,333 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: master/132.72.109.20:9000
2019-01-08 20:02:18,334 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 20:02:19,335 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 20:02:20,336 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 20:02:21,336 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 20:02:22,337 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 20:02:23,338 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 20:02:24,339 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 20:02:25,340 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 20:02:26,340 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 20:02:27,341 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 20:02:27,342 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: master/132.72.109.20:9000
2019-01-08 20:02:33,343 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 20:02:34,344 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 20:02:35,345 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 20:02:36,346 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 20:02:37,346 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 20:02:38,347 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 20:02:39,348 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 20:02:40,349 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 20:02:41,349 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 20:02:42,350 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 20:02:42,351 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: master/132.72.109.20:9000
2019-01-08 20:02:48,353 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 20:02:49,353 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 20:02:50,354 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 20:02:51,355 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 20:02:52,355 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 20:02:53,356 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 20:02:54,357 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 20:02:55,358 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 20:02:56,358 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 20:02:57,359 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 20:02:57,360 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: master/132.72.109.20:9000
2019-01-08 20:03:03,362 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 20:03:04,362 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 20:03:05,363 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 20:03:06,364 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 20:03:07,364 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 20:03:08,365 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 20:03:09,366 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 20:03:10,366 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 20:03:11,367 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 20:03:12,368 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 20:03:12,369 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: master/132.72.109.20:9000
2019-01-08 20:03:18,370 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 20:03:19,370 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 20:03:20,371 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 20:03:21,372 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 20:03:22,372 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 20:03:23,373 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 20:03:24,374 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 20:03:25,374 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 20:03:26,375 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 20:03:27,377 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 20:03:27,378 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: master/132.72.109.20:9000
2019-01-08 20:03:33,379 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 20:03:34,380 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 20:03:35,381 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 20:03:36,382 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 20:03:37,383 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 20:03:38,383 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 20:03:39,384 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 20:03:40,385 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 20:03:41,386 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 20:03:42,387 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 20:03:42,389 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: master/132.72.109.20:9000
2019-01-08 20:03:48,390 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 20:03:49,391 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 20:03:50,391 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 20:03:51,392 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 20:03:52,393 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 20:03:53,393 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 20:03:54,394 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 20:03:55,395 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 20:03:56,396 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 20:03:57,396 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 20:03:57,397 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: master/132.72.109.20:9000
2019-01-08 20:04:03,398 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 20:04:04,399 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 20:04:05,400 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 20:04:06,400 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 20:04:07,401 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 20:04:08,402 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 20:04:09,402 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 20:04:10,403 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 20:04:11,404 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 20:04:12,405 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 20:04:12,405 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: master/132.72.109.20:9000
2019-01-08 20:04:18,407 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 20:04:19,407 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 20:04:20,408 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 20:04:21,409 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 20:04:22,409 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 20:04:23,410 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 20:04:24,411 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 20:04:25,411 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 20:04:26,412 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 20:04:27,413 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 20:04:27,413 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: master/132.72.109.20:9000
2019-01-08 20:04:33,415 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 20:04:34,415 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 20:04:35,416 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 20:04:36,417 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 20:04:37,417 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 20:04:38,418 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 20:04:39,419 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 20:04:40,420 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 20:04:41,420 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 20:04:42,421 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 20:04:42,422 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: master/132.72.109.20:9000
2019-01-08 20:04:48,423 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 20:04:49,424 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 20:04:50,424 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 20:04:51,425 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 20:04:52,426 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 20:04:53,426 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 20:04:54,427 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 20:04:55,428 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 20:04:56,428 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 20:04:57,429 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 20:04:57,430 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: master/132.72.109.20:9000
2019-01-08 20:05:03,431 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 20:05:04,432 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 20:05:05,432 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 20:05:06,433 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 20:05:07,434 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 20:05:08,434 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 20:05:09,435 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 20:05:10,436 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 20:05:11,437 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 20:05:12,438 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 20:05:12,439 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: master/132.72.109.20:9000
2019-01-08 20:05:18,439 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 20:05:19,440 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 20:05:20,441 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 20:05:21,442 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 20:05:22,443 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 20:05:23,443 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 20:05:24,444 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 20:05:25,445 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 20:05:26,446 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 20:05:27,446 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 20:05:27,447 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: master/132.72.109.20:9000
2019-01-08 20:05:33,449 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 20:05:34,450 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 20:05:35,451 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 20:05:36,451 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 20:05:37,452 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 20:05:38,453 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 20:05:39,454 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 20:05:40,455 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: master/132.72.109.20:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-01-08 20:05:40,818 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to master/132.72.109.20:9000
2019-01-08 20:05:40,825 INFO org.apache.hadoop.hdfs.server.common.Storage: Using 1 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=1, dataDirs=1)
2019-01-08 20:05:40,829 WARN org.apache.hadoop.hdfs.server.common.Storage: Storage directory /usr/local/hadoop/data/hadoop-data/dn does not exist
2019-01-08 20:05:40,829 INFO org.apache.hadoop.hdfs.server.common.Storage: Storage directory /usr/local/hadoop/data/hadoop-data/dn does not exist
2019-01-08 20:05:40,830 WARN org.apache.hadoop.hdfs.server.common.Storage: Failed to add storage directory [DISK]file:/usr/local/hadoop/data/hadoop-data/dn
java.io.IOException: Storage directory /usr/local/hadoop/data/hadoop-data/dn does not exist
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.loadStorageDirectory(DataStorage.java:277)
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.loadDataStorage(DataStorage.java:409)
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.addStorageLocations(DataStorage.java:388)
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.recoverTransitionRead(DataStorage.java:556)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.initStorage(DataNode.java:1649)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.initBlockPool(DataNode.java:1610)
	at org.apache.hadoop.hdfs.server.datanode.BPOfferService.verifyAndSetNamespaceInfo(BPOfferService.java:388)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.connectToNNAndHandshake(BPServiceActor.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:816)
	at java.lang.Thread.run(Thread.java:748)
2019-01-08 20:05:40,838 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: Initialization failed for Block pool <registering> (Datanode Uuid unassigned) service to master/132.72.109.20:9000. Exiting. 
java.io.IOException: All specified directories have failed to load.
	at org.apache.hadoop.hdfs.server.datanode.DataStorage.recoverTransitionRead(DataStorage.java:557)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.initStorage(DataNode.java:1649)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.initBlockPool(DataNode.java:1610)
	at org.apache.hadoop.hdfs.server.datanode.BPOfferService.verifyAndSetNamespaceInfo(BPOfferService.java:388)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.connectToNNAndHandshake(BPServiceActor.java:280)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:816)
	at java.lang.Thread.run(Thread.java:748)
2019-01-08 20:05:40,838 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Ending block pool service for: Block pool <registering> (Datanode Uuid unassigned) service to master/132.72.109.20:9000
2019-01-08 20:05:40,841 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Removed Block pool <registering> (Datanode Uuid unassigned)
2019-01-08 20:05:42,841 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Exiting Datanode
2019-01-08 20:05:42,845 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at master/132.72.109.20
************************************************************/
2019-01-08 20:07:46,631 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = master/132.72.109.20
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.9.1
STARTUP_MSG:   classpath = /usr/local/hadoop/etc/hadoop:/usr/local/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-lang-2.6.jar:/usr/local/hadoop/share/hadoop/common/lib/json-smart-1.3.1.jar:/usr/local/hadoop/share/hadoop/common/lib/curator-framework-2.7.1.jar:/usr/local/hadoop/share/hadoop/common/lib/gson-2.2.4.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-net-3.1.jar:/usr/local/hadoop/share/hadoop/common/lib/jetty-sslengine-6.1.26.jar:/usr/local/hadoop/share/hadoop/common/lib/jcip-annotations-1.0-1.jar:/usr/local/hadoop/share/hadoop/common/lib/activation-1.1.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-configuration-1.6.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-digester-1.8.jar:/usr/local/hadoop/share/hadoop/common/lib/xmlenc-0.52.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/usr/local/hadoop/share/hadoop/common/lib/stax-api-1.0-2.jar:/usr/local/hadoop/share/hadoop/common/lib/woodstox-core-5.0.3.jar:/usr/local/hadoop/share/hadoop/common/lib/slf4j-api-1.7.25.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-collections-3.2.2.jar:/usr/local/hadoop/share/hadoop/common/lib/jsch-0.1.54.jar:/usr/local/hadoop/share/hadoop/common/lib/avro-1.7.7.jar:/usr/local/hadoop/share/hadoop/common/lib/netty-3.6.2.Final.jar:/usr/local/hadoop/share/hadoop/common/lib/hadoop-annotations-2.9.1.jar:/usr/local/hadoop/share/hadoop/common/lib/stax2-api-3.1.4.jar:/usr/local/hadoop/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/usr/local/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/usr/local/hadoop/share/hadoop/common/lib/jersey-core-1.9.jar:/usr/local/hadoop/share/hadoop/common/lib/httpcore-4.4.4.jar:/usr/local/hadoop/share/hadoop/common/lib/junit-4.11.jar:/usr/local/hadoop/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/usr/local/hadoop/share/hadoop/common/lib/zookeeper-3.4.6.jar:/usr/local/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-io-2.4.jar:/usr/local/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.25.jar:/usr/local/hadoop/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/local/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/usr/local/hadoop/share/hadoop/common/lib/mockito-all-1.8.5.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-codec-1.4.jar:/usr/local/hadoop/share/hadoop/common/lib/xz-1.0.jar:/usr/local/hadoop/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/usr/local/hadoop/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/usr/local/hadoop/share/hadoop/common/lib/asm-3.2.jar:/usr/local/hadoop/share/hadoop/common/lib/nimbus-jose-jwt-4.41.1.jar:/usr/local/hadoop/share/hadoop/common/lib/jsr305-3.0.0.jar:/usr/local/hadoop/share/hadoop/common/lib/snappy-java-1.0.5.jar:/usr/local/hadoop/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop/share/hadoop/common/lib/curator-client-2.7.1.jar:/usr/local/hadoop/share/hadoop/common/lib/jetty-6.1.26.jar:/usr/local/hadoop/share/hadoop/common/lib/htrace-core4-4.1.0-incubating.jar:/usr/local/hadoop/share/hadoop/common/lib/jets3t-0.9.0.jar:/usr/local/hadoop/share/hadoop/common/lib/guava-11.0.2.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/usr/local/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/usr/local/hadoop/share/hadoop/common/lib/jersey-json-1.9.jar:/usr/local/hadoop/share/hadoop/common/lib/httpclient-4.5.2.jar:/usr/local/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-lang3-3.4.jar:/usr/local/hadoop/share/hadoop/common/lib/hamcrest-core-1.3.jar:/usr/local/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/usr/local/hadoop/share/hadoop/common/lib/jetty-util-6.1.26.jar:/usr/local/hadoop/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-compress-1.4.1.jar:/usr/local/hadoop/share/hadoop/common/lib/servlet-api-2.5.jar:/usr/local/hadoop/share/hadoop/common/lib/hadoop-auth-2.9.1.jar:/usr/local/hadoop/share/hadoop/common/lib/jersey-server-1.9.jar:/usr/local/hadoop/share/hadoop/common/hadoop-common-2.9.1.jar:/usr/local/hadoop/share/hadoop/common/hadoop-common-2.9.1-tests.jar:/usr/local/hadoop/share/hadoop/common/hadoop-nfs-2.9.1.jar:/usr/local/hadoop/share/hadoop/hdfs:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/okio-1.6.0.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jackson-databind-2.7.8.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jackson-annotations-2.7.8.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-io-2.4.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/asm-3.2.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/htrace-core4-4.1.0-incubating.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jackson-core-2.7.8.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/guava-11.0.2.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/hadoop-hdfs-client-2.9.1.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/okhttp-2.7.5.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-native-client-2.9.1.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-2.9.1.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-rbf-2.9.1.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.9.1-tests.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-native-client-2.9.1-tests.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-rbf-2.9.1-tests.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-client-2.9.1.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.9.1.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-client-2.9.1-tests.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jsp-api-2.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-lang-2.6.jar:/usr/local/hadoop/share/hadoop/yarn/lib/json-smart-1.3.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/curator-framework-2.7.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/gson-2.2.4.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-cli-1.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-net-3.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jetty-sslengine-6.1.26.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jcip-annotations-1.0-1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/fst-2.50.jar:/usr/local/hadoop/share/hadoop/yarn/lib/activation-1.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/ehcache-3.3.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-configuration-1.6.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-digester-1.8.jar:/usr/local/hadoop/share/hadoop/yarn/lib/xmlenc-0.52.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-beanutils-1.7.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/json-io-2.5.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/woodstox-core-5.0.3.jar:/usr/local/hadoop/share/hadoop/yarn/lib/mssql-jdbc-6.2.1.jre7.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jsch-0.1.54.jar:/usr/local/hadoop/share/hadoop/yarn/lib/avro-1.7.7.jar:/usr/local/hadoop/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/usr/local/hadoop/share/hadoop/yarn/lib/stax2-api-3.1.4.jar:/usr/local/hadoop/share/hadoop/yarn/lib/guice-3.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/curator-recipes-2.7.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-beanutils-core-1.8.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-core-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/geronimo-jcache_1.0_spec-1.0-alpha-1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/httpcore-4.4.4.jar:/usr/local/hadoop/share/hadoop/yarn/lib/java-util-1.9.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/api-util-1.0.0-M20.jar:/usr/local/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop/share/hadoop/yarn/lib/metrics-core-3.0.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-io-2.4.jar:/usr/local/hadoop/share/hadoop/yarn/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jettison-1.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-codec-1.4.jar:/usr/local/hadoop/share/hadoop/yarn/lib/xz-1.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/api-asn1-api-1.0.0-M20.jar:/usr/local/hadoop/share/hadoop/yarn/lib/apacheds-i18n-2.0.0-M15.jar:/usr/local/hadoop/share/hadoop/yarn/lib/asm-3.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/nimbus-jose-jwt-4.41.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-client-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/snappy-java-1.0.5.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/curator-client-2.7.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jetty-6.1.26.jar:/usr/local/hadoop/share/hadoop/yarn/lib/htrace-core4-4.1.0-incubating.jar:/usr/local/hadoop/share/hadoop/yarn/lib/HikariCP-java7-2.4.12.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jets3t-0.9.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/guava-11.0.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/usr/local/hadoop/share/hadoop/yarn/lib/paranamer-2.3.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-math3-3.1.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-json-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/httpclient-4.5.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-lang3-3.4.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop/share/hadoop/yarn/lib/log4j-1.2.17.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/usr/local/hadoop/share/hadoop/yarn/lib/java-xmlbuilder-0.4.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/servlet-api-2.5.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-server-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.9.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.9.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-router-2.9.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-2.9.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.9.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.9.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-client-2.9.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-api-2.9.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.9.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.9.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.9.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-registry-2.9.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-2.9.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.9.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-2.9.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/avro-1.7.7.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/hadoop-annotations-2.9.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/guice-3.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/javax.inject-1.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/junit-4.11.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/xz-1.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/asm-3.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/snappy-java-1.0.5.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.9.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.9.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.9.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.9.1-tests.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.9.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.9.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.9.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.9.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.9.1.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://github.com/razo7/hadoop-2.9.1-OR2.git -r ef46505203318032151d4f27c5bbb6d9e7cda417; compiled by 'hadoop2' on 2019-01-08T16:41Z
STARTUP_MSG:   java = 1.8.0_181
************************************************************/
2019-01-08 20:07:46,643 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2019-01-08 20:07:47,287 INFO org.apache.hadoop.hdfs.server.datanode.checker.ThrottledAsyncChecker: Scheduling a check for [DISK]file:/usr/local/hadoop/data/hadoop-data/dn
2019-01-08 20:07:47,435 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2019-01-08 20:07:47,526 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2019-01-08 20:07:47,526 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2019-01-08 20:07:47,535 INFO org.apache.hadoop.hdfs.server.common.Util: dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2019-01-08 20:07:47,538 INFO org.apache.hadoop.hdfs.server.datanode.BlockScanner: Initialized block scanner with targetBytesPerSec 1048576
2019-01-08 20:07:47,542 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is master
2019-01-08 20:07:47,542 INFO org.apache.hadoop.hdfs.server.common.Util: dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2019-01-08 20:07:47,542 WARN org.apache.hadoop.conf.Configuration: No unit for dfs.datanode.outliers.report.interval(1800000) assuming MILLISECONDS
2019-01-08 20:07:47,546 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2019-01-08 20:07:47,578 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened streaming server at /0.0.0.0:50010
2019-01-08 20:07:47,580 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwidth is 10485760 bytes/s
2019-01-08 20:07:47,580 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Number threads for balancing is 50
2019-01-08 20:07:47,697 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2019-01-08 20:07:47,707 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-01-08 20:07:47,723 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.datanode is not defined
2019-01-08 20:07:47,729 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-01-08 20:07:47,731 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2019-01-08 20:07:47,731 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-01-08 20:07:47,731 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-01-08 20:07:47,749 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 45423
2019-01-08 20:07:47,749 INFO org.mortbay.log: jetty-6.1.26
2019-01-08 20:07:48,033 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@localhost:45423
2019-01-08 20:07:48,158 INFO org.apache.hadoop.hdfs.server.datanode.web.DatanodeHttpServer: Listening HTTP traffic on /0.0.0.0:50075
2019-01-08 20:07:48,164 INFO org.apache.hadoop.util.JvmPauseMonitor: Starting JVM pause monitor
2019-01-08 20:07:48,477 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnUserName = hadoop2
2019-01-08 20:07:48,477 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: supergroup = supergroup
2019-01-08 20:07:48,525 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2019-01-08 20:07:48,541 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 50020
2019-01-08 20:07:48,612 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened IPC server at /0.0.0.0:50020
2019-01-08 20:07:48,626 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Refresh request received for nameservices: null
2019-01-08 20:07:48,640 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting BPOfferServices for nameservices: <default>
2019-01-08 20:07:48,653 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to master/132.72.109.20:9000 starting to offer service
2019-01-08 20:07:48,669 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2019-01-08 20:07:48,670 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2019-01-08 20:07:48,811 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to master/132.72.109.20:9000
2019-01-08 20:07:48,814 INFO org.apache.hadoop.hdfs.server.common.Storage: Using 1 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=1, dataDirs=1)
2019-01-08 20:07:48,853 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /usr/local/hadoop/data/hadoop-data/dn/in_use.lock acquired by nodename 2664@master
2019-01-08 20:07:48,854 INFO org.apache.hadoop.hdfs.server.common.Storage: Storage directory /usr/local/hadoop/data/hadoop-data/dn is not formatted for namespace 225363434. Formatting...
2019-01-08 20:07:48,855 INFO org.apache.hadoop.hdfs.server.common.Storage: Generated new storageID DS-bc012d25-5f83-4272-9ceb-fcbd8886bd57 for directory /usr/local/hadoop/data/hadoop-data/dn
2019-01-08 20:07:48,947 INFO org.apache.hadoop.hdfs.server.common.Storage: Analyzing storage directories for bpid BP-1717489377-132.72.109.20-1546970734525
2019-01-08 20:07:48,947 INFO org.apache.hadoop.hdfs.server.common.Storage: Locking is disabled for /usr/local/hadoop/data/hadoop-data/dn/current/BP-1717489377-132.72.109.20-1546970734525
2019-01-08 20:07:48,949 INFO org.apache.hadoop.hdfs.server.common.Storage: Block pool storage directory /usr/local/hadoop/data/hadoop-data/dn/current/BP-1717489377-132.72.109.20-1546970734525 is not formatted for BP-1717489377-132.72.109.20-1546970734525. Formatting ...
2019-01-08 20:07:48,949 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting block pool BP-1717489377-132.72.109.20-1546970734525 directory /usr/local/hadoop/data/hadoop-data/dn/current/BP-1717489377-132.72.109.20-1546970734525/current
2019-01-08 20:07:48,995 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Setting up storage: nsid=225363434;bpid=BP-1717489377-132.72.109.20-1546970734525;lv=-57;nsInfo=lv=-63;cid=CID-134fef86-d39e-4fb6-b146-de33ed769859;nsid=225363434;c=1546970734525;bpid=BP-1717489377-132.72.109.20-1546970734525;dnuuid=null
2019-01-08 20:07:49,022 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Generated and persisted new Datanode UUID 26e32cb0-cb1e-4297-9ba9-d8e02973be0c
2019-01-08 20:07:49,079 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added new volume: DS-bc012d25-5f83-4272-9ceb-fcbd8886bd57
2019-01-08 20:07:49,080 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added volume - /usr/local/hadoop/data/hadoop-data/dn/current, StorageType: DISK
2019-01-08 20:07:49,085 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Registered FSDatasetState MBean
2019-01-08 20:07:49,098 INFO org.apache.hadoop.hdfs.server.datanode.checker.ThrottledAsyncChecker: Scheduling a check for /usr/local/hadoop/data/hadoop-data/dn/current
2019-01-08 20:07:49,108 INFO org.apache.hadoop.hdfs.server.datanode.checker.DatasetVolumeChecker: Scheduled health check for volume /usr/local/hadoop/data/hadoop-data/dn/current
2019-01-08 20:07:49,110 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding block pool BP-1717489377-132.72.109.20-1546970734525
2019-01-08 20:07:49,111 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Scanning block pool BP-1717489377-132.72.109.20-1546970734525 on volume /usr/local/hadoop/data/hadoop-data/dn/current...
2019-01-08 20:07:49,143 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time taken to scan block pool BP-1717489377-132.72.109.20-1546970734525 on /usr/local/hadoop/data/hadoop-data/dn/current: 32ms
2019-01-08 20:07:49,143 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to scan all replicas for block pool BP-1717489377-132.72.109.20-1546970734525: 33ms
2019-01-08 20:07:49,148 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding replicas to map for block pool BP-1717489377-132.72.109.20-1546970734525 on volume /usr/local/hadoop/data/hadoop-data/dn/current...
2019-01-08 20:07:49,148 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.BlockPoolSlice: Replica Cache file: /usr/local/hadoop/data/hadoop-data/dn/current/BP-1717489377-132.72.109.20-1546970734525/current/replicas doesn't exist 
2019-01-08 20:07:49,148 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time to add replicas to map for block pool BP-1717489377-132.72.109.20-1546970734525 on volume /usr/local/hadoop/data/hadoop-data/dn/current: 0ms
2019-01-08 20:07:49,148 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to add all replicas to map: 1ms
2019-01-08 20:07:49,153 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: Now scanning bpid BP-1717489377-132.72.109.20-1546970734525 on volume /usr/local/hadoop/data/hadoop-data/dn
2019-01-08 20:07:49,154 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/usr/local/hadoop/data/hadoop-data/dn, DS-bc012d25-5f83-4272-9ceb-fcbd8886bd57): finished scanning block pool BP-1717489377-132.72.109.20-1546970734525
2019-01-08 20:07:49,175 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: Periodic Directory Tree Verification scan starting at 1/9/19 12:11 AM with interval of 21600000ms
2019-01-08 20:07:49,182 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool BP-1717489377-132.72.109.20-1546970734525 (Datanode Uuid 26e32cb0-cb1e-4297-9ba9-d8e02973be0c) service to master/132.72.109.20:9000 beginning handshake with NN
2019-01-08 20:07:49,207 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/usr/local/hadoop/data/hadoop-data/dn, DS-bc012d25-5f83-4272-9ceb-fcbd8886bd57): no suitable block pools found to scan.  Waiting 1814399943 ms.
2019-01-08 20:07:49,248 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool Block pool BP-1717489377-132.72.109.20-1546970734525 (Datanode Uuid 26e32cb0-cb1e-4297-9ba9-d8e02973be0c) service to master/132.72.109.20:9000 successfully registered with NN
2019-01-08 20:07:49,248 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: For namenode master/132.72.109.20:9000 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2019-01-08 20:07:49,391 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0x46d6a38a58189d9c,  containing 1 storage report(s), of which we sent 1. The reports had 0 total blocks and used 1 RPC(s). This took 5 msec to generate and 59 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2019-01-08 20:07:49,391 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-1717489377-132.72.109.20-1546970734525
2019-01-08 20:11:16,149 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1717489377-132.72.109.20-1546970734525:blk_1073741825_1001 src: /132.72.109.20:41642 dest: /132.72.109.20:50010
2019-01-08 20:11:16,363 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /132.72.109.20:41642, dest: /132.72.109.20:50010, bytes: 107851, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-758753106_1, offset: 0, srvID: 26e32cb0-cb1e-4297-9ba9-d8e02973be0c, blockid: BP-1717489377-132.72.109.20-1546970734525:blk_1073741825_1001, duration(ns): 73399906
2019-01-08 20:11:16,367 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1717489377-132.72.109.20-1546970734525:blk_1073741825_1001, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[132.72.109.41:50010] terminating
2019-01-08 20:11:18,907 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1717489377-132.72.109.20-1546970734525:blk_1073741826_1002 src: /132.72.109.20:41648 dest: /132.72.109.20:50010
2019-01-08 20:11:19,018 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /132.72.109.20:41648, dest: /132.72.109.20:50010, bytes: 1077861, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_856040948_1, offset: 0, srvID: 26e32cb0-cb1e-4297-9ba9-d8e02973be0c, blockid: BP-1717489377-132.72.109.20-1546970734525:blk_1073741826_1002, duration(ns): 106368974
2019-01-08 20:11:19,018 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1717489377-132.72.109.20-1546970734525:blk_1073741826_1002, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[132.72.109.41:50010] terminating
2019-01-08 20:11:21,609 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1717489377-132.72.109.20-1546970734525:blk_1073741827_1003 src: /132.72.109.20:41654 dest: /132.72.109.20:50010
2019-01-08 20:11:33,131 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /132.72.109.20:41654, dest: /132.72.109.20:50010, bytes: 134217728, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-174457819_1, offset: 0, srvID: 26e32cb0-cb1e-4297-9ba9-d8e02973be0c, blockid: BP-1717489377-132.72.109.20-1546970734525:blk_1073741827_1003, duration(ns): 11517202293
2019-01-08 20:11:33,131 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1717489377-132.72.109.20-1546970734525:blk_1073741827_1003, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[132.72.109.41:50010] terminating
2019-01-08 20:11:33,162 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1717489377-132.72.109.20-1546970734525:blk_1073741828_1004 src: /132.72.109.20:41660 dest: /132.72.109.20:50010
2019-01-08 20:11:44,706 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /132.72.109.20:41660, dest: /132.72.109.20:50010, bytes: 134217728, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-174457819_1, offset: 0, srvID: 26e32cb0-cb1e-4297-9ba9-d8e02973be0c, blockid: BP-1717489377-132.72.109.20-1546970734525:blk_1073741828_1004, duration(ns): 11538258043
2019-01-08 20:11:44,718 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1717489377-132.72.109.20-1546970734525:blk_1073741828_1004, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[132.72.109.41:50010] terminating
2019-01-08 20:11:44,773 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1717489377-132.72.109.20-1546970734525:blk_1073741829_1005 src: /132.72.109.20:41666 dest: /132.72.109.20:50010
2019-01-08 20:11:56,296 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /132.72.109.20:41666, dest: /132.72.109.20:50010, bytes: 134217728, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-174457819_1, offset: 0, srvID: 26e32cb0-cb1e-4297-9ba9-d8e02973be0c, blockid: BP-1717489377-132.72.109.20-1546970734525:blk_1073741829_1005, duration(ns): 11512813885
2019-01-08 20:11:56,296 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1717489377-132.72.109.20-1546970734525:blk_1073741829_1005, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[132.72.109.41:50010] terminating
2019-01-08 20:11:56,318 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1717489377-132.72.109.20-1546970734525:blk_1073741830_1006 src: /132.72.109.20:41672 dest: /132.72.109.20:50010
2019-01-08 20:12:07,834 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /132.72.109.20:41672, dest: /132.72.109.20:50010, bytes: 134217728, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-174457819_1, offset: 0, srvID: 26e32cb0-cb1e-4297-9ba9-d8e02973be0c, blockid: BP-1717489377-132.72.109.20-1546970734525:blk_1073741830_1006, duration(ns): 11499435997
2019-01-08 20:12:07,842 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1717489377-132.72.109.20-1546970734525:blk_1073741830_1006, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[132.72.109.41:50010] terminating
2019-01-08 20:12:07,880 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1717489377-132.72.109.20-1546970734525:blk_1073741831_1007 src: /132.72.109.20:41680 dest: /132.72.109.20:50010
2019-01-08 20:12:08,069 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /132.72.109.20:41680, dest: /132.72.109.20:50010, bytes: 2068605, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-174457819_1, offset: 0, srvID: 26e32cb0-cb1e-4297-9ba9-d8e02973be0c, blockid: BP-1717489377-132.72.109.20-1546970734525:blk_1073741831_1007, duration(ns): 182131121
2019-01-08 20:12:08,080 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1717489377-132.72.109.20-1546970734525:blk_1073741831_1007, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[132.72.109.41:50010] terminating
2019-01-08 20:12:11,111 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1717489377-132.72.109.20-1546970734525:blk_1073741832_1008 src: /132.72.109.20:41686 dest: /132.72.109.20:50010
2019-01-08 20:12:20,366 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /132.72.109.20:41686, dest: /132.72.109.20:50010, bytes: 107785907, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1268683057_1, offset: 0, srvID: 26e32cb0-cb1e-4297-9ba9-d8e02973be0c, blockid: BP-1717489377-132.72.109.20-1546970734525:blk_1073741832_1008, duration(ns): 9248839954
2019-01-08 20:12:20,366 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1717489377-132.72.109.20-1546970734525:blk_1073741832_1008, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[132.72.109.41:50010] terminating
2019-01-08 20:12:22,871 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1717489377-132.72.109.20-1546970734525:blk_1073741833_1009 src: /132.72.109.20:41692 dest: /132.72.109.20:50010
2019-01-08 20:12:34,390 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /132.72.109.20:41692, dest: /132.72.109.20:50010, bytes: 134217728, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_240725449_1, offset: 0, srvID: 26e32cb0-cb1e-4297-9ba9-d8e02973be0c, blockid: BP-1717489377-132.72.109.20-1546970734525:blk_1073741833_1009, duration(ns): 11507815415
2019-01-08 20:12:34,405 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1717489377-132.72.109.20-1546970734525:blk_1073741833_1009, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[132.72.109.41:50010] terminating
2019-01-08 20:12:34,435 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1717489377-132.72.109.20-1546970734525:blk_1073741834_1010 src: /132.72.109.20:41698 dest: /132.72.109.20:50010
2019-01-08 20:12:45,956 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /132.72.109.20:41698, dest: /132.72.109.20:50010, bytes: 134217728, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_240725449_1, offset: 0, srvID: 26e32cb0-cb1e-4297-9ba9-d8e02973be0c, blockid: BP-1717489377-132.72.109.20-1546970734525:blk_1073741834_1010, duration(ns): 11517204318
2019-01-08 20:12:45,958 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1717489377-132.72.109.20-1546970734525:blk_1073741834_1010, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[132.72.109.41:50010] terminating
2019-01-08 20:12:46,138 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1717489377-132.72.109.20-1546970734525:blk_1073741835_1011 src: /132.72.109.20:41704 dest: /132.72.109.20:50010
2019-01-08 20:12:57,649 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /132.72.109.20:41704, dest: /132.72.109.20:50010, bytes: 134217728, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_240725449_1, offset: 0, srvID: 26e32cb0-cb1e-4297-9ba9-d8e02973be0c, blockid: BP-1717489377-132.72.109.20-1546970734525:blk_1073741835_1011, duration(ns): 11506845040
2019-01-08 20:12:57,661 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1717489377-132.72.109.20-1546970734525:blk_1073741835_1011, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[132.72.109.41:50010] terminating
2019-01-08 20:12:57,721 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1717489377-132.72.109.20-1546970734525:blk_1073741836_1012 src: /132.72.109.20:41710 dest: /132.72.109.20:50010
2019-01-08 20:13:09,238 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /132.72.109.20:41710, dest: /132.72.109.20:50010, bytes: 134217728, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_240725449_1, offset: 0, srvID: 26e32cb0-cb1e-4297-9ba9-d8e02973be0c, blockid: BP-1717489377-132.72.109.20-1546970734525:blk_1073741836_1012, duration(ns): 11511662133
2019-01-08 20:13:09,238 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1717489377-132.72.109.20-1546970734525:blk_1073741836_1012, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[132.72.109.41:50010] terminating
2019-01-08 20:13:09,278 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1717489377-132.72.109.20-1546970734525:blk_1073741837_1013 src: /132.72.109.20:41716 dest: /132.72.109.20:50010
2019-01-08 20:13:20,798 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /132.72.109.20:41716, dest: /132.72.109.20:50010, bytes: 134217728, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_240725449_1, offset: 0, srvID: 26e32cb0-cb1e-4297-9ba9-d8e02973be0c, blockid: BP-1717489377-132.72.109.20-1546970734525:blk_1073741837_1013, duration(ns): 11515365118
2019-01-08 20:13:20,809 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1717489377-132.72.109.20-1546970734525:blk_1073741837_1013, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[132.72.109.41:50010] terminating
2019-01-08 20:13:20,847 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1717489377-132.72.109.20-1546970734525:blk_1073741838_1014 src: /132.72.109.20:41722 dest: /132.72.109.20:50010
2019-01-08 20:13:32,358 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /132.72.109.20:41722, dest: /132.72.109.20:50010, bytes: 134217728, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_240725449_1, offset: 0, srvID: 26e32cb0-cb1e-4297-9ba9-d8e02973be0c, blockid: BP-1717489377-132.72.109.20-1546970734525:blk_1073741838_1014, duration(ns): 11506786094
2019-01-08 20:13:32,358 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1717489377-132.72.109.20-1546970734525:blk_1073741838_1014, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[132.72.109.41:50010] terminating
2019-01-08 20:13:32,384 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1717489377-132.72.109.20-1546970734525:blk_1073741839_1015 src: /132.72.109.20:41726 dest: /132.72.109.20:50010
2019-01-08 20:13:43,895 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /132.72.109.20:41726, dest: /132.72.109.20:50010, bytes: 134217728, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_240725449_1, offset: 0, srvID: 26e32cb0-cb1e-4297-9ba9-d8e02973be0c, blockid: BP-1717489377-132.72.109.20-1546970734525:blk_1073741839_1015, duration(ns): 11506337922
2019-01-08 20:13:43,908 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1717489377-132.72.109.20-1546970734525:blk_1073741839_1015, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[132.72.109.41:50010] terminating
2019-01-08 20:13:43,975 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1717489377-132.72.109.20-1546970734525:blk_1073741840_1016 src: /132.72.109.20:41732 dest: /132.72.109.20:50010
2019-01-08 20:13:55,482 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /132.72.109.20:41732, dest: /132.72.109.20:50010, bytes: 134217728, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_240725449_1, offset: 0, srvID: 26e32cb0-cb1e-4297-9ba9-d8e02973be0c, blockid: BP-1717489377-132.72.109.20-1546970734525:blk_1073741840_1016, duration(ns): 11503188010
2019-01-08 20:13:55,483 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1717489377-132.72.109.20-1546970734525:blk_1073741840_1016, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[132.72.109.41:50010] terminating
2019-01-08 20:13:55,507 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1717489377-132.72.109.20-1546970734525:blk_1073741841_1017 src: /132.72.109.20:41738 dest: /132.72.109.20:50010
2019-01-08 20:13:56,365 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /132.72.109.20:41738, dest: /132.72.109.20:50010, bytes: 4145567, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_240725449_1, offset: 0, srvID: 26e32cb0-cb1e-4297-9ba9-d8e02973be0c, blockid: BP-1717489377-132.72.109.20-1546970734525:blk_1073741841_1017, duration(ns): 359693506
2019-01-08 20:13:56,366 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1717489377-132.72.109.20-1546970734525:blk_1073741841_1017, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[132.72.109.41:50010] terminating
2019-01-08 20:15:00,655 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1717489377-132.72.109.20-1546970734525:blk_1073741842_1018 src: /132.72.109.20:41748 dest: /132.72.109.20:50010
2019-01-08 20:15:04,891 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /132.72.109.20:41748, dest: /132.72.109.20:50010, bytes: 49221245, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-587237367_1, offset: 0, srvID: 26e32cb0-cb1e-4297-9ba9-d8e02973be0c, blockid: BP-1717489377-132.72.109.20-1546970734525:blk_1073741842_1018, duration(ns): 4223826158
2019-01-08 20:15:04,891 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1717489377-132.72.109.20-1546970734525:blk_1073741842_1018, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[132.72.109.41:50010] terminating
2019-01-08 20:15:05,210 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1717489377-132.72.109.20-1546970734525:blk_1073741843_1019 src: /132.72.109.20:41754 dest: /132.72.109.20:50010
2019-01-08 20:15:05,224 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /132.72.109.20:41754, dest: /132.72.109.20:50010, bytes: 123, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-587237367_1, offset: 0, srvID: 26e32cb0-cb1e-4297-9ba9-d8e02973be0c, blockid: BP-1717489377-132.72.109.20-1546970734525:blk_1073741843_1019, duration(ns): 4711772
2019-01-08 20:15:05,224 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1717489377-132.72.109.20-1546970734525:blk_1073741843_1019, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[132.72.109.41:50010] terminating
2019-01-08 20:15:05,269 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1717489377-132.72.109.20-1546970734525:blk_1073741844_1020 src: /132.72.109.20:41758 dest: /132.72.109.20:50010
2019-01-08 20:15:05,289 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /132.72.109.20:41758, dest: /132.72.109.20:50010, bytes: 36, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-587237367_1, offset: 0, srvID: 26e32cb0-cb1e-4297-9ba9-d8e02973be0c, blockid: BP-1717489377-132.72.109.20-1546970734525:blk_1073741844_1020, duration(ns): 9264586
2019-01-08 20:15:05,290 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1717489377-132.72.109.20-1546970734525:blk_1073741844_1020, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[132.72.109.41:50010] terminating
2019-01-08 20:15:05,612 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1717489377-132.72.109.20-1546970734525:blk_1073741845_1021 src: /132.72.109.20:41762 dest: /132.72.109.20:50010
2019-01-08 20:15:05,637 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /132.72.109.20:41762, dest: /132.72.109.20:50010, bytes: 168838, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-587237367_1, offset: 0, srvID: 26e32cb0-cb1e-4297-9ba9-d8e02973be0c, blockid: BP-1717489377-132.72.109.20-1546970734525:blk_1073741845_1021, duration(ns): 20535014
2019-01-08 20:15:05,637 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1717489377-132.72.109.20-1546970734525:blk_1073741845_1021, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[132.72.109.41:50010] terminating
2019-01-08 20:15:16,848 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1717489377-132.72.109.20-1546970734525:blk_1073741846_1022 src: /132.72.109.41:45904 dest: /132.72.109.20:50010
2019-01-08 20:15:16,916 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /132.72.109.41:45904, dest: /132.72.109.20:50010, bytes: 195916, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_147205118_1, offset: 0, srvID: 26e32cb0-cb1e-4297-9ba9-d8e02973be0c, blockid: BP-1717489377-132.72.109.20-1546970734525:blk_1073741846_1022, duration(ns): 65837492
2019-01-08 20:15:16,916 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1717489377-132.72.109.20-1546970734525:blk_1073741846_1022, type=LAST_IN_PIPELINE terminating
2019-01-08 20:15:23,602 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1717489377-132.72.109.20-1546970734525:blk_1073741847_1023 src: /132.72.109.41:45930 dest: /132.72.109.20:50010
2019-01-08 20:15:23,632 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /132.72.109.41:45930, dest: /132.72.109.20:50010, bytes: 6, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_147205118_1, offset: 0, srvID: 26e32cb0-cb1e-4297-9ba9-d8e02973be0c, blockid: BP-1717489377-132.72.109.20-1546970734525:blk_1073741847_1023, duration(ns): 12087012
2019-01-08 20:15:23,632 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1717489377-132.72.109.20-1546970734525:blk_1073741847_1023, type=LAST_IN_PIPELINE terminating
2019-01-08 20:15:23,794 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1717489377-132.72.109.20-1546970734525:blk_1073741848_1024 src: /132.72.109.41:45934 dest: /132.72.109.20:50010
2019-01-08 20:15:23,814 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /132.72.109.41:45934, dest: /132.72.109.20:50010, bytes: 86, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_147205118_1, offset: 0, srvID: 26e32cb0-cb1e-4297-9ba9-d8e02973be0c, blockid: BP-1717489377-132.72.109.20-1546970734525:blk_1073741848_1024, duration(ns): 6047557
2019-01-08 20:15:23,814 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1717489377-132.72.109.20-1546970734525:blk_1073741848_1024, type=LAST_IN_PIPELINE terminating
2019-01-08 20:15:54,683 INFO datanode.webhdfs: 132.72.200.30 GET /webhdfs/v1/mappersLocations?op=OPEN&namenoderpcaddress=master:9000&offset=0 200
2019-01-08 20:16:04,206 INFO datanode.webhdfs: 132.72.200.30 GET /webhdfs/v1/reducersLocations?op=OPEN&namenoderpcaddress=master:9000&offset=0 200
2019-01-08 20:16:10,029 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1717489377-132.72.109.20-1546970734525:blk_1073741849_1025 src: /132.72.109.41:45950 dest: /132.72.109.20:50010
2019-01-08 20:16:15,563 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1717489377-132.72.109.20-1546970734525:blk_1073741850_1026 src: /132.72.109.41:45968 dest: /132.72.109.20:50010
2019-01-08 20:16:15,662 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /132.72.109.41:45968, dest: /132.72.109.20:50010, bytes: 8757, op: HDFS_WRITE, cliID: DFSClient_attempt_1546970280036_0001_r_000005_0_-737997408_1, offset: 0, srvID: 26e32cb0-cb1e-4297-9ba9-d8e02973be0c, blockid: BP-1717489377-132.72.109.20-1546970734525:blk_1073741850_1026, duration(ns): 35900655
2019-01-08 20:16:15,662 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1717489377-132.72.109.20-1546970734525:blk_1073741850_1026, type=LAST_IN_PIPELINE terminating
2019-01-08 20:16:15,877 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1717489377-132.72.109.20-1546970734525:blk_1073741851_1027 src: /132.72.109.41:45976 dest: /132.72.109.20:50010
2019-01-08 20:16:15,909 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1717489377-132.72.109.20-1546970734525:blk_1073741853_1029 src: /132.72.109.41:45978 dest: /132.72.109.20:50010
2019-01-08 20:16:15,945 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1717489377-132.72.109.20-1546970734525:blk_1073741852_1028 src: /132.72.109.41:45980 dest: /132.72.109.20:50010
2019-01-08 20:16:15,996 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /132.72.109.41:45976, dest: /132.72.109.20:50010, bytes: 8758, op: HDFS_WRITE, cliID: DFSClient_attempt_1546970280036_0001_r_000001_0_1793457176_1, offset: 0, srvID: 26e32cb0-cb1e-4297-9ba9-d8e02973be0c, blockid: BP-1717489377-132.72.109.20-1546970734525:blk_1073741851_1027, duration(ns): 107714955
2019-01-08 20:16:15,996 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1717489377-132.72.109.20-1546970734525:blk_1073741851_1027, type=LAST_IN_PIPELINE terminating
2019-01-08 20:16:16,005 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /132.72.109.41:45978, dest: /132.72.109.20:50010, bytes: 8761, op: HDFS_WRITE, cliID: DFSClient_attempt_1546970280036_0001_r_000003_0_-1889093767_1, offset: 0, srvID: 26e32cb0-cb1e-4297-9ba9-d8e02973be0c, blockid: BP-1717489377-132.72.109.20-1546970734525:blk_1073741853_1029, duration(ns): 94445041
2019-01-08 20:16:16,006 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1717489377-132.72.109.20-1546970734525:blk_1073741853_1029, type=LAST_IN_PIPELINE terminating
2019-01-08 20:16:16,022 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /132.72.109.41:45980, dest: /132.72.109.20:50010, bytes: 8761, op: HDFS_WRITE, cliID: DFSClient_attempt_1546970280036_0001_r_000007_0_-1865144770_1, offset: 0, srvID: 26e32cb0-cb1e-4297-9ba9-d8e02973be0c, blockid: BP-1717489377-132.72.109.20-1546970734525:blk_1073741852_1028, duration(ns): 59322348
2019-01-08 20:16:16,022 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1717489377-132.72.109.20-1546970734525:blk_1073741852_1028, type=LAST_IN_PIPELINE terminating
2019-01-08 20:16:18,514 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1717489377-132.72.109.20-1546970734525:blk_1073741854_1030 src: /132.72.109.20:41854 dest: /132.72.109.20:50010
2019-01-08 20:16:18,523 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1717489377-132.72.109.20-1546970734525:blk_1073741858_1034 src: /132.72.109.20:41850 dest: /132.72.109.20:50010
2019-01-08 20:16:18,538 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1717489377-132.72.109.20-1546970734525:blk_1073741855_1031 src: /132.72.109.20:41858 dest: /132.72.109.20:50010
2019-01-08 20:16:18,562 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1717489377-132.72.109.20-1546970734525:blk_1073741857_1033 src: /132.72.109.20:41856 dest: /132.72.109.20:50010
2019-01-08 20:16:18,568 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1717489377-132.72.109.20-1546970734525:blk_1073741856_1032 src: /132.72.109.20:41852 dest: /132.72.109.20:50010
2019-01-08 20:16:18,601 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /132.72.109.20:41854, dest: /132.72.109.20:50010, bytes: 8765, op: HDFS_WRITE, cliID: DFSClient_attempt_1546970280036_0001_r_000008_0_-910445297_1, offset: 0, srvID: 26e32cb0-cb1e-4297-9ba9-d8e02973be0c, blockid: BP-1717489377-132.72.109.20-1546970734525:blk_1073741854_1030, duration(ns): 66944617
2019-01-08 20:16:18,601 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1717489377-132.72.109.20-1546970734525:blk_1073741854_1030, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[132.72.109.41:50010] terminating
2019-01-08 20:16:18,614 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /132.72.109.20:41850, dest: /132.72.109.20:50010, bytes: 8762, op: HDFS_WRITE, cliID: DFSClient_attempt_1546970280036_0001_r_000004_0_-741309519_1, offset: 0, srvID: 26e32cb0-cb1e-4297-9ba9-d8e02973be0c, blockid: BP-1717489377-132.72.109.20-1546970734525:blk_1073741858_1034, duration(ns): 72583671
2019-01-08 20:16:18,614 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1717489377-132.72.109.20-1546970734525:blk_1073741858_1034, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[132.72.109.41:50010] terminating
2019-01-08 20:16:18,631 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /132.72.109.20:41856, dest: /132.72.109.20:50010, bytes: 8758, op: HDFS_WRITE, cliID: DFSClient_attempt_1546970280036_0001_r_000006_0_1318988326_1, offset: 0, srvID: 26e32cb0-cb1e-4297-9ba9-d8e02973be0c, blockid: BP-1717489377-132.72.109.20-1546970734525:blk_1073741857_1033, duration(ns): 52571420
2019-01-08 20:16:18,631 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1717489377-132.72.109.20-1546970734525:blk_1073741857_1033, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[132.72.109.41:50010] terminating
2019-01-08 20:16:18,670 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /132.72.109.20:41852, dest: /132.72.109.20:50010, bytes: 8759, op: HDFS_WRITE, cliID: DFSClient_attempt_1546970280036_0001_r_000000_0_731636245_1, offset: 0, srvID: 26e32cb0-cb1e-4297-9ba9-d8e02973be0c, blockid: BP-1717489377-132.72.109.20-1546970734525:blk_1073741856_1032, duration(ns): 75524548
2019-01-08 20:16:18,670 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1717489377-132.72.109.20-1546970734525:blk_1073741856_1032, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[132.72.109.41:50010] terminating
2019-01-08 20:16:18,689 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /132.72.109.20:41858, dest: /132.72.109.20:50010, bytes: 8762, op: HDFS_WRITE, cliID: DFSClient_attempt_1546970280036_0001_r_000002_0_1187024945_1, offset: 0, srvID: 26e32cb0-cb1e-4297-9ba9-d8e02973be0c, blockid: BP-1717489377-132.72.109.20-1546970734525:blk_1073741855_1031, duration(ns): 132840427
2019-01-08 20:16:18,689 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1717489377-132.72.109.20-1546970734525:blk_1073741855_1031, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[132.72.109.41:50010] terminating
2019-01-08 20:16:19,537 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /132.72.109.41:45950, dest: /132.72.109.20:50010, bytes: 95217, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_147205118_1, offset: 0, srvID: 26e32cb0-cb1e-4297-9ba9-d8e02973be0c, blockid: BP-1717489377-132.72.109.20-1546970734525:blk_1073741849_1025, duration(ns): 9250330297
2019-01-08 20:16:19,538 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1717489377-132.72.109.20-1546970734525:blk_1073741849_1025, type=LAST_IN_PIPELINE terminating
2019-01-08 20:16:19,580 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1717489377-132.72.109.20-1546970734525:blk_1073741859_1035 src: /132.72.109.41:45984 dest: /132.72.109.20:50010
2019-01-08 20:16:19,619 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /132.72.109.41:45984, dest: /132.72.109.20:50010, bytes: 360, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_147205118_1, offset: 0, srvID: 26e32cb0-cb1e-4297-9ba9-d8e02973be0c, blockid: BP-1717489377-132.72.109.20-1546970734525:blk_1073741859_1035, duration(ns): 6579189
2019-01-08 20:16:19,619 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1717489377-132.72.109.20-1546970734525:blk_1073741859_1035, type=LAST_IN_PIPELINE terminating
2019-01-08 20:16:19,780 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1717489377-132.72.109.20-1546970734525:blk_1073741860_1036 src: /132.72.109.41:45990 dest: /132.72.109.20:50010
2019-01-08 20:16:19,797 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /132.72.109.41:45990, dest: /132.72.109.20:50010, bytes: 95217, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_147205118_1, offset: 0, srvID: 26e32cb0-cb1e-4297-9ba9-d8e02973be0c, blockid: BP-1717489377-132.72.109.20-1546970734525:blk_1073741860_1036, duration(ns): 15363476
2019-01-08 20:16:19,798 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1717489377-132.72.109.20-1546970734525:blk_1073741860_1036, type=LAST_IN_PIPELINE terminating
2019-01-08 20:16:19,881 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1717489377-132.72.109.20-1546970734525:blk_1073741861_1037 src: /132.72.109.41:45994 dest: /132.72.109.20:50010
2019-01-08 20:16:19,905 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /132.72.109.41:45994, dest: /132.72.109.20:50010, bytes: 195916, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_147205118_1, offset: 0, srvID: 26e32cb0-cb1e-4297-9ba9-d8e02973be0c, blockid: BP-1717489377-132.72.109.20-1546970734525:blk_1073741861_1037, duration(ns): 20683706
2019-01-08 20:16:19,905 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1717489377-132.72.109.20-1546970734525:blk_1073741861_1037, type=LAST_IN_PIPELINE terminating
2019-01-08 20:16:21,760 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1717489377-132.72.109.20-1546970734525:blk_1073741862_1038 src: /132.72.109.20:41874 dest: /132.72.109.20:50010
2019-01-08 20:16:25,530 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741842_1018 file /usr/local/hadoop/data/hadoop-data/dn/current/BP-1717489377-132.72.109.20-1546970734525/current/finalized/subdir0/subdir0/blk_1073741842 for deletion
2019-01-08 20:16:25,577 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741843_1019 file /usr/local/hadoop/data/hadoop-data/dn/current/BP-1717489377-132.72.109.20-1546970734525/current/finalized/subdir0/subdir0/blk_1073741843 for deletion
2019-01-08 20:16:25,578 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1717489377-132.72.109.20-1546970734525 blk_1073741842_1018 file /usr/local/hadoop/data/hadoop-data/dn/current/BP-1717489377-132.72.109.20-1546970734525/current/finalized/subdir0/subdir0/blk_1073741842
2019-01-08 20:16:25,578 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741844_1020 file /usr/local/hadoop/data/hadoop-data/dn/current/BP-1717489377-132.72.109.20-1546970734525/current/finalized/subdir0/subdir0/blk_1073741844 for deletion
2019-01-08 20:16:25,578 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741845_1021 file /usr/local/hadoop/data/hadoop-data/dn/current/BP-1717489377-132.72.109.20-1546970734525/current/finalized/subdir0/subdir0/blk_1073741845 for deletion
2019-01-08 20:16:25,578 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741846_1022 file /usr/local/hadoop/data/hadoop-data/dn/current/BP-1717489377-132.72.109.20-1546970734525/current/finalized/subdir0/subdir0/blk_1073741846 for deletion
2019-01-08 20:16:25,578 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741849_1025 file /usr/local/hadoop/data/hadoop-data/dn/current/BP-1717489377-132.72.109.20-1546970734525/current/finalized/subdir0/subdir0/blk_1073741849 for deletion
2019-01-08 20:16:25,579 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1717489377-132.72.109.20-1546970734525 blk_1073741843_1019 file /usr/local/hadoop/data/hadoop-data/dn/current/BP-1717489377-132.72.109.20-1546970734525/current/finalized/subdir0/subdir0/blk_1073741843
2019-01-08 20:16:25,579 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1717489377-132.72.109.20-1546970734525 blk_1073741844_1020 file /usr/local/hadoop/data/hadoop-data/dn/current/BP-1717489377-132.72.109.20-1546970734525/current/finalized/subdir0/subdir0/blk_1073741844
2019-01-08 20:16:25,579 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1717489377-132.72.109.20-1546970734525 blk_1073741845_1021 file /usr/local/hadoop/data/hadoop-data/dn/current/BP-1717489377-132.72.109.20-1546970734525/current/finalized/subdir0/subdir0/blk_1073741845
2019-01-08 20:16:25,579 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1717489377-132.72.109.20-1546970734525 blk_1073741846_1022 file /usr/local/hadoop/data/hadoop-data/dn/current/BP-1717489377-132.72.109.20-1546970734525/current/finalized/subdir0/subdir0/blk_1073741846
2019-01-08 20:16:25,579 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1717489377-132.72.109.20-1546970734525 blk_1073741849_1025 file /usr/local/hadoop/data/hadoop-data/dn/current/BP-1717489377-132.72.109.20-1546970734525/current/finalized/subdir0/subdir0/blk_1073741849
2019-01-08 20:16:26,105 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /132.72.109.20:41874, dest: /132.72.109.20:50010, bytes: 49221245, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-587237367_1, offset: 0, srvID: 26e32cb0-cb1e-4297-9ba9-d8e02973be0c, blockid: BP-1717489377-132.72.109.20-1546970734525:blk_1073741862_1038, duration(ns): 4340487152
2019-01-08 20:16:26,106 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1717489377-132.72.109.20-1546970734525:blk_1073741862_1038, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[132.72.109.41:50010] terminating
2019-01-08 20:16:26,191 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1717489377-132.72.109.20-1546970734525:blk_1073741863_1039 src: /132.72.109.20:41878 dest: /132.72.109.20:50010
2019-01-08 20:16:26,199 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /132.72.109.20:41878, dest: /132.72.109.20:50010, bytes: 123, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-587237367_1, offset: 0, srvID: 26e32cb0-cb1e-4297-9ba9-d8e02973be0c, blockid: BP-1717489377-132.72.109.20-1546970734525:blk_1073741863_1039, duration(ns): 3755087
2019-01-08 20:16:26,200 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1717489377-132.72.109.20-1546970734525:blk_1073741863_1039, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[132.72.109.41:50010] terminating
2019-01-08 20:16:26,232 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1717489377-132.72.109.20-1546970734525:blk_1073741864_1040 src: /132.72.109.20:41882 dest: /132.72.109.20:50010
2019-01-08 20:16:26,241 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /132.72.109.20:41882, dest: /132.72.109.20:50010, bytes: 36, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-587237367_1, offset: 0, srvID: 26e32cb0-cb1e-4297-9ba9-d8e02973be0c, blockid: BP-1717489377-132.72.109.20-1546970734525:blk_1073741864_1040, duration(ns): 3974668
2019-01-08 20:16:26,241 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1717489377-132.72.109.20-1546970734525:blk_1073741864_1040, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[132.72.109.41:50010] terminating
2019-01-08 20:16:26,334 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1717489377-132.72.109.20-1546970734525:blk_1073741865_1041 src: /132.72.109.20:41886 dest: /132.72.109.20:50010
2019-01-08 20:16:26,362 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /132.72.109.20:41886, dest: /132.72.109.20:50010, bytes: 168677, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-587237367_1, offset: 0, srvID: 26e32cb0-cb1e-4297-9ba9-d8e02973be0c, blockid: BP-1717489377-132.72.109.20-1546970734525:blk_1073741865_1041, duration(ns): 18016258
2019-01-08 20:16:26,363 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1717489377-132.72.109.20-1546970734525:blk_1073741865_1041, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[132.72.109.41:50010] terminating
2019-01-08 20:16:27,401 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1717489377-132.72.109.20-1546970734525:blk_1073741866_1042 src: /132.72.109.20:41896 dest: /132.72.109.20:50010
2019-01-08 20:16:27,466 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /132.72.109.20:41896, dest: /132.72.109.20:50010, bytes: 338934, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-2111530813_105, offset: 0, srvID: 26e32cb0-cb1e-4297-9ba9-d8e02973be0c, blockid: BP-1717489377-132.72.109.20-1546970734525:blk_1073741866_1042, duration(ns): 59738392
2019-01-08 20:16:27,466 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1717489377-132.72.109.20-1546970734525:blk_1073741866_1042, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[132.72.109.41:50010] terminating
2019-01-08 20:16:27,811 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1717489377-132.72.109.20-1546970734525:blk_1073741867_1043 src: /132.72.109.41:46020 dest: /132.72.109.20:50010
2019-01-08 20:16:27,853 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /132.72.109.41:46020, dest: /132.72.109.20:50010, bytes: 276665, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-840305954_91, offset: 0, srvID: 26e32cb0-cb1e-4297-9ba9-d8e02973be0c, blockid: BP-1717489377-132.72.109.20-1546970734525:blk_1073741867_1043, duration(ns): 39364573
2019-01-08 20:16:27,853 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1717489377-132.72.109.20-1546970734525:blk_1073741867_1043, type=LAST_IN_PIPELINE terminating
2019-01-08 20:16:34,119 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1717489377-132.72.109.20-1546970734525:blk_1073741868_1044 src: /132.72.109.41:46030 dest: /132.72.109.20:50010
2019-01-08 20:16:34,153 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /132.72.109.41:46030, dest: /132.72.109.20:50010, bytes: 195916, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-2092162080_1, offset: 0, srvID: 26e32cb0-cb1e-4297-9ba9-d8e02973be0c, blockid: BP-1717489377-132.72.109.20-1546970734525:blk_1073741868_1044, duration(ns): 30889683
2019-01-08 20:16:34,156 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1717489377-132.72.109.20-1546970734525:blk_1073741868_1044, type=LAST_IN_PIPELINE terminating
2019-01-08 20:16:40,990 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1717489377-132.72.109.20-1546970734525:blk_1073741869_1045 src: /132.72.109.41:46056 dest: /132.72.109.20:50010
2019-01-08 20:16:41,046 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /132.72.109.41:46056, dest: /132.72.109.20:50010, bytes: 6, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-2092162080_1, offset: 0, srvID: 26e32cb0-cb1e-4297-9ba9-d8e02973be0c, blockid: BP-1717489377-132.72.109.20-1546970734525:blk_1073741869_1045, duration(ns): 45993698
2019-01-08 20:16:41,046 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1717489377-132.72.109.20-1546970734525:blk_1073741869_1045, type=LAST_IN_PIPELINE terminating
2019-01-08 20:16:41,330 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1717489377-132.72.109.20-1546970734525:blk_1073741870_1046 src: /132.72.109.41:46060 dest: /132.72.109.20:50010
2019-01-08 20:16:41,351 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /132.72.109.41:46060, dest: /132.72.109.20:50010, bytes: 86, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-2092162080_1, offset: 0, srvID: 26e32cb0-cb1e-4297-9ba9-d8e02973be0c, blockid: BP-1717489377-132.72.109.20-1546970734525:blk_1073741870_1046, duration(ns): 19319845
2019-01-08 20:16:41,351 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1717489377-132.72.109.20-1546970734525:blk_1073741870_1046, type=LAST_IN_PIPELINE terminating
2019-01-08 20:16:43,276 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741847_1023 file /usr/local/hadoop/data/hadoop-data/dn/current/BP-1717489377-132.72.109.20-1546970734525/current/finalized/subdir0/subdir0/blk_1073741847 for deletion
2019-01-08 20:16:43,276 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741848_1024 file /usr/local/hadoop/data/hadoop-data/dn/current/BP-1717489377-132.72.109.20-1546970734525/current/finalized/subdir0/subdir0/blk_1073741848 for deletion
2019-01-08 20:16:43,276 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1717489377-132.72.109.20-1546970734525 blk_1073741847_1023 file /usr/local/hadoop/data/hadoop-data/dn/current/BP-1717489377-132.72.109.20-1546970734525/current/finalized/subdir0/subdir0/blk_1073741847
2019-01-08 20:16:43,277 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1717489377-132.72.109.20-1546970734525 blk_1073741848_1024 file /usr/local/hadoop/data/hadoop-data/dn/current/BP-1717489377-132.72.109.20-1546970734525/current/finalized/subdir0/subdir0/blk_1073741848
2019-01-08 20:17:22,125 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1717489377-132.72.109.20-1546970734525:blk_1073741871_1047 src: /132.72.109.41:46080 dest: /132.72.109.20:50010
2019-01-08 20:17:23,031 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1717489377-132.72.109.20-1546970734525:blk_1073741872_1048 src: /132.72.109.41:46092 dest: /132.72.109.20:50010
2019-01-08 20:17:23,150 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /132.72.109.41:46092, dest: /132.72.109.20:50010, bytes: 8761, op: HDFS_WRITE, cliID: DFSClient_attempt_1546970280036_0002_r_000003_0_753323208_1, offset: 0, srvID: 26e32cb0-cb1e-4297-9ba9-d8e02973be0c, blockid: BP-1717489377-132.72.109.20-1546970734525:blk_1073741872_1048, duration(ns): 83982257
2019-01-08 20:17:23,153 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1717489377-132.72.109.20-1546970734525:blk_1073741872_1048, type=LAST_IN_PIPELINE terminating
2019-01-08 20:17:23,713 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1717489377-132.72.109.20-1546970734525:blk_1073741873_1049 src: /132.72.109.41:46098 dest: /132.72.109.20:50010
2019-01-08 20:17:23,738 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /132.72.109.41:46098, dest: /132.72.109.20:50010, bytes: 8758, op: HDFS_WRITE, cliID: DFSClient_attempt_1546970280036_0002_r_000001_0_717226122_1, offset: 0, srvID: 26e32cb0-cb1e-4297-9ba9-d8e02973be0c, blockid: BP-1717489377-132.72.109.20-1546970734525:blk_1073741873_1049, duration(ns): 23499427
2019-01-08 20:17:23,738 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1717489377-132.72.109.20-1546970734525:blk_1073741873_1049, type=LAST_IN_PIPELINE terminating
2019-01-08 20:17:23,964 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1717489377-132.72.109.20-1546970734525:blk_1073741874_1050 src: /132.72.109.41:46104 dest: /132.72.109.20:50010
2019-01-08 20:17:24,012 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1717489377-132.72.109.20-1546970734525:blk_1073741875_1051 src: /132.72.109.41:46106 dest: /132.72.109.20:50010
2019-01-08 20:17:24,014 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /132.72.109.41:46104, dest: /132.72.109.20:50010, bytes: 8757, op: HDFS_WRITE, cliID: DFSClient_attempt_1546970280036_0002_r_000005_0_-1168082470_1, offset: 0, srvID: 26e32cb0-cb1e-4297-9ba9-d8e02973be0c, blockid: BP-1717489377-132.72.109.20-1546970734525:blk_1073741874_1050, duration(ns): 49342797
2019-01-08 20:17:24,014 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1717489377-132.72.109.20-1546970734525:blk_1073741874_1050, type=LAST_IN_PIPELINE terminating
2019-01-08 20:17:24,043 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /132.72.109.41:46106, dest: /132.72.109.20:50010, bytes: 8761, op: HDFS_WRITE, cliID: DFSClient_attempt_1546970280036_0002_r_000007_0_1336571071_1, offset: 0, srvID: 26e32cb0-cb1e-4297-9ba9-d8e02973be0c, blockid: BP-1717489377-132.72.109.20-1546970734525:blk_1073741875_1051, duration(ns): 28510609
2019-01-08 20:17:24,044 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1717489377-132.72.109.20-1546970734525:blk_1073741875_1051, type=LAST_IN_PIPELINE terminating
2019-01-08 20:17:42,892 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1717489377-132.72.109.20-1546970734525:blk_1073741879_1055 src: /132.72.109.20:41978 dest: /132.72.109.20:50010
2019-01-08 20:17:42,895 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1717489377-132.72.109.20-1546970734525:blk_1073741876_1052 src: /132.72.109.20:41976 dest: /132.72.109.20:50010
2019-01-08 20:17:42,896 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1717489377-132.72.109.20-1546970734525:blk_1073741878_1054 src: /132.72.109.20:41980 dest: /132.72.109.20:50010
2019-01-08 20:17:42,897 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1717489377-132.72.109.20-1546970734525:blk_1073741877_1053 src: /132.72.109.20:41972 dest: /132.72.109.20:50010
2019-01-08 20:17:42,902 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1717489377-132.72.109.20-1546970734525:blk_1073741880_1056 src: /132.72.109.20:41974 dest: /132.72.109.20:50010
2019-01-08 20:17:43,042 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /132.72.109.20:41974, dest: /132.72.109.20:50010, bytes: 8758, op: HDFS_WRITE, cliID: DFSClient_attempt_1546970280036_0002_r_000006_0_-1194146604_1, offset: 0, srvID: 26e32cb0-cb1e-4297-9ba9-d8e02973be0c, blockid: BP-1717489377-132.72.109.20-1546970734525:blk_1073741880_1056, duration(ns): 116497077
2019-01-08 20:17:43,042 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1717489377-132.72.109.20-1546970734525:blk_1073741880_1056, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[132.72.109.41:50010] terminating
2019-01-08 20:17:43,044 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /132.72.109.20:41978, dest: /132.72.109.20:50010, bytes: 8765, op: HDFS_WRITE, cliID: DFSClient_attempt_1546970280036_0002_r_000008_0_-779621613_1, offset: 0, srvID: 26e32cb0-cb1e-4297-9ba9-d8e02973be0c, blockid: BP-1717489377-132.72.109.20-1546970734525:blk_1073741879_1055, duration(ns): 145299972
2019-01-08 20:17:43,044 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1717489377-132.72.109.20-1546970734525:blk_1073741879_1055, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[132.72.109.41:50010] terminating
2019-01-08 20:17:43,049 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /132.72.109.20:41976, dest: /132.72.109.20:50010, bytes: 8762, op: HDFS_WRITE, cliID: DFSClient_attempt_1546970280036_0002_r_000002_0_523100913_1, offset: 0, srvID: 26e32cb0-cb1e-4297-9ba9-d8e02973be0c, blockid: BP-1717489377-132.72.109.20-1546970734525:blk_1073741876_1052, duration(ns): 119745046
2019-01-08 20:17:43,049 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1717489377-132.72.109.20-1546970734525:blk_1073741876_1052, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[132.72.109.41:50010] terminating
2019-01-08 20:17:43,053 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /132.72.109.20:41972, dest: /132.72.109.20:50010, bytes: 8762, op: HDFS_WRITE, cliID: DFSClient_attempt_1546970280036_0002_r_000004_0_1170459243_1, offset: 0, srvID: 26e32cb0-cb1e-4297-9ba9-d8e02973be0c, blockid: BP-1717489377-132.72.109.20-1546970734525:blk_1073741877_1053, duration(ns): 126993384
2019-01-08 20:17:43,053 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1717489377-132.72.109.20-1546970734525:blk_1073741877_1053, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[132.72.109.41:50010] terminating
2019-01-08 20:17:43,054 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /132.72.109.20:41980, dest: /132.72.109.20:50010, bytes: 8759, op: HDFS_WRITE, cliID: DFSClient_attempt_1546970280036_0002_r_000000_0_-2026219016_1, offset: 0, srvID: 26e32cb0-cb1e-4297-9ba9-d8e02973be0c, blockid: BP-1717489377-132.72.109.20-1546970734525:blk_1073741878_1054, duration(ns): 137024617
2019-01-08 20:17:43,054 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1717489377-132.72.109.20-1546970734525:blk_1073741878_1054, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[132.72.109.41:50010] terminating
2019-01-08 20:17:45,114 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /132.72.109.41:46080, dest: /132.72.109.20:50010, bytes: 95941, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-2092162080_1, offset: 0, srvID: 26e32cb0-cb1e-4297-9ba9-d8e02973be0c, blockid: BP-1717489377-132.72.109.20-1546970734525:blk_1073741871_1047, duration(ns): 22528551362
2019-01-08 20:17:45,114 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1717489377-132.72.109.20-1546970734525:blk_1073741871_1047, type=LAST_IN_PIPELINE terminating
2019-01-08 20:17:45,253 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1717489377-132.72.109.20-1546970734525:blk_1073741881_1057 src: /132.72.109.41:46116 dest: /132.72.109.20:50010
2019-01-08 20:17:45,263 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /132.72.109.41:46116, dest: /132.72.109.20:50010, bytes: 360, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-2092162080_1, offset: 0, srvID: 26e32cb0-cb1e-4297-9ba9-d8e02973be0c, blockid: BP-1717489377-132.72.109.20-1546970734525:blk_1073741881_1057, duration(ns): 3687899
2019-01-08 20:17:45,263 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1717489377-132.72.109.20-1546970734525:blk_1073741881_1057, type=LAST_IN_PIPELINE terminating
2019-01-08 20:17:45,426 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1717489377-132.72.109.20-1546970734525:blk_1073741882_1058 src: /132.72.109.41:46122 dest: /132.72.109.20:50010
2019-01-08 20:17:45,440 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /132.72.109.41:46122, dest: /132.72.109.20:50010, bytes: 95941, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-2092162080_1, offset: 0, srvID: 26e32cb0-cb1e-4297-9ba9-d8e02973be0c, blockid: BP-1717489377-132.72.109.20-1546970734525:blk_1073741882_1058, duration(ns): 11689475
2019-01-08 20:17:45,440 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1717489377-132.72.109.20-1546970734525:blk_1073741882_1058, type=LAST_IN_PIPELINE terminating
2019-01-08 20:17:45,642 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1717489377-132.72.109.20-1546970734525:blk_1073741883_1059 src: /132.72.109.41:46126 dest: /132.72.109.20:50010
2019-01-08 20:17:45,669 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /132.72.109.41:46126, dest: /132.72.109.20:50010, bytes: 195916, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-2092162080_1, offset: 0, srvID: 26e32cb0-cb1e-4297-9ba9-d8e02973be0c, blockid: BP-1717489377-132.72.109.20-1546970734525:blk_1073741883_1059, duration(ns): 24263490
2019-01-08 20:17:45,669 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1717489377-132.72.109.20-1546970734525:blk_1073741883_1059, type=LAST_IN_PIPELINE terminating
2019-01-08 20:17:53,980 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1717489377-132.72.109.20-1546970734525:blk_1073741884_1060 src: /132.72.109.41:46132 dest: /132.72.109.20:50010
2019-01-08 20:17:54,008 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /132.72.109.41:46132, dest: /132.72.109.20:50010, bytes: 275642, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-940707108_148, offset: 0, srvID: 26e32cb0-cb1e-4297-9ba9-d8e02973be0c, blockid: BP-1717489377-132.72.109.20-1546970734525:blk_1073741884_1060, duration(ns): 22431414
2019-01-08 20:17:54,009 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1717489377-132.72.109.20-1546970734525:blk_1073741884_1060, type=LAST_IN_PIPELINE terminating
2019-01-08 20:17:54,136 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1717489377-132.72.109.20-1546970734525:blk_1073741885_1061 src: /132.72.109.20:41998 dest: /132.72.109.20:50010
2019-01-08 20:17:54,267 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /132.72.109.20:41998, dest: /132.72.109.20:50010, bytes: 340775, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-147494400_172, offset: 0, srvID: 26e32cb0-cb1e-4297-9ba9-d8e02973be0c, blockid: BP-1717489377-132.72.109.20-1546970734525:blk_1073741885_1061, duration(ns): 126528241
2019-01-08 20:17:54,267 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1717489377-132.72.109.20-1546970734525:blk_1073741885_1061, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[132.72.109.41:50010] terminating
2019-01-08 20:17:55,282 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741862_1038 file /usr/local/hadoop/data/hadoop-data/dn/current/BP-1717489377-132.72.109.20-1546970734525/current/finalized/subdir0/subdir0/blk_1073741862 for deletion
2019-01-08 20:17:55,282 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741863_1039 file /usr/local/hadoop/data/hadoop-data/dn/current/BP-1717489377-132.72.109.20-1546970734525/current/finalized/subdir0/subdir0/blk_1073741863 for deletion
2019-01-08 20:17:55,283 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741864_1040 file /usr/local/hadoop/data/hadoop-data/dn/current/BP-1717489377-132.72.109.20-1546970734525/current/finalized/subdir0/subdir0/blk_1073741864 for deletion
2019-01-08 20:17:55,283 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741865_1041 file /usr/local/hadoop/data/hadoop-data/dn/current/BP-1717489377-132.72.109.20-1546970734525/current/finalized/subdir0/subdir0/blk_1073741865 for deletion
2019-01-08 20:17:55,283 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741868_1044 file /usr/local/hadoop/data/hadoop-data/dn/current/BP-1717489377-132.72.109.20-1546970734525/current/finalized/subdir0/subdir0/blk_1073741868 for deletion
2019-01-08 20:17:55,283 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741871_1047 file /usr/local/hadoop/data/hadoop-data/dn/current/BP-1717489377-132.72.109.20-1546970734525/current/finalized/subdir0/subdir0/blk_1073741871 for deletion
2019-01-08 20:17:55,283 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1717489377-132.72.109.20-1546970734525 blk_1073741862_1038 file /usr/local/hadoop/data/hadoop-data/dn/current/BP-1717489377-132.72.109.20-1546970734525/current/finalized/subdir0/subdir0/blk_1073741862
2019-01-08 20:17:55,283 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1717489377-132.72.109.20-1546970734525 blk_1073741863_1039 file /usr/local/hadoop/data/hadoop-data/dn/current/BP-1717489377-132.72.109.20-1546970734525/current/finalized/subdir0/subdir0/blk_1073741863
2019-01-08 20:17:55,283 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1717489377-132.72.109.20-1546970734525 blk_1073741864_1040 file /usr/local/hadoop/data/hadoop-data/dn/current/BP-1717489377-132.72.109.20-1546970734525/current/finalized/subdir0/subdir0/blk_1073741864
2019-01-08 20:17:55,283 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1717489377-132.72.109.20-1546970734525 blk_1073741865_1041 file /usr/local/hadoop/data/hadoop-data/dn/current/BP-1717489377-132.72.109.20-1546970734525/current/finalized/subdir0/subdir0/blk_1073741865
2019-01-08 20:17:55,284 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1717489377-132.72.109.20-1546970734525 blk_1073741868_1044 file /usr/local/hadoop/data/hadoop-data/dn/current/BP-1717489377-132.72.109.20-1546970734525/current/finalized/subdir0/subdir0/blk_1073741868
2019-01-08 20:17:55,284 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1717489377-132.72.109.20-1546970734525 blk_1073741871_1047 file /usr/local/hadoop/data/hadoop-data/dn/current/BP-1717489377-132.72.109.20-1546970734525/current/finalized/subdir0/subdir0/blk_1073741871
2019-01-08 20:18:28,281 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741859_1035 file /usr/local/hadoop/data/hadoop-data/dn/current/BP-1717489377-132.72.109.20-1546970734525/current/finalized/subdir0/subdir0/blk_1073741859 for deletion
2019-01-08 20:18:28,281 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741881_1057 file /usr/local/hadoop/data/hadoop-data/dn/current/BP-1717489377-132.72.109.20-1546970734525/current/finalized/subdir0/subdir0/blk_1073741881 for deletion
2019-01-08 20:18:28,282 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1717489377-132.72.109.20-1546970734525 blk_1073741859_1035 file /usr/local/hadoop/data/hadoop-data/dn/current/BP-1717489377-132.72.109.20-1546970734525/current/finalized/subdir0/subdir0/blk_1073741859
2019-01-08 20:18:28,282 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1717489377-132.72.109.20-1546970734525 blk_1073741881_1057 file /usr/local/hadoop/data/hadoop-data/dn/current/BP-1717489377-132.72.109.20-1546970734525/current/finalized/subdir0/subdir0/blk_1073741881
2019-01-08 21:01:31,795 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1717489377-132.72.109.20-1546970734525:blk_1073741886_1062 src: /132.72.109.20:42190 dest: /132.72.109.20:50010
2019-01-08 21:01:36,029 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /132.72.109.20:42190, dest: /132.72.109.20:50010, bytes: 49221245, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1050584424_1, offset: 0, srvID: 26e32cb0-cb1e-4297-9ba9-d8e02973be0c, blockid: BP-1717489377-132.72.109.20-1546970734525:blk_1073741886_1062, duration(ns): 4229548813
2019-01-08 21:01:36,029 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1717489377-132.72.109.20-1546970734525:blk_1073741886_1062, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[132.72.109.41:50010] terminating
2019-01-08 21:01:36,770 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1717489377-132.72.109.20-1546970734525:blk_1073741887_1063 src: /132.72.109.20:42194 dest: /132.72.109.20:50010
2019-01-08 21:01:36,789 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /132.72.109.20:42194, dest: /132.72.109.20:50010, bytes: 123, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1050584424_1, offset: 0, srvID: 26e32cb0-cb1e-4297-9ba9-d8e02973be0c, blockid: BP-1717489377-132.72.109.20-1546970734525:blk_1073741887_1063, duration(ns): 15226727
2019-01-08 21:01:36,789 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1717489377-132.72.109.20-1546970734525:blk_1073741887_1063, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[132.72.109.41:50010] terminating
2019-01-08 21:01:36,836 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1717489377-132.72.109.20-1546970734525:blk_1073741888_1064 src: /132.72.109.20:42198 dest: /132.72.109.20:50010
2019-01-08 21:01:36,848 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /132.72.109.20:42198, dest: /132.72.109.20:50010, bytes: 36, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1050584424_1, offset: 0, srvID: 26e32cb0-cb1e-4297-9ba9-d8e02973be0c, blockid: BP-1717489377-132.72.109.20-1546970734525:blk_1073741888_1064, duration(ns): 5188719
2019-01-08 21:01:36,848 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1717489377-132.72.109.20-1546970734525:blk_1073741888_1064, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[132.72.109.41:50010] terminating
2019-01-08 21:01:37,545 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1717489377-132.72.109.20-1546970734525:blk_1073741889_1065 src: /132.72.109.20:42202 dest: /132.72.109.20:50010
2019-01-08 21:01:37,571 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /132.72.109.20:42202, dest: /132.72.109.20:50010, bytes: 168838, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1050584424_1, offset: 0, srvID: 26e32cb0-cb1e-4297-9ba9-d8e02973be0c, blockid: BP-1717489377-132.72.109.20-1546970734525:blk_1073741889_1065, duration(ns): 17301712
2019-01-08 21:01:37,571 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1717489377-132.72.109.20-1546970734525:blk_1073741889_1065, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[132.72.109.41:50010] terminating
2019-01-08 21:01:45,103 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1717489377-132.72.109.20-1546970734525:blk_1073741890_1066 src: /132.72.109.41:46152 dest: /132.72.109.20:50010
2019-01-08 21:01:45,133 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /132.72.109.41:46152, dest: /132.72.109.20:50010, bytes: 195916, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1302788802_1, offset: 0, srvID: 26e32cb0-cb1e-4297-9ba9-d8e02973be0c, blockid: BP-1717489377-132.72.109.20-1546970734525:blk_1073741890_1066, duration(ns): 28742901
2019-01-08 21:01:45,134 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1717489377-132.72.109.20-1546970734525:blk_1073741890_1066, type=LAST_IN_PIPELINE terminating
2019-01-08 21:01:51,857 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1717489377-132.72.109.20-1546970734525:blk_1073741891_1067 src: /132.72.109.41:46178 dest: /132.72.109.20:50010
2019-01-08 21:01:51,909 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /132.72.109.41:46178, dest: /132.72.109.20:50010, bytes: 12, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1302788802_1, offset: 0, srvID: 26e32cb0-cb1e-4297-9ba9-d8e02973be0c, blockid: BP-1717489377-132.72.109.20-1546970734525:blk_1073741891_1067, duration(ns): 29309524
2019-01-08 21:01:51,909 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1717489377-132.72.109.20-1546970734525:blk_1073741891_1067, type=LAST_IN_PIPELINE terminating
2019-01-08 21:01:51,969 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1717489377-132.72.109.20-1546970734525:blk_1073741892_1068 src: /132.72.109.41:46182 dest: /132.72.109.20:50010
2019-01-08 21:01:51,983 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /132.72.109.41:46182, dest: /132.72.109.20:50010, bytes: 92, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1302788802_1, offset: 0, srvID: 26e32cb0-cb1e-4297-9ba9-d8e02973be0c, blockid: BP-1717489377-132.72.109.20-1546970734525:blk_1073741892_1068, duration(ns): 3482566
2019-01-08 21:01:51,983 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1717489377-132.72.109.20-1546970734525:blk_1073741892_1068, type=LAST_IN_PIPELINE terminating
2019-01-08 21:01:55,379 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741869_1045 file /usr/local/hadoop/data/hadoop-data/dn/current/BP-1717489377-132.72.109.20-1546970734525/current/finalized/subdir0/subdir0/blk_1073741869 for deletion
2019-01-08 21:01:55,411 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741870_1046 file /usr/local/hadoop/data/hadoop-data/dn/current/BP-1717489377-132.72.109.20-1546970734525/current/finalized/subdir0/subdir0/blk_1073741870 for deletion
2019-01-08 21:01:55,427 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1717489377-132.72.109.20-1546970734525 blk_1073741869_1045 file /usr/local/hadoop/data/hadoop-data/dn/current/BP-1717489377-132.72.109.20-1546970734525/current/finalized/subdir0/subdir0/blk_1073741869
2019-01-08 21:01:55,427 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1717489377-132.72.109.20-1546970734525 blk_1073741870_1046 file /usr/local/hadoop/data/hadoop-data/dn/current/BP-1717489377-132.72.109.20-1546970734525/current/finalized/subdir0/subdir0/blk_1073741870
2019-01-08 21:02:08,925 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1717489377-132.72.109.20-1546970734525:blk_1073741893_1069 src: /132.72.109.41:46206 dest: /132.72.109.20:50010
2019-01-08 21:02:11,019 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1717489377-132.72.109.20-1546970734525:blk_1073741894_1070 src: /132.72.109.41:46230 dest: /132.72.109.20:50010
2019-01-08 21:02:11,093 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /132.72.109.41:46230, dest: /132.72.109.20:50010, bytes: 8762, op: HDFS_WRITE, cliID: DFSClient_attempt_1546970280036_0003_r_000002_0_-1416815126_1, offset: 0, srvID: 26e32cb0-cb1e-4297-9ba9-d8e02973be0c, blockid: BP-1717489377-132.72.109.20-1546970734525:blk_1073741894_1070, duration(ns): 21210379
2019-01-08 21:02:11,093 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1717489377-132.72.109.20-1546970734525:blk_1073741894_1070, type=LAST_IN_PIPELINE terminating
2019-01-08 21:02:11,646 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1717489377-132.72.109.20-1546970734525:blk_1073741895_1071 src: /132.72.109.41:46238 dest: /132.72.109.20:50010
2019-01-08 21:02:11,696 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1717489377-132.72.109.20-1546970734525:blk_1073741896_1072 src: /132.72.109.41:46240 dest: /132.72.109.20:50010
2019-01-08 21:02:11,728 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /132.72.109.41:46238, dest: /132.72.109.20:50010, bytes: 8762, op: HDFS_WRITE, cliID: DFSClient_attempt_1546970280036_0003_r_000004_0_-1115698403_1, offset: 0, srvID: 26e32cb0-cb1e-4297-9ba9-d8e02973be0c, blockid: BP-1717489377-132.72.109.20-1546970734525:blk_1073741895_1071, duration(ns): 58443116
2019-01-08 21:02:11,728 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1717489377-132.72.109.20-1546970734525:blk_1073741895_1071, type=LAST_IN_PIPELINE terminating
2019-01-08 21:02:11,831 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1717489377-132.72.109.20-1546970734525:blk_1073741897_1073 src: /132.72.109.41:46242 dest: /132.72.109.20:50010
2019-01-08 21:02:11,849 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /132.72.109.41:46240, dest: /132.72.109.20:50010, bytes: 8758, op: HDFS_WRITE, cliID: DFSClient_attempt_1546970280036_0003_r_000006_0_-529298767_1, offset: 0, srvID: 26e32cb0-cb1e-4297-9ba9-d8e02973be0c, blockid: BP-1717489377-132.72.109.20-1546970734525:blk_1073741896_1072, duration(ns): 130427550
2019-01-08 21:02:11,849 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1717489377-132.72.109.20-1546970734525:blk_1073741896_1072, type=LAST_IN_PIPELINE terminating
2019-01-08 21:02:11,936 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /132.72.109.41:46242, dest: /132.72.109.20:50010, bytes: 8765, op: HDFS_WRITE, cliID: DFSClient_attempt_1546970280036_0003_r_000008_0_1132863081_1, offset: 0, srvID: 26e32cb0-cb1e-4297-9ba9-d8e02973be0c, blockid: BP-1717489377-132.72.109.20-1546970734525:blk_1073741897_1073, duration(ns): 99547645
2019-01-08 21:02:11,937 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1717489377-132.72.109.20-1546970734525:blk_1073741897_1073, type=LAST_IN_PIPELINE terminating
2019-01-08 21:02:12,378 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1717489377-132.72.109.20-1546970734525:blk_1073741898_1074 src: /132.72.109.41:46246 dest: /132.72.109.20:50010
2019-01-08 21:02:12,502 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /132.72.109.41:46246, dest: /132.72.109.20:50010, bytes: 8759, op: HDFS_WRITE, cliID: DFSClient_attempt_1546970280036_0003_r_000000_0_1635176432_1, offset: 0, srvID: 26e32cb0-cb1e-4297-9ba9-d8e02973be0c, blockid: BP-1717489377-132.72.109.20-1546970734525:blk_1073741898_1074, duration(ns): 121683351
2019-01-08 21:02:12,502 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1717489377-132.72.109.20-1546970734525:blk_1073741898_1074, type=LAST_IN_PIPELINE terminating
2019-01-08 21:02:14,192 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1717489377-132.72.109.20-1546970734525:blk_1073741900_1076 src: /132.72.109.20:42250 dest: /132.72.109.20:50010
2019-01-08 21:02:14,193 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1717489377-132.72.109.20-1546970734525:blk_1073741902_1078 src: /132.72.109.20:42252 dest: /132.72.109.20:50010
2019-01-08 21:02:14,195 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1717489377-132.72.109.20-1546970734525:blk_1073741899_1075 src: /132.72.109.20:42248 dest: /132.72.109.20:50010
2019-01-08 21:02:14,199 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1717489377-132.72.109.20-1546970734525:blk_1073741901_1077 src: /132.72.109.20:42246 dest: /132.72.109.20:50010
2019-01-08 21:02:14,325 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /132.72.109.20:42252, dest: /132.72.109.20:50010, bytes: 8757, op: HDFS_WRITE, cliID: DFSClient_attempt_1546970280036_0003_r_000005_0_1030702452_1, offset: 0, srvID: 26e32cb0-cb1e-4297-9ba9-d8e02973be0c, blockid: BP-1717489377-132.72.109.20-1546970734525:blk_1073741902_1078, duration(ns): 117131515
2019-01-08 21:02:14,325 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1717489377-132.72.109.20-1546970734525:blk_1073741902_1078, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[132.72.109.41:50010] terminating
2019-01-08 21:02:14,326 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /132.72.109.20:42250, dest: /132.72.109.20:50010, bytes: 8761, op: HDFS_WRITE, cliID: DFSClient_attempt_1546970280036_0003_r_000007_0_1096948872_1, offset: 0, srvID: 26e32cb0-cb1e-4297-9ba9-d8e02973be0c, blockid: BP-1717489377-132.72.109.20-1546970734525:blk_1073741900_1076, duration(ns): 122911580
2019-01-08 21:02:14,327 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1717489377-132.72.109.20-1546970734525:blk_1073741900_1076, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[132.72.109.41:50010] terminating
2019-01-08 21:02:14,332 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /132.72.109.20:42248, dest: /132.72.109.20:50010, bytes: 8761, op: HDFS_WRITE, cliID: DFSClient_attempt_1546970280036_0003_r_000003_0_1414071523_1, offset: 0, srvID: 26e32cb0-cb1e-4297-9ba9-d8e02973be0c, blockid: BP-1717489377-132.72.109.20-1546970734525:blk_1073741899_1075, duration(ns): 119682119
2019-01-08 21:02:14,332 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1717489377-132.72.109.20-1546970734525:blk_1073741899_1075, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[132.72.109.41:50010] terminating
2019-01-08 21:02:14,356 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /132.72.109.20:42246, dest: /132.72.109.20:50010, bytes: 8758, op: HDFS_WRITE, cliID: DFSClient_attempt_1546970280036_0003_r_000001_0_658085211_1, offset: 0, srvID: 26e32cb0-cb1e-4297-9ba9-d8e02973be0c, blockid: BP-1717489377-132.72.109.20-1546970734525:blk_1073741901_1077, duration(ns): 143930593
2019-01-08 21:02:14,356 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1717489377-132.72.109.20-1546970734525:blk_1073741901_1077, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[132.72.109.41:50010] terminating
2019-01-08 21:02:15,531 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /132.72.109.41:46206, dest: /132.72.109.20:50010, bytes: 95145, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1302788802_1, offset: 0, srvID: 26e32cb0-cb1e-4297-9ba9-d8e02973be0c, blockid: BP-1717489377-132.72.109.20-1546970734525:blk_1073741893_1069, duration(ns): 6587864910
2019-01-08 21:02:15,531 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1717489377-132.72.109.20-1546970734525:blk_1073741893_1069, type=LAST_IN_PIPELINE terminating
2019-01-08 21:02:15,673 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1717489377-132.72.109.20-1546970734525:blk_1073741903_1079 src: /132.72.109.41:46250 dest: /132.72.109.20:50010
2019-01-08 21:02:15,683 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /132.72.109.41:46250, dest: /132.72.109.20:50010, bytes: 358, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1302788802_1, offset: 0, srvID: 26e32cb0-cb1e-4297-9ba9-d8e02973be0c, blockid: BP-1717489377-132.72.109.20-1546970734525:blk_1073741903_1079, duration(ns): 1716280
2019-01-08 21:02:15,683 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1717489377-132.72.109.20-1546970734525:blk_1073741903_1079, type=LAST_IN_PIPELINE terminating
2019-01-08 21:02:16,282 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1717489377-132.72.109.20-1546970734525:blk_1073741904_1080 src: /132.72.109.41:46256 dest: /132.72.109.20:50010
2019-01-08 21:02:16,299 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /132.72.109.41:46256, dest: /132.72.109.20:50010, bytes: 95145, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1302788802_1, offset: 0, srvID: 26e32cb0-cb1e-4297-9ba9-d8e02973be0c, blockid: BP-1717489377-132.72.109.20-1546970734525:blk_1073741904_1080, duration(ns): 13888498
2019-01-08 21:02:16,299 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1717489377-132.72.109.20-1546970734525:blk_1073741904_1080, type=LAST_IN_PIPELINE terminating
2019-01-08 21:02:16,406 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1717489377-132.72.109.20-1546970734525:blk_1073741905_1081 src: /132.72.109.41:46260 dest: /132.72.109.20:50010
2019-01-08 21:02:16,439 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /132.72.109.41:46260, dest: /132.72.109.20:50010, bytes: 195916, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1302788802_1, offset: 0, srvID: 26e32cb0-cb1e-4297-9ba9-d8e02973be0c, blockid: BP-1717489377-132.72.109.20-1546970734525:blk_1073741905_1081, duration(ns): 23464716
2019-01-08 21:02:16,439 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1717489377-132.72.109.20-1546970734525:blk_1073741905_1081, type=LAST_IN_PIPELINE terminating
2019-01-08 21:02:19,235 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1717489377-132.72.109.20-1546970734525:blk_1073741906_1082 src: /132.72.109.20:42266 dest: /132.72.109.20:50010
2019-01-08 21:02:22,381 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741888_1064 file /usr/local/hadoop/data/hadoop-data/dn/current/BP-1717489377-132.72.109.20-1546970734525/current/finalized/subdir0/subdir0/blk_1073741888 for deletion
2019-01-08 21:02:22,381 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741889_1065 file /usr/local/hadoop/data/hadoop-data/dn/current/BP-1717489377-132.72.109.20-1546970734525/current/finalized/subdir0/subdir0/blk_1073741889 for deletion
2019-01-08 21:02:22,381 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741890_1066 file /usr/local/hadoop/data/hadoop-data/dn/current/BP-1717489377-132.72.109.20-1546970734525/current/finalized/subdir0/subdir0/blk_1073741890 for deletion
2019-01-08 21:02:22,381 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741893_1069 file /usr/local/hadoop/data/hadoop-data/dn/current/BP-1717489377-132.72.109.20-1546970734525/current/finalized/subdir0/subdir0/blk_1073741893 for deletion
2019-01-08 21:02:22,382 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741886_1062 file /usr/local/hadoop/data/hadoop-data/dn/current/BP-1717489377-132.72.109.20-1546970734525/current/finalized/subdir0/subdir0/blk_1073741886 for deletion
2019-01-08 21:02:22,382 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741887_1063 file /usr/local/hadoop/data/hadoop-data/dn/current/BP-1717489377-132.72.109.20-1546970734525/current/finalized/subdir0/subdir0/blk_1073741887 for deletion
2019-01-08 21:02:22,382 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1717489377-132.72.109.20-1546970734525 blk_1073741888_1064 file /usr/local/hadoop/data/hadoop-data/dn/current/BP-1717489377-132.72.109.20-1546970734525/current/finalized/subdir0/subdir0/blk_1073741888
2019-01-08 21:02:22,382 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1717489377-132.72.109.20-1546970734525 blk_1073741889_1065 file /usr/local/hadoop/data/hadoop-data/dn/current/BP-1717489377-132.72.109.20-1546970734525/current/finalized/subdir0/subdir0/blk_1073741889
2019-01-08 21:02:22,382 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1717489377-132.72.109.20-1546970734525 blk_1073741890_1066 file /usr/local/hadoop/data/hadoop-data/dn/current/BP-1717489377-132.72.109.20-1546970734525/current/finalized/subdir0/subdir0/blk_1073741890
2019-01-08 21:02:22,383 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1717489377-132.72.109.20-1546970734525 blk_1073741893_1069 file /usr/local/hadoop/data/hadoop-data/dn/current/BP-1717489377-132.72.109.20-1546970734525/current/finalized/subdir0/subdir0/blk_1073741893
2019-01-08 21:02:22,383 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1717489377-132.72.109.20-1546970734525 blk_1073741886_1062 file /usr/local/hadoop/data/hadoop-data/dn/current/BP-1717489377-132.72.109.20-1546970734525/current/finalized/subdir0/subdir0/blk_1073741886
2019-01-08 21:02:22,383 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1717489377-132.72.109.20-1546970734525 blk_1073741887_1063 file /usr/local/hadoop/data/hadoop-data/dn/current/BP-1717489377-132.72.109.20-1546970734525/current/finalized/subdir0/subdir0/blk_1073741887
2019-01-08 21:02:23,461 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /132.72.109.20:42266, dest: /132.72.109.20:50010, bytes: 49221245, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1050584424_1, offset: 0, srvID: 26e32cb0-cb1e-4297-9ba9-d8e02973be0c, blockid: BP-1717489377-132.72.109.20-1546970734525:blk_1073741906_1082, duration(ns): 4221142367
2019-01-08 21:02:23,461 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1717489377-132.72.109.20-1546970734525:blk_1073741906_1082, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[132.72.109.41:50010] terminating
2019-01-08 21:02:23,541 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1717489377-132.72.109.20-1546970734525:blk_1073741907_1083 src: /132.72.109.20:42272 dest: /132.72.109.20:50010
2019-01-08 21:02:23,550 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /132.72.109.20:42272, dest: /132.72.109.20:50010, bytes: 123, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1050584424_1, offset: 0, srvID: 26e32cb0-cb1e-4297-9ba9-d8e02973be0c, blockid: BP-1717489377-132.72.109.20-1546970734525:blk_1073741907_1083, duration(ns): 3105562
2019-01-08 21:02:23,550 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1717489377-132.72.109.20-1546970734525:blk_1073741907_1083, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[132.72.109.41:50010] terminating
2019-01-08 21:02:23,591 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1717489377-132.72.109.20-1546970734525:blk_1073741908_1084 src: /132.72.109.20:42276 dest: /132.72.109.20:50010
2019-01-08 21:02:23,599 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /132.72.109.20:42276, dest: /132.72.109.20:50010, bytes: 36, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1050584424_1, offset: 0, srvID: 26e32cb0-cb1e-4297-9ba9-d8e02973be0c, blockid: BP-1717489377-132.72.109.20-1546970734525:blk_1073741908_1084, duration(ns): 2706909
2019-01-08 21:02:23,599 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1717489377-132.72.109.20-1546970734525:blk_1073741908_1084, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[132.72.109.41:50010] terminating
2019-01-08 21:02:23,874 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1717489377-132.72.109.20-1546970734525:blk_1073741909_1085 src: /132.72.109.20:42282 dest: /132.72.109.20:50010
2019-01-08 21:02:23,902 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /132.72.109.20:42282, dest: /132.72.109.20:50010, bytes: 92243, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1518398220_224, offset: 0, srvID: 26e32cb0-cb1e-4297-9ba9-d8e02973be0c, blockid: BP-1717489377-132.72.109.20-1546970734525:blk_1073741909_1085, duration(ns): 19881299
2019-01-08 21:02:23,903 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1717489377-132.72.109.20-1546970734525:blk_1073741909_1085, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[132.72.109.41:50010] terminating
2019-01-08 21:02:23,936 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1717489377-132.72.109.20-1546970734525:blk_1073741910_1086 src: /132.72.109.20:42286 dest: /132.72.109.20:50010
2019-01-08 21:02:23,965 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /132.72.109.20:42286, dest: /132.72.109.20:50010, bytes: 168677, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1050584424_1, offset: 0, srvID: 26e32cb0-cb1e-4297-9ba9-d8e02973be0c, blockid: BP-1717489377-132.72.109.20-1546970734525:blk_1073741910_1086, duration(ns): 16853610
2019-01-08 21:02:23,966 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1717489377-132.72.109.20-1546970734525:blk_1073741910_1086, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[132.72.109.41:50010] terminating
2019-01-08 21:02:24,285 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1717489377-132.72.109.20-1546970734525:blk_1073741911_1087 src: /132.72.109.41:46274 dest: /132.72.109.20:50010
2019-01-08 21:02:24,335 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /132.72.109.41:46274, dest: /132.72.109.20:50010, bytes: 469719, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1918018566_200, offset: 0, srvID: 26e32cb0-cb1e-4297-9ba9-d8e02973be0c, blockid: BP-1717489377-132.72.109.20-1546970734525:blk_1073741911_1087, duration(ns): 46748263
2019-01-08 21:02:24,335 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1717489377-132.72.109.20-1546970734525:blk_1073741911_1087, type=LAST_IN_PIPELINE terminating
2019-01-08 21:02:31,572 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1717489377-132.72.109.20-1546970734525:blk_1073741912_1088 src: /132.72.109.41:46294 dest: /132.72.109.20:50010
2019-01-08 21:02:31,603 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /132.72.109.41:46294, dest: /132.72.109.20:50010, bytes: 195916, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1818472075_1, offset: 0, srvID: 26e32cb0-cb1e-4297-9ba9-d8e02973be0c, blockid: BP-1717489377-132.72.109.20-1546970734525:blk_1073741912_1088, duration(ns): 29706850
2019-01-08 21:02:31,603 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1717489377-132.72.109.20-1546970734525:blk_1073741912_1088, type=LAST_IN_PIPELINE terminating
2019-01-08 21:02:37,395 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1717489377-132.72.109.20-1546970734525:blk_1073741913_1089 src: /132.72.109.41:46320 dest: /132.72.109.20:50010
2019-01-08 21:02:37,496 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /132.72.109.41:46320, dest: /132.72.109.20:50010, bytes: 12, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1818472075_1, offset: 0, srvID: 26e32cb0-cb1e-4297-9ba9-d8e02973be0c, blockid: BP-1717489377-132.72.109.20-1546970734525:blk_1073741913_1089, duration(ns): 94779022
2019-01-08 21:02:37,496 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1717489377-132.72.109.20-1546970734525:blk_1073741913_1089, type=LAST_IN_PIPELINE terminating
2019-01-08 21:02:37,661 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1717489377-132.72.109.20-1546970734525:blk_1073741914_1090 src: /132.72.109.41:46324 dest: /132.72.109.20:50010
2019-01-08 21:02:37,679 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /132.72.109.41:46324, dest: /132.72.109.20:50010, bytes: 92, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1818472075_1, offset: 0, srvID: 26e32cb0-cb1e-4297-9ba9-d8e02973be0c, blockid: BP-1717489377-132.72.109.20-1546970734525:blk_1073741914_1090, duration(ns): 14989546
2019-01-08 21:02:37,679 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1717489377-132.72.109.20-1546970734525:blk_1073741914_1090, type=LAST_IN_PIPELINE terminating
2019-01-08 21:02:43,382 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741891_1067 file /usr/local/hadoop/data/hadoop-data/dn/current/BP-1717489377-132.72.109.20-1546970734525/current/finalized/subdir0/subdir0/blk_1073741891 for deletion
2019-01-08 21:02:43,382 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741892_1068 file /usr/local/hadoop/data/hadoop-data/dn/current/BP-1717489377-132.72.109.20-1546970734525/current/finalized/subdir0/subdir0/blk_1073741892 for deletion
2019-01-08 21:02:43,397 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1717489377-132.72.109.20-1546970734525 blk_1073741891_1067 file /usr/local/hadoop/data/hadoop-data/dn/current/BP-1717489377-132.72.109.20-1546970734525/current/finalized/subdir0/subdir0/blk_1073741891
2019-01-08 21:02:43,397 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1717489377-132.72.109.20-1546970734525 blk_1073741892_1068 file /usr/local/hadoop/data/hadoop-data/dn/current/BP-1717489377-132.72.109.20-1546970734525/current/finalized/subdir0/subdir0/blk_1073741892
2019-01-08 21:02:54,691 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1717489377-132.72.109.20-1546970734525:blk_1073741915_1091 src: /132.72.109.41:46352 dest: /132.72.109.20:50010
2019-01-08 21:02:57,091 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1717489377-132.72.109.20-1546970734525:blk_1073741916_1092 src: /132.72.109.41:46376 dest: /132.72.109.20:50010
2019-01-08 21:02:57,145 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /132.72.109.41:46376, dest: /132.72.109.20:50010, bytes: 8762, op: HDFS_WRITE, cliID: DFSClient_attempt_1546970280036_0004_r_000004_0_-217882537_1, offset: 0, srvID: 26e32cb0-cb1e-4297-9ba9-d8e02973be0c, blockid: BP-1717489377-132.72.109.20-1546970734525:blk_1073741916_1092, duration(ns): 35403874
2019-01-08 21:02:57,145 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1717489377-132.72.109.20-1546970734525:blk_1073741916_1092, type=LAST_IN_PIPELINE terminating
2019-01-08 21:02:57,157 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1717489377-132.72.109.20-1546970734525:blk_1073741917_1093 src: /132.72.109.41:46378 dest: /132.72.109.20:50010
2019-01-08 21:02:57,237 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /132.72.109.41:46378, dest: /132.72.109.20:50010, bytes: 8759, op: HDFS_WRITE, cliID: DFSClient_attempt_1546970280036_0004_r_000000_0_-1931187121_1, offset: 0, srvID: 26e32cb0-cb1e-4297-9ba9-d8e02973be0c, blockid: BP-1717489377-132.72.109.20-1546970734525:blk_1073741917_1093, duration(ns): 61029339
2019-01-08 21:02:57,237 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1717489377-132.72.109.20-1546970734525:blk_1073741917_1093, type=LAST_IN_PIPELINE terminating
2019-01-08 21:02:57,716 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1717489377-132.72.109.20-1546970734525:blk_1073741918_1094 src: /132.72.109.41:46386 dest: /132.72.109.20:50010
2019-01-08 21:02:57,721 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1717489377-132.72.109.20-1546970734525:blk_1073741919_1095 src: /132.72.109.20:42332 dest: /132.72.109.20:50010
2019-01-08 21:02:57,782 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /132.72.109.41:46386, dest: /132.72.109.20:50010, bytes: 8758, op: HDFS_WRITE, cliID: DFSClient_attempt_1546970280036_0004_r_000006_0_-621589973_1, offset: 0, srvID: 26e32cb0-cb1e-4297-9ba9-d8e02973be0c, blockid: BP-1717489377-132.72.109.20-1546970734525:blk_1073741918_1094, duration(ns): 44614403
2019-01-08 21:02:57,782 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1717489377-132.72.109.20-1546970734525:blk_1073741918_1094, type=LAST_IN_PIPELINE terminating
2019-01-08 21:02:57,783 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1717489377-132.72.109.20-1546970734525:blk_1073741920_1096 src: /132.72.109.41:46388 dest: /132.72.109.20:50010
2019-01-08 21:02:57,827 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /132.72.109.20:42332, dest: /132.72.109.20:50010, bytes: 8757, op: HDFS_WRITE, cliID: DFSClient_attempt_1546970280036_0004_r_000005_0_835518937_1, offset: 0, srvID: 26e32cb0-cb1e-4297-9ba9-d8e02973be0c, blockid: BP-1717489377-132.72.109.20-1546970734525:blk_1073741919_1095, duration(ns): 71853342
2019-01-08 21:02:57,827 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1717489377-132.72.109.20-1546970734525:blk_1073741919_1095, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[132.72.109.41:50010] terminating
2019-01-08 21:02:57,858 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /132.72.109.41:46388, dest: /132.72.109.20:50010, bytes: 8762, op: HDFS_WRITE, cliID: DFSClient_attempt_1546970280036_0004_r_000002_0_-1541001874_1, offset: 0, srvID: 26e32cb0-cb1e-4297-9ba9-d8e02973be0c, blockid: BP-1717489377-132.72.109.20-1546970734525:blk_1073741920_1096, duration(ns): 56303319
2019-01-08 21:02:57,858 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1717489377-132.72.109.20-1546970734525:blk_1073741920_1096, type=LAST_IN_PIPELINE terminating
2019-01-08 21:02:57,978 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1717489377-132.72.109.20-1546970734525:blk_1073741921_1097 src: /132.72.109.20:42334 dest: /132.72.109.20:50010
2019-01-08 21:02:58,030 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1717489377-132.72.109.20-1546970734525:blk_1073741922_1098 src: /132.72.109.20:42338 dest: /132.72.109.20:50010
2019-01-08 21:02:58,072 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /132.72.109.20:42334, dest: /132.72.109.20:50010, bytes: 8758, op: HDFS_WRITE, cliID: DFSClient_attempt_1546970280036_0004_r_000001_0_-640980836_1, offset: 0, srvID: 26e32cb0-cb1e-4297-9ba9-d8e02973be0c, blockid: BP-1717489377-132.72.109.20-1546970734525:blk_1073741921_1097, duration(ns): 69186032
2019-01-08 21:02:58,072 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1717489377-132.72.109.20-1546970734525:blk_1073741921_1097, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[132.72.109.41:50010] terminating
2019-01-08 21:02:58,122 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1717489377-132.72.109.20-1546970734525:blk_1073741923_1099 src: /132.72.109.20:42340 dest: /132.72.109.20:50010
2019-01-08 21:02:58,123 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /132.72.109.20:42338, dest: /132.72.109.20:50010, bytes: 8761, op: HDFS_WRITE, cliID: DFSClient_attempt_1546970280036_0004_r_000007_0_1737433741_1, offset: 0, srvID: 26e32cb0-cb1e-4297-9ba9-d8e02973be0c, blockid: BP-1717489377-132.72.109.20-1546970734525:blk_1073741922_1098, duration(ns): 66341746
2019-01-08 21:02:58,123 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1717489377-132.72.109.20-1546970734525:blk_1073741922_1098, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[132.72.109.41:50010] terminating
2019-01-08 21:02:58,223 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /132.72.109.20:42340, dest: /132.72.109.20:50010, bytes: 8761, op: HDFS_WRITE, cliID: DFSClient_attempt_1546970280036_0004_r_000003_0_2100765111_1, offset: 0, srvID: 26e32cb0-cb1e-4297-9ba9-d8e02973be0c, blockid: BP-1717489377-132.72.109.20-1546970734525:blk_1073741923_1099, duration(ns): 70060794
2019-01-08 21:02:58,223 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1717489377-132.72.109.20-1546970734525:blk_1073741923_1099, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[132.72.109.41:50010] terminating
2019-01-08 21:02:58,533 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1717489377-132.72.109.20-1546970734525:blk_1073741924_1100 src: /132.72.109.41:46392 dest: /132.72.109.20:50010
2019-01-08 21:02:58,593 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /132.72.109.41:46392, dest: /132.72.109.20:50010, bytes: 8765, op: HDFS_WRITE, cliID: DFSClient_attempt_1546970280036_0004_r_000008_0_359820999_1, offset: 0, srvID: 26e32cb0-cb1e-4297-9ba9-d8e02973be0c, blockid: BP-1717489377-132.72.109.20-1546970734525:blk_1073741924_1100, duration(ns): 39004052
2019-01-08 21:02:58,593 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1717489377-132.72.109.20-1546970734525:blk_1073741924_1100, type=LAST_IN_PIPELINE terminating
2019-01-08 21:02:59,065 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /132.72.109.41:46352, dest: /132.72.109.20:50010, bytes: 95161, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1818472075_1, offset: 0, srvID: 26e32cb0-cb1e-4297-9ba9-d8e02973be0c, blockid: BP-1717489377-132.72.109.20-1546970734525:blk_1073741915_1091, duration(ns): 4372696347
2019-01-08 21:02:59,065 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1717489377-132.72.109.20-1546970734525:blk_1073741915_1091, type=LAST_IN_PIPELINE terminating
2019-01-08 21:02:59,113 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1717489377-132.72.109.20-1546970734525:blk_1073741925_1101 src: /132.72.109.41:46396 dest: /132.72.109.20:50010
2019-01-08 21:02:59,125 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /132.72.109.41:46396, dest: /132.72.109.20:50010, bytes: 358, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1818472075_1, offset: 0, srvID: 26e32cb0-cb1e-4297-9ba9-d8e02973be0c, blockid: BP-1717489377-132.72.109.20-1546970734525:blk_1073741925_1101, duration(ns): 5638706
2019-01-08 21:02:59,125 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1717489377-132.72.109.20-1546970734525:blk_1073741925_1101, type=LAST_IN_PIPELINE terminating
2019-01-08 21:02:59,194 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1717489377-132.72.109.20-1546970734525:blk_1073741926_1102 src: /132.72.109.41:46402 dest: /132.72.109.20:50010
2019-01-08 21:02:59,208 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /132.72.109.41:46402, dest: /132.72.109.20:50010, bytes: 95161, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1818472075_1, offset: 0, srvID: 26e32cb0-cb1e-4297-9ba9-d8e02973be0c, blockid: BP-1717489377-132.72.109.20-1546970734525:blk_1073741926_1102, duration(ns): 13411412
2019-01-08 21:02:59,209 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1717489377-132.72.109.20-1546970734525:blk_1073741926_1102, type=LAST_IN_PIPELINE terminating
2019-01-08 21:02:59,269 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1717489377-132.72.109.20-1546970734525:blk_1073741927_1103 src: /132.72.109.41:46406 dest: /132.72.109.20:50010
2019-01-08 21:02:59,294 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /132.72.109.41:46406, dest: /132.72.109.20:50010, bytes: 195916, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1818472075_1, offset: 0, srvID: 26e32cb0-cb1e-4297-9ba9-d8e02973be0c, blockid: BP-1717489377-132.72.109.20-1546970734525:blk_1073741927_1103, duration(ns): 23505363
2019-01-08 21:02:59,294 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1717489377-132.72.109.20-1546970734525:blk_1073741927_1103, type=LAST_IN_PIPELINE terminating
2019-01-08 21:03:04,384 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741906_1082 file /usr/local/hadoop/data/hadoop-data/dn/current/BP-1717489377-132.72.109.20-1546970734525/current/finalized/subdir0/subdir0/blk_1073741906 for deletion
2019-01-08 21:03:04,385 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741907_1083 file /usr/local/hadoop/data/hadoop-data/dn/current/BP-1717489377-132.72.109.20-1546970734525/current/finalized/subdir0/subdir0/blk_1073741907 for deletion
2019-01-08 21:03:04,385 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741908_1084 file /usr/local/hadoop/data/hadoop-data/dn/current/BP-1717489377-132.72.109.20-1546970734525/current/finalized/subdir0/subdir0/blk_1073741908 for deletion
2019-01-08 21:03:04,385 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741910_1086 file /usr/local/hadoop/data/hadoop-data/dn/current/BP-1717489377-132.72.109.20-1546970734525/current/finalized/subdir0/subdir0/blk_1073741910 for deletion
2019-01-08 21:03:04,385 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741912_1088 file /usr/local/hadoop/data/hadoop-data/dn/current/BP-1717489377-132.72.109.20-1546970734525/current/finalized/subdir0/subdir0/blk_1073741912 for deletion
2019-01-08 21:03:04,385 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741915_1091 file /usr/local/hadoop/data/hadoop-data/dn/current/BP-1717489377-132.72.109.20-1546970734525/current/finalized/subdir0/subdir0/blk_1073741915 for deletion
2019-01-08 21:03:04,386 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1717489377-132.72.109.20-1546970734525 blk_1073741906_1082 file /usr/local/hadoop/data/hadoop-data/dn/current/BP-1717489377-132.72.109.20-1546970734525/current/finalized/subdir0/subdir0/blk_1073741906
2019-01-08 21:03:04,386 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1717489377-132.72.109.20-1546970734525 blk_1073741907_1083 file /usr/local/hadoop/data/hadoop-data/dn/current/BP-1717489377-132.72.109.20-1546970734525/current/finalized/subdir0/subdir0/blk_1073741907
2019-01-08 21:03:04,386 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1717489377-132.72.109.20-1546970734525 blk_1073741908_1084 file /usr/local/hadoop/data/hadoop-data/dn/current/BP-1717489377-132.72.109.20-1546970734525/current/finalized/subdir0/subdir0/blk_1073741908
2019-01-08 21:03:04,386 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1717489377-132.72.109.20-1546970734525 blk_1073741910_1086 file /usr/local/hadoop/data/hadoop-data/dn/current/BP-1717489377-132.72.109.20-1546970734525/current/finalized/subdir0/subdir0/blk_1073741910
2019-01-08 21:03:04,386 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1717489377-132.72.109.20-1546970734525 blk_1073741912_1088 file /usr/local/hadoop/data/hadoop-data/dn/current/BP-1717489377-132.72.109.20-1546970734525/current/finalized/subdir0/subdir0/blk_1073741912
2019-01-08 21:03:04,386 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1717489377-132.72.109.20-1546970734525 blk_1073741915_1091 file /usr/local/hadoop/data/hadoop-data/dn/current/BP-1717489377-132.72.109.20-1546970734525/current/finalized/subdir0/subdir0/blk_1073741915
2019-01-08 21:03:06,258 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1717489377-132.72.109.20-1546970734525:blk_1073741928_1104 src: /132.72.109.20:42358 dest: /132.72.109.20:50010
2019-01-08 21:03:06,273 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /132.72.109.20:42358, dest: /132.72.109.20:50010, bytes: 92240, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1707087021_267, offset: 0, srvID: 26e32cb0-cb1e-4297-9ba9-d8e02973be0c, blockid: BP-1717489377-132.72.109.20-1546970734525:blk_1073741928_1104, duration(ns): 10758142
2019-01-08 21:03:06,273 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1717489377-132.72.109.20-1546970734525:blk_1073741928_1104, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[132.72.109.41:50010] terminating
2019-01-08 21:03:07,208 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1717489377-132.72.109.20-1546970734525:blk_1073741929_1105 src: /132.72.109.41:46426 dest: /132.72.109.20:50010
2019-01-08 21:03:07,252 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /132.72.109.41:46426, dest: /132.72.109.20:50010, bytes: 460138, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1598481545_273, offset: 0, srvID: 26e32cb0-cb1e-4297-9ba9-d8e02973be0c, blockid: BP-1717489377-132.72.109.20-1546970734525:blk_1073741929_1105, duration(ns): 42380809
2019-01-08 21:03:07,252 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1717489377-132.72.109.20-1546970734525:blk_1073741929_1105, type=LAST_IN_PIPELINE terminating
2019-01-08 21:03:10,384 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741925_1101 file /usr/local/hadoop/data/hadoop-data/dn/current/BP-1717489377-132.72.109.20-1546970734525/current/finalized/subdir0/subdir0/blk_1073741925 for deletion
2019-01-08 21:03:10,385 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741903_1079 file /usr/local/hadoop/data/hadoop-data/dn/current/BP-1717489377-132.72.109.20-1546970734525/current/finalized/subdir0/subdir0/blk_1073741903 for deletion
2019-01-08 21:03:10,385 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1717489377-132.72.109.20-1546970734525 blk_1073741925_1101 file /usr/local/hadoop/data/hadoop-data/dn/current/BP-1717489377-132.72.109.20-1546970734525/current/finalized/subdir0/subdir0/blk_1073741925
2019-01-08 21:03:10,385 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1717489377-132.72.109.20-1546970734525 blk_1073741903_1079 file /usr/local/hadoop/data/hadoop-data/dn/current/BP-1717489377-132.72.109.20-1546970734525/current/finalized/subdir0/subdir0/blk_1073741903
2019-01-08 23:00:23,121 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 5532ms
No GCs detected
2019-01-08 23:21:49,097 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: IOException in offerService
java.io.EOFException: End of File Exception between local host is: "master/132.72.109.20"; destination host is: "master":9000; : java.io.EOFException; For more details see:  http://wiki.apache.org/hadoop/EOFException
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:824)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:788)
	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1497)
	at org.apache.hadoop.ipc.Client.call(Client.java:1439)
	at org.apache.hadoop.ipc.Client.call(Client.java:1349)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy15.sendHeartbeat(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolClientSideTranslatorPB.sendHeartbeat(DatanodeProtocolClientSideTranslatorPB.java:166)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.sendHeartBeat(BPServiceActor.java:514)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.offerService(BPServiceActor.java:645)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:841)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.hadoop.ipc.Client$IpcStreams.readResponse(Client.java:1798)
	at org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1167)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:1063)
2019-01-08 23:21:52,769 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: RECEIVED SIGNAL 15: SIGTERM
2019-01-08 23:21:52,772 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at master/132.72.109.20
************************************************************/

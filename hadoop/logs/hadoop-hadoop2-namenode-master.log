2019-01-08 19:57:39,993 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting NameNode
STARTUP_MSG:   host = master/132.72.109.20
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.9.1
STARTUP_MSG:   classpath = /usr/local/hadoop/etc/hadoop:/usr/local/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-lang-2.6.jar:/usr/local/hadoop/share/hadoop/common/lib/json-smart-1.3.1.jar:/usr/local/hadoop/share/hadoop/common/lib/curator-framework-2.7.1.jar:/usr/local/hadoop/share/hadoop/common/lib/gson-2.2.4.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-net-3.1.jar:/usr/local/hadoop/share/hadoop/common/lib/jetty-sslengine-6.1.26.jar:/usr/local/hadoop/share/hadoop/common/lib/jcip-annotations-1.0-1.jar:/usr/local/hadoop/share/hadoop/common/lib/activation-1.1.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-configuration-1.6.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-digester-1.8.jar:/usr/local/hadoop/share/hadoop/common/lib/xmlenc-0.52.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/usr/local/hadoop/share/hadoop/common/lib/stax-api-1.0-2.jar:/usr/local/hadoop/share/hadoop/common/lib/woodstox-core-5.0.3.jar:/usr/local/hadoop/share/hadoop/common/lib/slf4j-api-1.7.25.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-collections-3.2.2.jar:/usr/local/hadoop/share/hadoop/common/lib/jsch-0.1.54.jar:/usr/local/hadoop/share/hadoop/common/lib/avro-1.7.7.jar:/usr/local/hadoop/share/hadoop/common/lib/netty-3.6.2.Final.jar:/usr/local/hadoop/share/hadoop/common/lib/hadoop-annotations-2.9.1.jar:/usr/local/hadoop/share/hadoop/common/lib/stax2-api-3.1.4.jar:/usr/local/hadoop/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/usr/local/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/usr/local/hadoop/share/hadoop/common/lib/jersey-core-1.9.jar:/usr/local/hadoop/share/hadoop/common/lib/httpcore-4.4.4.jar:/usr/local/hadoop/share/hadoop/common/lib/junit-4.11.jar:/usr/local/hadoop/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/usr/local/hadoop/share/hadoop/common/lib/zookeeper-3.4.6.jar:/usr/local/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-io-2.4.jar:/usr/local/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.25.jar:/usr/local/hadoop/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/local/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/usr/local/hadoop/share/hadoop/common/lib/mockito-all-1.8.5.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-codec-1.4.jar:/usr/local/hadoop/share/hadoop/common/lib/xz-1.0.jar:/usr/local/hadoop/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/usr/local/hadoop/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/usr/local/hadoop/share/hadoop/common/lib/asm-3.2.jar:/usr/local/hadoop/share/hadoop/common/lib/nimbus-jose-jwt-4.41.1.jar:/usr/local/hadoop/share/hadoop/common/lib/jsr305-3.0.0.jar:/usr/local/hadoop/share/hadoop/common/lib/snappy-java-1.0.5.jar:/usr/local/hadoop/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop/share/hadoop/common/lib/curator-client-2.7.1.jar:/usr/local/hadoop/share/hadoop/common/lib/jetty-6.1.26.jar:/usr/local/hadoop/share/hadoop/common/lib/htrace-core4-4.1.0-incubating.jar:/usr/local/hadoop/share/hadoop/common/lib/jets3t-0.9.0.jar:/usr/local/hadoop/share/hadoop/common/lib/guava-11.0.2.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/usr/local/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/usr/local/hadoop/share/hadoop/common/lib/jersey-json-1.9.jar:/usr/local/hadoop/share/hadoop/common/lib/httpclient-4.5.2.jar:/usr/local/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-lang3-3.4.jar:/usr/local/hadoop/share/hadoop/common/lib/hamcrest-core-1.3.jar:/usr/local/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/usr/local/hadoop/share/hadoop/common/lib/jetty-util-6.1.26.jar:/usr/local/hadoop/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-compress-1.4.1.jar:/usr/local/hadoop/share/hadoop/common/lib/servlet-api-2.5.jar:/usr/local/hadoop/share/hadoop/common/lib/hadoop-auth-2.9.1.jar:/usr/local/hadoop/share/hadoop/common/lib/jersey-server-1.9.jar:/usr/local/hadoop/share/hadoop/common/hadoop-common-2.9.1.jar:/usr/local/hadoop/share/hadoop/common/hadoop-common-2.9.1-tests.jar:/usr/local/hadoop/share/hadoop/common/hadoop-nfs-2.9.1.jar:/usr/local/hadoop/share/hadoop/hdfs:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/okio-1.6.0.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jackson-databind-2.7.8.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jackson-annotations-2.7.8.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-io-2.4.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/asm-3.2.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/htrace-core4-4.1.0-incubating.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jackson-core-2.7.8.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/guava-11.0.2.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/hadoop-hdfs-client-2.9.1.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/okhttp-2.7.5.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-native-client-2.9.1.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-2.9.1.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-rbf-2.9.1.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.9.1-tests.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-native-client-2.9.1-tests.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-rbf-2.9.1-tests.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-client-2.9.1.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.9.1.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-client-2.9.1-tests.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jsp-api-2.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-lang-2.6.jar:/usr/local/hadoop/share/hadoop/yarn/lib/json-smart-1.3.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/curator-framework-2.7.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/gson-2.2.4.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-cli-1.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-net-3.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jetty-sslengine-6.1.26.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jcip-annotations-1.0-1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/fst-2.50.jar:/usr/local/hadoop/share/hadoop/yarn/lib/activation-1.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/ehcache-3.3.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-configuration-1.6.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-digester-1.8.jar:/usr/local/hadoop/share/hadoop/yarn/lib/xmlenc-0.52.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-beanutils-1.7.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/json-io-2.5.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/woodstox-core-5.0.3.jar:/usr/local/hadoop/share/hadoop/yarn/lib/mssql-jdbc-6.2.1.jre7.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jsch-0.1.54.jar:/usr/local/hadoop/share/hadoop/yarn/lib/avro-1.7.7.jar:/usr/local/hadoop/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/usr/local/hadoop/share/hadoop/yarn/lib/stax2-api-3.1.4.jar:/usr/local/hadoop/share/hadoop/yarn/lib/guice-3.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/curator-recipes-2.7.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-beanutils-core-1.8.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-core-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/geronimo-jcache_1.0_spec-1.0-alpha-1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/httpcore-4.4.4.jar:/usr/local/hadoop/share/hadoop/yarn/lib/java-util-1.9.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/api-util-1.0.0-M20.jar:/usr/local/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop/share/hadoop/yarn/lib/metrics-core-3.0.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-io-2.4.jar:/usr/local/hadoop/share/hadoop/yarn/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jettison-1.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-codec-1.4.jar:/usr/local/hadoop/share/hadoop/yarn/lib/xz-1.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/api-asn1-api-1.0.0-M20.jar:/usr/local/hadoop/share/hadoop/yarn/lib/apacheds-i18n-2.0.0-M15.jar:/usr/local/hadoop/share/hadoop/yarn/lib/asm-3.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/nimbus-jose-jwt-4.41.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-client-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/snappy-java-1.0.5.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/curator-client-2.7.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jetty-6.1.26.jar:/usr/local/hadoop/share/hadoop/yarn/lib/htrace-core4-4.1.0-incubating.jar:/usr/local/hadoop/share/hadoop/yarn/lib/HikariCP-java7-2.4.12.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jets3t-0.9.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/guava-11.0.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/usr/local/hadoop/share/hadoop/yarn/lib/paranamer-2.3.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-math3-3.1.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-json-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/httpclient-4.5.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-lang3-3.4.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop/share/hadoop/yarn/lib/log4j-1.2.17.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/usr/local/hadoop/share/hadoop/yarn/lib/java-xmlbuilder-0.4.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/servlet-api-2.5.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-server-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.9.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.9.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-router-2.9.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-2.9.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.9.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.9.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-client-2.9.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-api-2.9.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.9.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.9.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.9.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-registry-2.9.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-2.9.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.9.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-2.9.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/avro-1.7.7.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/hadoop-annotations-2.9.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/guice-3.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/javax.inject-1.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/junit-4.11.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/xz-1.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/asm-3.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/snappy-java-1.0.5.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.9.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.9.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.9.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.9.1-tests.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.9.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.9.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.9.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.9.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.9.1.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://github.com/razo7/hadoop-2.9.1-OR2.git -r ef46505203318032151d4f27c5bbb6d9e7cda417; compiled by 'hadoop2' on 2019-01-08T16:41Z
STARTUP_MSG:   java = 1.8.0_181
************************************************************/
2019-01-08 19:57:40,011 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2019-01-08 19:57:40,017 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: createNameNode []
2019-01-08 19:57:40,296 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2019-01-08 19:57:40,636 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2019-01-08 19:57:40,636 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NameNode metrics system started
2019-01-08 19:57:40,673 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: fs.defaultFS is hdfs://master:9000
2019-01-08 19:57:40,677 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Clients are to use master:9000 to access this namenode/service.
2019-01-08 19:57:40,906 INFO org.apache.hadoop.util.JvmPauseMonitor: Starting JVM pause monitor
2019-01-08 19:57:40,917 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for hdfs at: http://0.0.0.0:50070
2019-01-08 19:57:40,996 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2019-01-08 19:57:41,006 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-01-08 19:57:41,100 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.namenode is not defined
2019-01-08 19:57:41,107 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-01-08 19:57:41,113 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2019-01-08 19:57:41,114 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-01-08 19:57:41,114 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-01-08 19:57:41,315 INFO org.apache.hadoop.http.HttpServer2: Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2019-01-08 19:57:41,315 INFO org.apache.hadoop.http.HttpServer2: addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2019-01-08 19:57:41,363 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50070
2019-01-08 19:57:41,363 INFO org.mortbay.log: jetty-6.1.26
2019-01-08 19:57:41,874 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:50070
2019-01-08 19:57:41,928 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one image storage directory (dfs.namenode.name.dir) configured. Beware of data loss due to lack of redundant storage directories!
2019-01-08 19:57:41,928 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one namespace edits storage directory (dfs.namenode.edits.dir) configured. Beware of data loss due to lack of redundant storage directories!
2019-01-08 19:57:41,985 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Edit logging is async:true
2019-01-08 19:57:42,016 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: KeyProvider: null
2019-01-08 19:57:42,017 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair: true
2019-01-08 19:57:42,020 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Detailed lock hold time metrics enabled: false
2019-01-08 19:57:42,026 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = hadoop2 (auth:SIMPLE)
2019-01-08 19:57:42,026 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2019-01-08 19:57:42,026 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2019-01-08 19:57:42,026 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2019-01-08 19:57:42,070 INFO org.apache.hadoop.hdfs.server.common.Util: dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2019-01-08 19:57:42,092 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2019-01-08 19:57:42,092 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2019-01-08 19:57:42,095 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2019-01-08 19:57:42,095 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2019 Jan 08 19:57:42
2019-01-08 19:57:42,097 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2019-01-08 19:57:42,097 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-01-08 19:57:42,103 INFO org.apache.hadoop.util.GSet: 2.0% max memory 889 MB = 17.8 MB
2019-01-08 19:57:42,103 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2019-01-08 19:57:42,123 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2019-01-08 19:57:42,124 WARN org.apache.hadoop.conf.Configuration: No unit for dfs.heartbeat.interval(3) assuming SECONDS
2019-01-08 19:57:42,129 WARN org.apache.hadoop.conf.Configuration: No unit for dfs.namenode.safemode.extension(30000) assuming MILLISECONDS
2019-01-08 19:57:42,130 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManagerSafeMode: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2019-01-08 19:57:42,130 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManagerSafeMode: dfs.namenode.safemode.min.datanodes = 0
2019-01-08 19:57:42,130 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManagerSafeMode: dfs.namenode.safemode.extension = 30000
2019-01-08 19:57:42,130 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 3
2019-01-08 19:57:42,130 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2019-01-08 19:57:42,130 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2019-01-08 19:57:42,130 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2019-01-08 19:57:42,130 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2019-01-08 19:57:42,130 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2019-01-08 19:57:42,130 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2019-01-08 19:57:42,132 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2019-01-08 19:57:42,939 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2019-01-08 19:57:42,939 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-01-08 19:57:42,940 INFO org.apache.hadoop.util.GSet: 1.0% max memory 889 MB = 8.9 MB
2019-01-08 19:57:42,940 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2019-01-08 19:57:42,942 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: ACLs enabled? false
2019-01-08 19:57:42,942 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: XAttrs enabled? true
2019-01-08 19:57:42,942 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occurring more than 10 times
2019-01-08 19:57:42,947 INFO org.apache.hadoop.hdfs.server.namenode.snapshot.SnapshotManager: Loaded config captureOpenFiles: falseskipCaptureAccessTimeOnlyChange: false
2019-01-08 19:57:42,953 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2019-01-08 19:57:42,954 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-01-08 19:57:42,955 INFO org.apache.hadoop.util.GSet: 0.25% max memory 889 MB = 2.2 MB
2019-01-08 19:57:42,955 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2019-01-08 19:57:42,961 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.window.num.buckets = 10
2019-01-08 19:57:42,961 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.num.users = 10
2019-01-08 19:57:42,961 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2019-01-08 19:57:42,969 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache on namenode is enabled
2019-01-08 19:57:42,970 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2019-01-08 19:57:42,972 INFO org.apache.hadoop.util.GSet: Computing capacity for map NameNodeRetryCache
2019-01-08 19:57:42,972 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-01-08 19:57:42,972 INFO org.apache.hadoop.util.GSet: 0.029999999329447746% max memory 889 MB = 273.1 KB
2019-01-08 19:57:42,972 INFO org.apache.hadoop.util.GSet: capacity      = 2^15 = 32768 entries
2019-01-08 19:57:43,050 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /usr/local/hadoop/data/hadoop-data/nn/in_use.lock acquired by nodename 32713@master
2019-01-08 19:57:43,072 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Encountered exception loading fsimage
java.io.IOException: NameNode is not formatted.
	at org.apache.hadoop.hdfs.server.namenode.FSImage.recoverTransitionRead(FSImage.java:236)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.loadFSImage(FSNamesystem.java:1049)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.loadFromDisk(FSNamesystem.java:681)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.loadNamesystem(NameNode.java:666)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:728)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:953)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:932)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1673)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.main(NameNode.java:1741)
2019-01-08 19:57:43,081 INFO org.mortbay.log: Stopped HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:50070
2019-01-08 19:57:43,081 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Stopping NameNode metrics system...
2019-01-08 19:57:43,082 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NameNode metrics system stopped.
2019-01-08 19:57:43,082 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NameNode metrics system shutdown complete.
2019-01-08 19:57:43,082 ERROR org.apache.hadoop.hdfs.server.namenode.NameNode: Failed to start namenode.
java.io.IOException: NameNode is not formatted.
	at org.apache.hadoop.hdfs.server.namenode.FSImage.recoverTransitionRead(FSImage.java:236)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.loadFSImage(FSNamesystem.java:1049)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.loadFromDisk(FSNamesystem.java:681)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.loadNamesystem(NameNode.java:666)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:728)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:953)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:932)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1673)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.main(NameNode.java:1741)
2019-01-08 19:57:43,084 INFO org.apache.hadoop.util.ExitUtil: Exiting with status 1: java.io.IOException: NameNode is not formatted.
2019-01-08 19:57:43,089 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down NameNode at master/132.72.109.20
************************************************************/
2019-01-08 20:05:37,097 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting NameNode
STARTUP_MSG:   host = master/132.72.109.20
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.9.1
STARTUP_MSG:   classpath = /usr/local/hadoop/etc/hadoop:/usr/local/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-lang-2.6.jar:/usr/local/hadoop/share/hadoop/common/lib/json-smart-1.3.1.jar:/usr/local/hadoop/share/hadoop/common/lib/curator-framework-2.7.1.jar:/usr/local/hadoop/share/hadoop/common/lib/gson-2.2.4.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-net-3.1.jar:/usr/local/hadoop/share/hadoop/common/lib/jetty-sslengine-6.1.26.jar:/usr/local/hadoop/share/hadoop/common/lib/jcip-annotations-1.0-1.jar:/usr/local/hadoop/share/hadoop/common/lib/activation-1.1.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-configuration-1.6.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-digester-1.8.jar:/usr/local/hadoop/share/hadoop/common/lib/xmlenc-0.52.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/usr/local/hadoop/share/hadoop/common/lib/stax-api-1.0-2.jar:/usr/local/hadoop/share/hadoop/common/lib/woodstox-core-5.0.3.jar:/usr/local/hadoop/share/hadoop/common/lib/slf4j-api-1.7.25.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-collections-3.2.2.jar:/usr/local/hadoop/share/hadoop/common/lib/jsch-0.1.54.jar:/usr/local/hadoop/share/hadoop/common/lib/avro-1.7.7.jar:/usr/local/hadoop/share/hadoop/common/lib/netty-3.6.2.Final.jar:/usr/local/hadoop/share/hadoop/common/lib/hadoop-annotations-2.9.1.jar:/usr/local/hadoop/share/hadoop/common/lib/stax2-api-3.1.4.jar:/usr/local/hadoop/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/usr/local/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/usr/local/hadoop/share/hadoop/common/lib/jersey-core-1.9.jar:/usr/local/hadoop/share/hadoop/common/lib/httpcore-4.4.4.jar:/usr/local/hadoop/share/hadoop/common/lib/junit-4.11.jar:/usr/local/hadoop/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/usr/local/hadoop/share/hadoop/common/lib/zookeeper-3.4.6.jar:/usr/local/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-io-2.4.jar:/usr/local/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.25.jar:/usr/local/hadoop/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/local/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/usr/local/hadoop/share/hadoop/common/lib/mockito-all-1.8.5.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-codec-1.4.jar:/usr/local/hadoop/share/hadoop/common/lib/xz-1.0.jar:/usr/local/hadoop/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/usr/local/hadoop/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/usr/local/hadoop/share/hadoop/common/lib/asm-3.2.jar:/usr/local/hadoop/share/hadoop/common/lib/nimbus-jose-jwt-4.41.1.jar:/usr/local/hadoop/share/hadoop/common/lib/jsr305-3.0.0.jar:/usr/local/hadoop/share/hadoop/common/lib/snappy-java-1.0.5.jar:/usr/local/hadoop/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop/share/hadoop/common/lib/curator-client-2.7.1.jar:/usr/local/hadoop/share/hadoop/common/lib/jetty-6.1.26.jar:/usr/local/hadoop/share/hadoop/common/lib/htrace-core4-4.1.0-incubating.jar:/usr/local/hadoop/share/hadoop/common/lib/jets3t-0.9.0.jar:/usr/local/hadoop/share/hadoop/common/lib/guava-11.0.2.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/usr/local/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/usr/local/hadoop/share/hadoop/common/lib/jersey-json-1.9.jar:/usr/local/hadoop/share/hadoop/common/lib/httpclient-4.5.2.jar:/usr/local/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-lang3-3.4.jar:/usr/local/hadoop/share/hadoop/common/lib/hamcrest-core-1.3.jar:/usr/local/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/usr/local/hadoop/share/hadoop/common/lib/jetty-util-6.1.26.jar:/usr/local/hadoop/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-compress-1.4.1.jar:/usr/local/hadoop/share/hadoop/common/lib/servlet-api-2.5.jar:/usr/local/hadoop/share/hadoop/common/lib/hadoop-auth-2.9.1.jar:/usr/local/hadoop/share/hadoop/common/lib/jersey-server-1.9.jar:/usr/local/hadoop/share/hadoop/common/hadoop-common-2.9.1.jar:/usr/local/hadoop/share/hadoop/common/hadoop-common-2.9.1-tests.jar:/usr/local/hadoop/share/hadoop/common/hadoop-nfs-2.9.1.jar:/usr/local/hadoop/share/hadoop/hdfs:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/okio-1.6.0.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jackson-databind-2.7.8.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jackson-annotations-2.7.8.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-io-2.4.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/asm-3.2.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/htrace-core4-4.1.0-incubating.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jackson-core-2.7.8.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/guava-11.0.2.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/hadoop-hdfs-client-2.9.1.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/okhttp-2.7.5.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-native-client-2.9.1.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-2.9.1.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-rbf-2.9.1.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.9.1-tests.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-native-client-2.9.1-tests.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-rbf-2.9.1-tests.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-client-2.9.1.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.9.1.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-client-2.9.1-tests.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jsp-api-2.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-lang-2.6.jar:/usr/local/hadoop/share/hadoop/yarn/lib/json-smart-1.3.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/curator-framework-2.7.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/gson-2.2.4.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-cli-1.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-net-3.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jetty-sslengine-6.1.26.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jcip-annotations-1.0-1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/fst-2.50.jar:/usr/local/hadoop/share/hadoop/yarn/lib/activation-1.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/ehcache-3.3.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-configuration-1.6.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-digester-1.8.jar:/usr/local/hadoop/share/hadoop/yarn/lib/xmlenc-0.52.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-beanutils-1.7.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/json-io-2.5.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/woodstox-core-5.0.3.jar:/usr/local/hadoop/share/hadoop/yarn/lib/mssql-jdbc-6.2.1.jre7.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jsch-0.1.54.jar:/usr/local/hadoop/share/hadoop/yarn/lib/avro-1.7.7.jar:/usr/local/hadoop/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/usr/local/hadoop/share/hadoop/yarn/lib/stax2-api-3.1.4.jar:/usr/local/hadoop/share/hadoop/yarn/lib/guice-3.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/curator-recipes-2.7.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-beanutils-core-1.8.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-core-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/geronimo-jcache_1.0_spec-1.0-alpha-1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/httpcore-4.4.4.jar:/usr/local/hadoop/share/hadoop/yarn/lib/java-util-1.9.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/api-util-1.0.0-M20.jar:/usr/local/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop/share/hadoop/yarn/lib/metrics-core-3.0.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-io-2.4.jar:/usr/local/hadoop/share/hadoop/yarn/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jettison-1.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-codec-1.4.jar:/usr/local/hadoop/share/hadoop/yarn/lib/xz-1.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/api-asn1-api-1.0.0-M20.jar:/usr/local/hadoop/share/hadoop/yarn/lib/apacheds-i18n-2.0.0-M15.jar:/usr/local/hadoop/share/hadoop/yarn/lib/asm-3.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/nimbus-jose-jwt-4.41.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-client-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/snappy-java-1.0.5.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/curator-client-2.7.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jetty-6.1.26.jar:/usr/local/hadoop/share/hadoop/yarn/lib/htrace-core4-4.1.0-incubating.jar:/usr/local/hadoop/share/hadoop/yarn/lib/HikariCP-java7-2.4.12.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jets3t-0.9.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/guava-11.0.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/usr/local/hadoop/share/hadoop/yarn/lib/paranamer-2.3.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-math3-3.1.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-json-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/httpclient-4.5.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-lang3-3.4.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop/share/hadoop/yarn/lib/log4j-1.2.17.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/usr/local/hadoop/share/hadoop/yarn/lib/java-xmlbuilder-0.4.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/servlet-api-2.5.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-server-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.9.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.9.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-router-2.9.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-2.9.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.9.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.9.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-client-2.9.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-api-2.9.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.9.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.9.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.9.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-registry-2.9.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-2.9.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.9.1.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-2.9.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/avro-1.7.7.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/hadoop-annotations-2.9.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/guice-3.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/javax.inject-1.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/junit-4.11.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/xz-1.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/asm-3.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/snappy-java-1.0.5.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.9.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.9.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.9.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.9.1-tests.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.9.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.9.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.9.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.9.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.9.1.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://github.com/razo7/hadoop-2.9.1-OR2.git -r ef46505203318032151d4f27c5bbb6d9e7cda417; compiled by 'hadoop2' on 2019-01-08T16:41Z
STARTUP_MSG:   java = 1.8.0_181
************************************************************/
2019-01-08 20:05:37,121 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2019-01-08 20:05:37,126 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: createNameNode []
2019-01-08 20:05:37,379 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2019-01-08 20:05:37,524 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2019-01-08 20:05:37,524 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NameNode metrics system started
2019-01-08 20:05:37,554 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: fs.defaultFS is hdfs://master:9000
2019-01-08 20:05:37,558 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Clients are to use master:9000 to access this namenode/service.
2019-01-08 20:05:37,765 INFO org.apache.hadoop.util.JvmPauseMonitor: Starting JVM pause monitor
2019-01-08 20:05:37,776 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for hdfs at: http://0.0.0.0:50070
2019-01-08 20:05:37,846 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2019-01-08 20:05:37,858 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-01-08 20:05:37,876 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.namenode is not defined
2019-01-08 20:05:37,882 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-01-08 20:05:37,885 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2019-01-08 20:05:37,885 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-01-08 20:05:37,885 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-01-08 20:05:38,053 INFO org.apache.hadoop.http.HttpServer2: Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2019-01-08 20:05:38,053 INFO org.apache.hadoop.http.HttpServer2: addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2019-01-08 20:05:38,071 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50070
2019-01-08 20:05:38,071 INFO org.mortbay.log: jetty-6.1.26
2019-01-08 20:05:38,362 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:50070
2019-01-08 20:05:38,401 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one image storage directory (dfs.namenode.name.dir) configured. Beware of data loss due to lack of redundant storage directories!
2019-01-08 20:05:38,401 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one namespace edits storage directory (dfs.namenode.edits.dir) configured. Beware of data loss due to lack of redundant storage directories!
2019-01-08 20:05:38,454 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Edit logging is async:true
2019-01-08 20:05:38,466 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: KeyProvider: null
2019-01-08 20:05:38,467 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair: true
2019-01-08 20:05:38,470 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Detailed lock hold time metrics enabled: false
2019-01-08 20:05:38,476 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = hadoop2 (auth:SIMPLE)
2019-01-08 20:05:38,476 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2019-01-08 20:05:38,477 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2019-01-08 20:05:38,477 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
2019-01-08 20:05:38,512 INFO org.apache.hadoop.hdfs.server.common.Util: dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2019-01-08 20:05:38,536 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2019-01-08 20:05:38,536 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2019-01-08 20:05:38,539 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2019-01-08 20:05:38,539 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2019 Jan 08 20:05:38
2019-01-08 20:05:38,541 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2019-01-08 20:05:38,541 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-01-08 20:05:38,543 INFO org.apache.hadoop.util.GSet: 2.0% max memory 889 MB = 17.8 MB
2019-01-08 20:05:38,543 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2019-01-08 20:05:38,563 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2019-01-08 20:05:38,563 WARN org.apache.hadoop.conf.Configuration: No unit for dfs.heartbeat.interval(3) assuming SECONDS
2019-01-08 20:05:38,568 WARN org.apache.hadoop.conf.Configuration: No unit for dfs.namenode.safemode.extension(30000) assuming MILLISECONDS
2019-01-08 20:05:38,568 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManagerSafeMode: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2019-01-08 20:05:38,568 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManagerSafeMode: dfs.namenode.safemode.min.datanodes = 0
2019-01-08 20:05:38,568 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManagerSafeMode: dfs.namenode.safemode.extension = 30000
2019-01-08 20:05:38,568 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 3
2019-01-08 20:05:38,568 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2019-01-08 20:05:38,568 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2019-01-08 20:05:38,568 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2019-01-08 20:05:38,568 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2019-01-08 20:05:38,568 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2019-01-08 20:05:38,569 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2019-01-08 20:05:38,570 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2019-01-08 20:05:38,933 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2019-01-08 20:05:38,933 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-01-08 20:05:38,933 INFO org.apache.hadoop.util.GSet: 1.0% max memory 889 MB = 8.9 MB
2019-01-08 20:05:38,934 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2019-01-08 20:05:38,936 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: ACLs enabled? false
2019-01-08 20:05:38,936 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: XAttrs enabled? true
2019-01-08 20:05:38,936 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occurring more than 10 times
2019-01-08 20:05:38,940 INFO org.apache.hadoop.hdfs.server.namenode.snapshot.SnapshotManager: Loaded config captureOpenFiles: falseskipCaptureAccessTimeOnlyChange: false
2019-01-08 20:05:38,946 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2019-01-08 20:05:38,946 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-01-08 20:05:38,946 INFO org.apache.hadoop.util.GSet: 0.25% max memory 889 MB = 2.2 MB
2019-01-08 20:05:38,946 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2019-01-08 20:05:38,951 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.window.num.buckets = 10
2019-01-08 20:05:38,951 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.num.users = 10
2019-01-08 20:05:38,951 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2019-01-08 20:05:38,955 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache on namenode is enabled
2019-01-08 20:05:38,955 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2019-01-08 20:05:38,958 INFO org.apache.hadoop.util.GSet: Computing capacity for map NameNodeRetryCache
2019-01-08 20:05:38,958 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2019-01-08 20:05:38,958 INFO org.apache.hadoop.util.GSet: 0.029999999329447746% max memory 889 MB = 273.1 KB
2019-01-08 20:05:38,958 INFO org.apache.hadoop.util.GSet: capacity      = 2^15 = 32768 entries
2019-01-08 20:05:39,004 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /usr/local/hadoop/data/hadoop-data/nn/in_use.lock acquired by nodename 1669@master
2019-01-08 20:05:39,025 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Recovering unfinalized segments in /usr/local/hadoop/data/hadoop-data/nn/current
2019-01-08 20:05:39,025 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: No edit log streams selected.
2019-01-08 20:05:39,026 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Planning to load image: FSImageFile(file=/usr/local/hadoop/data/hadoop-data/nn/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2019-01-08 20:05:39,073 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatPBINode: Loading 1 INodes.
2019-01-08 20:05:39,105 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Loaded FSImage in 0 seconds.
2019-01-08 20:05:39,105 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loaded image for txid 0 from /usr/local/hadoop/data/hadoop-data/nn/current/fsimage_0000000000000000000
2019-01-08 20:05:39,111 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2019-01-08 20:05:39,111 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 1
2019-01-08 20:05:39,346 INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 0 entries 0 lookups
2019-01-08 20:05:39,346 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Finished loading FSImage in 385 msecs
2019-01-08 20:05:39,556 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: RPC server is binding to master:9000
2019-01-08 20:05:39,565 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2019-01-08 20:05:39,578 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 9000
2019-01-08 20:05:39,646 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Registered FSNamesystemState MBean
2019-01-08 20:05:39,694 INFO org.apache.hadoop.hdfs.server.namenode.LeaseManager: Number of blocks under construction: 0
2019-01-08 20:05:39,704 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: initializing replication queues
2019-01-08 20:05:39,704 INFO org.apache.hadoop.hdfs.StateChange: STATE* Leaving safe mode after 0 secs
2019-01-08 20:05:39,705 INFO org.apache.hadoop.hdfs.StateChange: STATE* Network topology has 0 racks and 0 datanodes
2019-01-08 20:05:39,705 INFO org.apache.hadoop.hdfs.StateChange: STATE* UnderReplicatedBlocks has 0 blocks
2019-01-08 20:05:39,728 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Total number of blocks            = 0
2019-01-08 20:05:39,728 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of invalid blocks          = 0
2019-01-08 20:05:39,728 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of under-replicated blocks = 0
2019-01-08 20:05:39,728 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of  over-replicated blocks = 0
2019-01-08 20:05:39,728 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of blocks being written    = 0
2019-01-08 20:05:39,728 INFO org.apache.hadoop.hdfs.StateChange: STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 24 msec
2019-01-08 20:05:39,743 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2019-01-08 20:05:39,745 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 9000: starting
2019-01-08 20:05:39,747 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: NameNode RPC up at: master/132.72.109.20:9000
2019-01-08 20:05:39,756 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Starting services required for active state
2019-01-08 20:05:39,756 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Initializing quota with 4 thread(s)
2019-01-08 20:05:39,761 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Quota initialization completed in 5 milliseconds
name space=1
storage space=0
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0
2019-01-08 20:05:39,783 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Starting CacheReplicationMonitor with interval 30000 milliseconds
2019-01-08 20:05:52,082 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 132.72.109.20
2019-01-08 20:05:52,082 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2019-01-08 20:05:52,082 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 1, 1
2019-01-08 20:05:52,096 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 1 Number of transactions batched in Syncs: 0 Number of syncs: 3 SyncTimes(ms): 71 
2019-01-08 20:05:52,098 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /usr/local/hadoop/data/hadoop-data/nn/current/edits_inprogress_0000000000000000001 -> /usr/local/hadoop/data/hadoop-data/nn/current/edits_0000000000000000001-0000000000000000002
2019-01-08 20:05:52,123 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 3
2019-01-08 20:05:52,674 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Sending fileName: /usr/local/hadoop/data/hadoop-data/nn/current/fsimage_0000000000000000000, fileSize: 323. Sent total: 323 bytes. Size of last segment intended to send: -1 bytes.
2019-01-08 20:05:52,765 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Sending fileName: /usr/local/hadoop/data/hadoop-data/nn/current/edits_0000000000000000001-0000000000000000002, fileSize: 42. Sent total: 42 bytes. Size of last segment intended to send: -1 bytes.
2019-01-08 20:05:53,103 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Combined time for fsimage download and fsync to all disks took 0.00s. The fsimage download took 0.00s at 0.00 KB/s. Synchronous (fsync) write to disk of /usr/local/hadoop/data/hadoop-data/nn/current/fsimage.ckpt_0000000000000000002 took 0.00s.
2019-01-08 20:05:53,103 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000000002 size 323 bytes.
2019-01-08 20:05:53,130 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 0
2019-01-08 20:07:49,231 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(132.72.109.20:50010, datanodeUuid=26e32cb0-cb1e-4297-9ba9-d8e02973be0c, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-57;cid=CID-134fef86-d39e-4fb6-b146-de33ed769859;nsid=225363434;c=1546970734525) storage 26e32cb0-cb1e-4297-9ba9-d8e02973be0c
2019-01-08 20:07:49,233 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/132.72.109.20:50010
2019-01-08 20:07:49,234 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockReportLeaseManager: Registered DN 26e32cb0-cb1e-4297-9ba9-d8e02973be0c (132.72.109.20:50010).
2019-01-08 20:07:49,305 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Adding new storage ID DS-bc012d25-5f83-4272-9ceb-fcbd8886bd57 for DN 132.72.109.20:50010
2019-01-08 20:07:49,352 INFO BlockStateChange: BLOCK* processReport 0x46d6a38a58189d9c: Processing first storage report for DS-bc012d25-5f83-4272-9ceb-fcbd8886bd57 from datanode 26e32cb0-cb1e-4297-9ba9-d8e02973be0c
2019-01-08 20:07:49,354 INFO BlockStateChange: BLOCK* processReport 0x46d6a38a58189d9c: from storage DS-bc012d25-5f83-4272-9ceb-fcbd8886bd57 node DatanodeRegistration(132.72.109.20:50010, datanodeUuid=26e32cb0-cb1e-4297-9ba9-d8e02973be0c, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-57;cid=CID-134fef86-d39e-4fb6-b146-de33ed769859;nsid=225363434;c=1546970734525), blocks: 0, hasStaleStorage: false, processing time: 2 msecs, invalidatedBlocks: 0
2019-01-08 20:09:11,065 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(132.72.109.41:50010, datanodeUuid=cefd8a8c-39cd-47c2-8290-a490be320b11, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-57;cid=CID-134fef86-d39e-4fb6-b146-de33ed769859;nsid=225363434;c=1546970734525) storage cefd8a8c-39cd-47c2-8290-a490be320b11
2019-01-08 20:09:11,065 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/132.72.109.41:50010
2019-01-08 20:09:11,065 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockReportLeaseManager: Registered DN cefd8a8c-39cd-47c2-8290-a490be320b11 (132.72.109.41:50010).
2019-01-08 20:09:11,112 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Adding new storage ID DS-dd543405-56c3-4046-875b-8f2f3c6f8079 for DN 132.72.109.41:50010
2019-01-08 20:09:11,156 INFO BlockStateChange: BLOCK* processReport 0x984137942e1ac32b: Processing first storage report for DS-dd543405-56c3-4046-875b-8f2f3c6f8079 from datanode cefd8a8c-39cd-47c2-8290-a490be320b11
2019-01-08 20:09:11,156 INFO BlockStateChange: BLOCK* processReport 0x984137942e1ac32b: from storage DS-dd543405-56c3-4046-875b-8f2f3c6f8079 node DatanodeRegistration(132.72.109.41:50010, datanodeUuid=cefd8a8c-39cd-47c2-8290-a490be320b11, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-57;cid=CID-134fef86-d39e-4fb6-b146-de33ed769859;nsid=225363434;c=1546970734525), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2019-01-08 20:10:41,110 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 16 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 70 
2019-01-08 20:11:15,914 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741825_1001, replicas=132.72.109.20:50010, 132.72.109.41:50010 for /user/hadoop2/input/input_103_104._COPYING_
2019-01-08 20:11:16,374 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/hadoop2/input/input_103_104._COPYING_ is closed by DFSClient_NONMAPREDUCE_-758753106_1
2019-01-08 20:11:18,768 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741826_1002, replicas=132.72.109.20:50010, 132.72.109.41:50010 for /user/hadoop2/input/input_105_104._COPYING_
2019-01-08 20:11:19,023 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/hadoop2/input/input_105_104._COPYING_ is closed by DFSClient_NONMAPREDUCE_856040948_1
2019-01-08 20:11:21,370 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741827_1003, replicas=132.72.109.20:50010, 132.72.109.41:50010 for /user/hadoop2/input/input_5107_104._COPYING_
2019-01-08 20:11:33,139 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741828_1004, replicas=132.72.109.20:50010, 132.72.109.41:50010 for /user/hadoop2/input/input_5107_104._COPYING_
2019-01-08 20:11:44,726 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741829_1005, replicas=132.72.109.20:50010, 132.72.109.41:50010 for /user/hadoop2/input/input_5107_104._COPYING_
2019-01-08 20:11:44,726 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 26 Total time for transactions(ms): 19 Number of transactions batched in Syncs: 6 Number of syncs: 19 SyncTimes(ms): 342 
2019-01-08 20:11:56,300 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741830_1006, replicas=132.72.109.20:50010, 132.72.109.41:50010 for /user/hadoop2/input/input_5107_104._COPYING_
2019-01-08 20:12:07,847 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741831_1007, replicas=132.72.109.20:50010, 132.72.109.41:50010 for /user/hadoop2/input/input_5107_104._COPYING_
2019-01-08 20:12:08,082 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/hadoop2/input/input_5107_104._COPYING_ is closed by DFSClient_NONMAPREDUCE_-174457819_1
2019-01-08 20:12:10,940 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741832_1008, replicas=132.72.109.20:50010, 132.72.109.41:50010 for /user/hadoop2/input/input_107_104._COPYING_
2019-01-08 20:12:20,371 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/hadoop2/input/input_107_104._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1268683057_1
2019-01-08 20:12:22,669 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741833_1009, replicas=132.72.109.20:50010, 132.72.109.41:50010 for /user/hadoop2/input/input_108_104._COPYING_
2019-01-08 20:12:32,089 INFO BlockStateChange: BLOCK* processReport 0x984137942e1ac32c: from storage DS-dd543405-56c3-4046-875b-8f2f3c6f8079 node DatanodeRegistration(132.72.109.41:50010, datanodeUuid=cefd8a8c-39cd-47c2-8290-a490be320b11, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-57;cid=CID-134fef86-d39e-4fb6-b146-de33ed769859;nsid=225363434;c=1546970734525), blocks: 9, hasStaleStorage: false, processing time: 1 msecs, invalidatedBlocks: 0
2019-01-08 20:12:34,412 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741834_1010, replicas=132.72.109.20:50010, 132.72.109.41:50010 for /user/hadoop2/input/input_108_104._COPYING_
2019-01-08 20:12:45,964 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 50 Total time for transactions(ms): 25 Number of transactions batched in Syncs: 16 Number of syncs: 33 SyncTimes(ms): 611 
2019-01-08 20:12:45,964 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741835_1011, replicas=132.72.109.20:50010, 132.72.109.41:50010 for /user/hadoop2/input/input_108_104._COPYING_
2019-01-08 20:12:57,663 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741836_1012, replicas=132.72.109.20:50010, 132.72.109.41:50010 for /user/hadoop2/input/input_108_104._COPYING_
2019-01-08 20:13:09,245 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741837_1013, replicas=132.72.109.20:50010, 132.72.109.41:50010 for /user/hadoop2/input/input_108_104._COPYING_
2019-01-08 20:13:20,814 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741838_1014, replicas=132.72.109.20:50010, 132.72.109.41:50010 for /user/hadoop2/input/input_108_104._COPYING_
2019-01-08 20:13:32,363 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741839_1015, replicas=132.72.109.20:50010, 132.72.109.41:50010 for /user/hadoop2/input/input_108_104._COPYING_
2019-01-08 20:13:43,912 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741840_1016, replicas=132.72.109.20:50010, 132.72.109.41:50010 for /user/hadoop2/input/input_108_104._COPYING_
2019-01-08 20:13:55,486 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741841_1017, replicas=132.72.109.20:50010, 132.72.109.41:50010 for /user/hadoop2/input/input_108_104._COPYING_
2019-01-08 20:13:55,487 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 69 Total time for transactions(ms): 25 Number of transactions batched in Syncs: 22 Number of syncs: 45 SyncTimes(ms): 963 
2019-01-08 20:13:56,371 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/hadoop2/input/input_108_104._COPYING_ is closed by DFSClient_NONMAPREDUCE_240725449_1
2019-01-08 20:14:59,900 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 74 Total time for transactions(ms): 27 Number of transactions batched in Syncs: 24 Number of syncs: 48 SyncTimes(ms): 993 
2019-01-08 20:15:00,569 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741842_1018, replicas=132.72.109.20:50010, 132.72.109.41:50010 for /tmp/hadoop-yarn/staging/hadoop2/.staging/job_1546970280036_0001/job.jar
2019-01-08 20:15:04,896 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/hadoop2/.staging/job_1546970280036_0001/job.jar is closed by DFSClient_NONMAPREDUCE_-587237367_1
2019-01-08 20:15:04,924 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Increasing replication from 3 to 10 for /tmp/hadoop-yarn/staging/hadoop2/.staging/job_1546970280036_0001/job.jar
2019-01-08 20:15:05,167 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Increasing replication from 3 to 10 for /tmp/hadoop-yarn/staging/hadoop2/.staging/job_1546970280036_0001/job.split
2019-01-08 20:15:05,195 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741843_1019, replicas=132.72.109.20:50010, 132.72.109.41:50010 for /tmp/hadoop-yarn/staging/hadoop2/.staging/job_1546970280036_0001/job.split
2019-01-08 20:15:05,226 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/hadoop2/.staging/job_1546970280036_0001/job.split is closed by DFSClient_NONMAPREDUCE_-587237367_1
2019-01-08 20:15:05,262 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741844_1020, replicas=132.72.109.20:50010, 132.72.109.41:50010 for /tmp/hadoop-yarn/staging/hadoop2/.staging/job_1546970280036_0001/job.splitmetainfo
2019-01-08 20:15:05,292 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/hadoop2/.staging/job_1546970280036_0001/job.splitmetainfo is closed by DFSClient_NONMAPREDUCE_-587237367_1
2019-01-08 20:15:05,588 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741845_1021, replicas=132.72.109.20:50010, 132.72.109.41:50010 for /tmp/hadoop-yarn/staging/hadoop2/.staging/job_1546970280036_0001/job.xml
2019-01-08 20:15:05,642 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/hadoop2/.staging/job_1546970280036_0001/job.xml is closed by DFSClient_NONMAPREDUCE_-587237367_1
2019-01-08 20:15:16,786 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741846_1022, replicas=132.72.109.41:50010, 132.72.109.20:50010 for /tmp/hadoop-yarn/staging/hadoop2/.staging/job_1546970280036_0001/job_1546970280036_0001_1_conf.xml
2019-01-08 20:15:16,928 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/hadoop2/.staging/job_1546970280036_0001/job_1546970280036_0001_1_conf.xml is closed by DFSClient_NONMAPREDUCE_147205118_1
2019-01-08 20:15:23,522 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741847_1023, replicas=132.72.109.41:50010, 132.72.109.20:50010 for /mappersLocations
2019-01-08 20:15:23,643 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /mappersLocations is closed by DFSClient_NONMAPREDUCE_147205118_1
2019-01-08 20:15:23,724 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741848_1024, replicas=132.72.109.41:50010, 132.72.109.20:50010 for /reducersLocations
2019-01-08 20:15:23,820 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /reducersLocations is closed by DFSClient_NONMAPREDUCE_147205118_1
2019-01-08 20:16:09,465 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741849_1025, replicas=132.72.109.41:50010, 132.72.109.20:50010 for /tmp/hadoop-yarn/staging/hadoop2/.staging/job_1546970280036_0001/job_1546970280036_0001_1.jhist
2019-01-08 20:16:09,465 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 140 Total time for transactions(ms): 30 Number of transactions batched in Syncs: 42 Number of syncs: 97 SyncTimes(ms): 1749 
2019-01-08 20:16:10,385 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* fsync: /tmp/hadoop-yarn/staging/hadoop2/.staging/job_1546970280036_0001/job_1546970280036_0001_1.jhist for DFSClient_NONMAPREDUCE_147205118_1
2019-01-08 20:16:15,166 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741850_1026, replicas=132.72.109.41:50010, 132.72.109.20:50010 for /user/hadoop2/output/input_105_104-9-1/0/_temporary/1/_temporary/attempt_1546970280036_0001_r_000005_0/part-r-00005
2019-01-08 20:16:15,608 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741851_1027, replicas=132.72.109.41:50010, 132.72.109.20:50010 for /user/hadoop2/output/input_105_104-9-1/0/_temporary/1/_temporary/attempt_1546970280036_0001_r_000001_0/part-r-00001
2019-01-08 20:16:15,642 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741852_1028, replicas=132.72.109.41:50010, 132.72.109.20:50010 for /user/hadoop2/output/input_105_104-9-1/0/_temporary/1/_temporary/attempt_1546970280036_0001_r_000007_0/part-r-00007
2019-01-08 20:16:15,651 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741853_1029, replicas=132.72.109.41:50010, 132.72.109.20:50010 for /user/hadoop2/output/input_105_104-9-1/0/_temporary/1/_temporary/attempt_1546970280036_0001_r_000003_0/part-r-00003
2019-01-08 20:16:15,676 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/hadoop2/output/input_105_104-9-1/0/_temporary/1/_temporary/attempt_1546970280036_0001_r_000005_0/part-r-00005 is closed by DFSClient_attempt_1546970280036_0001_r_000005_0_-737997408_1
2019-01-08 20:16:16,015 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/hadoop2/output/input_105_104-9-1/0/_temporary/1/_temporary/attempt_1546970280036_0001_r_000003_0/part-r-00003 is closed by DFSClient_attempt_1546970280036_0001_r_000003_0_-1889093767_1
2019-01-08 20:16:16,017 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/hadoop2/output/input_105_104-9-1/0/_temporary/1/_temporary/attempt_1546970280036_0001_r_000001_0/part-r-00001 is closed by DFSClient_attempt_1546970280036_0001_r_000001_0_1793457176_1
2019-01-08 20:16:16,033 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/hadoop2/output/input_105_104-9-1/0/_temporary/1/_temporary/attempt_1546970280036_0001_r_000007_0/part-r-00007 is closed by DFSClient_attempt_1546970280036_0001_r_000007_0_-1865144770_1
2019-01-08 20:16:18,081 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741854_1030, replicas=132.72.109.20:50010, 132.72.109.41:50010 for /user/hadoop2/output/input_105_104-9-1/0/_temporary/1/_temporary/attempt_1546970280036_0001_r_000008_0/part-r-00008
2019-01-08 20:16:18,086 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741855_1031, replicas=132.72.109.20:50010, 132.72.109.41:50010 for /user/hadoop2/output/input_105_104-9-1/0/_temporary/1/_temporary/attempt_1546970280036_0001_r_000002_0/part-r-00002
2019-01-08 20:16:18,093 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741856_1032, replicas=132.72.109.20:50010, 132.72.109.41:50010 for /user/hadoop2/output/input_105_104-9-1/0/_temporary/1/_temporary/attempt_1546970280036_0001_r_000000_0/part-r-00000
2019-01-08 20:16:18,094 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741857_1033, replicas=132.72.109.20:50010, 132.72.109.41:50010 for /user/hadoop2/output/input_105_104-9-1/0/_temporary/1/_temporary/attempt_1546970280036_0001_r_000006_0/part-r-00006
2019-01-08 20:16:18,094 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741858_1034, replicas=132.72.109.20:50010, 132.72.109.41:50010 for /user/hadoop2/output/input_105_104-9-1/0/_temporary/1/_temporary/attempt_1546970280036_0001_r_000004_0/part-r-00004
2019-01-08 20:16:18,606 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/hadoop2/output/input_105_104-9-1/0/_temporary/1/_temporary/attempt_1546970280036_0001_r_000008_0/part-r-00008 is closed by DFSClient_attempt_1546970280036_0001_r_000008_0_-910445297_1
2019-01-08 20:16:18,619 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/hadoop2/output/input_105_104-9-1/0/_temporary/1/_temporary/attempt_1546970280036_0001_r_000004_0/part-r-00004 is closed by DFSClient_attempt_1546970280036_0001_r_000004_0_-741309519_1
2019-01-08 20:16:18,652 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/hadoop2/output/input_105_104-9-1/0/_temporary/1/_temporary/attempt_1546970280036_0001_r_000006_0/part-r-00006 is closed by DFSClient_attempt_1546970280036_0001_r_000006_0_1318988326_1
2019-01-08 20:16:18,676 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/hadoop2/output/input_105_104-9-1/0/_temporary/1/_temporary/attempt_1546970280036_0001_r_000000_0/part-r-00000 is closed by DFSClient_attempt_1546970280036_0001_r_000000_0_731636245_1
2019-01-08 20:16:18,698 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/hadoop2/output/input_105_104-9-1/0/_temporary/1/_temporary/attempt_1546970280036_0001_r_000002_0/part-r-00002 is closed by DFSClient_attempt_1546970280036_0001_r_000002_0_1187024945_1
2019-01-08 20:16:19,194 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/hadoop2/.staging/job_1546970280036_0001/COMMIT_STARTED is closed by DFSClient_NONMAPREDUCE_147205118_1
2019-01-08 20:16:19,494 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/hadoop2/output/input_105_104-9-1/0/_SUCCESS is closed by DFSClient_NONMAPREDUCE_147205118_1
2019-01-08 20:16:19,510 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/hadoop2/.staging/job_1546970280036_0001/COMMIT_SUCCESS is closed by DFSClient_NONMAPREDUCE_147205118_1
2019-01-08 20:16:19,543 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/hadoop2/.staging/job_1546970280036_0001/job_1546970280036_0001_1.jhist is closed by DFSClient_NONMAPREDUCE_147205118_1
2019-01-08 20:16:19,563 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741859_1035, replicas=132.72.109.41:50010, 132.72.109.20:50010 for /tmp/hadoop-yarn/staging/history/done_intermediate/hadoop2/job_1546970280036_0001.summary_tmp
2019-01-08 20:16:19,624 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/history/done_intermediate/hadoop2/job_1546970280036_0001.summary_tmp is closed by DFSClient_NONMAPREDUCE_147205118_1
2019-01-08 20:16:19,735 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741860_1036, replicas=132.72.109.41:50010, 132.72.109.20:50010 for /tmp/hadoop-yarn/staging/history/done_intermediate/hadoop2/job_1546970280036_0001-1546971306012-hadoop2-input_105_104%2D000-1546971395349-1-9-SUCCEEDED-default-1546971332087.jhist_tmp
2019-01-08 20:16:19,800 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/history/done_intermediate/hadoop2/job_1546970280036_0001-1546971306012-hadoop2-input_105_104%2D000-1546971395349-1-9-SUCCEEDED-default-1546971332087.jhist_tmp is closed by DFSClient_NONMAPREDUCE_147205118_1
2019-01-08 20:16:19,865 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741861_1037, replicas=132.72.109.41:50010, 132.72.109.20:50010 for /tmp/hadoop-yarn/staging/history/done_intermediate/hadoop2/job_1546970280036_0001_conf.xml_tmp
2019-01-08 20:16:19,909 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/history/done_intermediate/hadoop2/job_1546970280036_0001_conf.xml_tmp is closed by DFSClient_NONMAPREDUCE_147205118_1
2019-01-08 20:16:21,745 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741862_1038, replicas=132.72.109.20:50010, 132.72.109.41:50010 for /tmp/hadoop-yarn/staging/hadoop2/.staging/job_1546970280036_0002/job.jar
2019-01-08 20:16:26,108 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/hadoop2/.staging/job_1546970280036_0002/job.jar is closed by DFSClient_NONMAPREDUCE_-587237367_1
2019-01-08 20:16:26,132 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Increasing replication from 3 to 10 for /tmp/hadoop-yarn/staging/hadoop2/.staging/job_1546970280036_0002/job.jar
2019-01-08 20:16:26,173 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Increasing replication from 3 to 10 for /tmp/hadoop-yarn/staging/hadoop2/.staging/job_1546970280036_0002/job.split
2019-01-08 20:16:26,183 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741863_1039, replicas=132.72.109.20:50010, 132.72.109.41:50010 for /tmp/hadoop-yarn/staging/hadoop2/.staging/job_1546970280036_0002/job.split
2019-01-08 20:16:26,201 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/hadoop2/.staging/job_1546970280036_0002/job.split is closed by DFSClient_NONMAPREDUCE_-587237367_1
2019-01-08 20:16:26,224 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741864_1040, replicas=132.72.109.20:50010, 132.72.109.41:50010 for /tmp/hadoop-yarn/staging/hadoop2/.staging/job_1546970280036_0002/job.splitmetainfo
2019-01-08 20:16:26,243 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/hadoop2/.staging/job_1546970280036_0002/job.splitmetainfo is closed by DFSClient_NONMAPREDUCE_-587237367_1
2019-01-08 20:16:26,308 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741865_1041, replicas=132.72.109.20:50010, 132.72.109.41:50010 for /tmp/hadoop-yarn/staging/hadoop2/.staging/job_1546970280036_0002/job.xml
2019-01-08 20:16:26,365 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/hadoop2/.staging/job_1546970280036_0002/job.xml is closed by DFSClient_NONMAPREDUCE_-587237367_1
2019-01-08 20:16:27,338 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741866_1042, replicas=132.72.109.20:50010, 132.72.109.41:50010 for /app-logs/hadoop2/logs/application_1546970280036_0001/master_39349.tmp
2019-01-08 20:16:27,470 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /app-logs/hadoop2/logs/application_1546970280036_0001/master_39349.tmp is closed by DFSClient_NONMAPREDUCE_-2111530813_105
2019-01-08 20:16:27,767 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741867_1043, replicas=132.72.109.41:50010, 132.72.109.20:50010 for /app-logs/hadoop2/logs/application_1546970280036_0001/razoldslave2_40557.tmp
2019-01-08 20:16:27,859 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /app-logs/hadoop2/logs/application_1546970280036_0001/razoldslave2_40557.tmp is closed by DFSClient_NONMAPREDUCE_-840305954_91
2019-01-08 20:16:34,073 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741868_1044, replicas=132.72.109.41:50010, 132.72.109.20:50010 for /tmp/hadoop-yarn/staging/hadoop2/.staging/job_1546970280036_0002/job_1546970280036_0002_1_conf.xml
2019-01-08 20:16:34,162 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/hadoop2/.staging/job_1546970280036_0002/job_1546970280036_0002_1_conf.xml is closed by DFSClient_NONMAPREDUCE_-2092162080_1
2019-01-08 20:16:40,942 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741869_1045, replicas=132.72.109.41:50010, 132.72.109.20:50010 for /mappersLocations
2019-01-08 20:16:41,061 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /mappersLocations is closed by DFSClient_NONMAPREDUCE_-2092162080_1
2019-01-08 20:16:41,186 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741870_1046, replicas=132.72.109.41:50010, 132.72.109.20:50010 for /reducersLocations
2019-01-08 20:16:41,355 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /reducersLocations is closed by DFSClient_NONMAPREDUCE_-2092162080_1
2019-01-08 20:17:21,747 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741871_1047, replicas=132.72.109.41:50010, 132.72.109.20:50010 for /tmp/hadoop-yarn/staging/hadoop2/.staging/job_1546970280036_0002/job_1546970280036_0002_1.jhist
2019-01-08 20:17:21,748 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 308 Total time for transactions(ms): 40 Number of transactions batched in Syncs: 101 Number of syncs: 206 SyncTimes(ms): 4334 
2019-01-08 20:17:22,577 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741872_1048, replicas=132.72.109.41:50010, 132.72.109.20:50010 for /user/hadoop2/output/input_105_104-9-1/1/_temporary/1/_temporary/attempt_1546970280036_0002_r_000003_0/part-r-00003
2019-01-08 20:17:22,598 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* fsync: /tmp/hadoop-yarn/staging/hadoop2/.staging/job_1546970280036_0002/job_1546970280036_0002_1.jhist for DFSClient_NONMAPREDUCE_-2092162080_1
2019-01-08 20:17:23,160 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/hadoop2/output/input_105_104-9-1/1/_temporary/1/_temporary/attempt_1546970280036_0002_r_000003_0/part-r-00003 is closed by DFSClient_attempt_1546970280036_0002_r_000003_0_753323208_1
2019-01-08 20:17:23,287 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741873_1049, replicas=132.72.109.41:50010, 132.72.109.20:50010 for /user/hadoop2/output/input_105_104-9-1/1/_temporary/1/_temporary/attempt_1546970280036_0002_r_000001_0/part-r-00001
2019-01-08 20:17:23,438 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741874_1050, replicas=132.72.109.41:50010, 132.72.109.20:50010 for /user/hadoop2/output/input_105_104-9-1/1/_temporary/1/_temporary/attempt_1546970280036_0002_r_000005_0/part-r-00005
2019-01-08 20:17:23,597 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741875_1051, replicas=132.72.109.41:50010, 132.72.109.20:50010 for /user/hadoop2/output/input_105_104-9-1/1/_temporary/1/_temporary/attempt_1546970280036_0002_r_000007_0/part-r-00007
2019-01-08 20:17:23,743 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/hadoop2/output/input_105_104-9-1/1/_temporary/1/_temporary/attempt_1546970280036_0002_r_000001_0/part-r-00001 is closed by DFSClient_attempt_1546970280036_0002_r_000001_0_717226122_1
2019-01-08 20:17:24,023 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/hadoop2/output/input_105_104-9-1/1/_temporary/1/_temporary/attempt_1546970280036_0002_r_000005_0/part-r-00005 is closed by DFSClient_attempt_1546970280036_0002_r_000005_0_-1168082470_1
2019-01-08 20:17:24,061 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/hadoop2/output/input_105_104-9-1/1/_temporary/1/_temporary/attempt_1546970280036_0002_r_000007_0/part-r-00007 is closed by DFSClient_attempt_1546970280036_0002_r_000007_0_1336571071_1
2019-01-08 20:17:35,384 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741876_1052, replicas=132.72.109.20:50010, 132.72.109.41:50010 for /user/hadoop2/output/input_105_104-9-1/1/_temporary/1/_temporary/attempt_1546970280036_0002_r_000002_0/part-r-00002
2019-01-08 20:17:35,390 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741877_1053, replicas=132.72.109.20:50010, 132.72.109.41:50010 for /user/hadoop2/output/input_105_104-9-1/1/_temporary/1/_temporary/attempt_1546970280036_0002_r_000004_0/part-r-00004
2019-01-08 20:17:35,391 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741878_1054, replicas=132.72.109.20:50010, 132.72.109.41:50010 for /user/hadoop2/output/input_105_104-9-1/1/_temporary/1/_temporary/attempt_1546970280036_0002_r_000000_0/part-r-00000
2019-01-08 20:17:35,391 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741879_1055, replicas=132.72.109.20:50010, 132.72.109.41:50010 for /user/hadoop2/output/input_105_104-9-1/1/_temporary/1/_temporary/attempt_1546970280036_0002_r_000008_0/part-r-00008
2019-01-08 20:17:35,391 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741880_1056, replicas=132.72.109.20:50010, 132.72.109.41:50010 for /user/hadoop2/output/input_105_104-9-1/1/_temporary/1/_temporary/attempt_1546970280036_0002_r_000006_0/part-r-00006
2019-01-08 20:17:43,059 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/hadoop2/output/input_105_104-9-1/1/_temporary/1/_temporary/attempt_1546970280036_0002_r_000004_0/part-r-00004 is closed by DFSClient_attempt_1546970280036_0002_r_000004_0_1170459243_1
2019-01-08 20:17:43,065 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/hadoop2/output/input_105_104-9-1/1/_temporary/1/_temporary/attempt_1546970280036_0002_r_000006_0/part-r-00006 is closed by DFSClient_attempt_1546970280036_0002_r_000006_0_-1194146604_1
2019-01-08 20:17:43,066 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/hadoop2/output/input_105_104-9-1/1/_temporary/1/_temporary/attempt_1546970280036_0002_r_000008_0/part-r-00008 is closed by DFSClient_attempt_1546970280036_0002_r_000008_0_-779621613_1
2019-01-08 20:17:43,068 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/hadoop2/output/input_105_104-9-1/1/_temporary/1/_temporary/attempt_1546970280036_0002_r_000002_0/part-r-00002 is closed by DFSClient_attempt_1546970280036_0002_r_000002_0_523100913_1
2019-01-08 20:17:43,079 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/hadoop2/output/input_105_104-9-1/1/_temporary/1/_temporary/attempt_1546970280036_0002_r_000000_0/part-r-00000 is closed by DFSClient_attempt_1546970280036_0002_r_000000_0_-2026219016_1
2019-01-08 20:17:43,732 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/hadoop2/.staging/job_1546970280036_0002/COMMIT_STARTED is closed by DFSClient_NONMAPREDUCE_-2092162080_1
2019-01-08 20:17:44,808 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/hadoop2/output/input_105_104-9-1/1/_SUCCESS is closed by DFSClient_NONMAPREDUCE_-2092162080_1
2019-01-08 20:17:45,040 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/hadoop2/.staging/job_1546970280036_0002/COMMIT_SUCCESS is closed by DFSClient_NONMAPREDUCE_-2092162080_1
2019-01-08 20:17:45,118 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/hadoop2/.staging/job_1546970280036_0002/job_1546970280036_0002_1.jhist is closed by DFSClient_NONMAPREDUCE_-2092162080_1
2019-01-08 20:17:45,209 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741881_1057, replicas=132.72.109.41:50010, 132.72.109.20:50010 for /tmp/hadoop-yarn/staging/history/done_intermediate/hadoop2/job_1546970280036_0002.summary_tmp
2019-01-08 20:17:45,265 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/history/done_intermediate/hadoop2/job_1546970280036_0002.summary_tmp is closed by DFSClient_NONMAPREDUCE_-2092162080_1
2019-01-08 20:17:45,392 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741882_1058, replicas=132.72.109.41:50010, 132.72.109.20:50010 for /tmp/hadoop-yarn/staging/history/done_intermediate/hadoop2/job_1546970280036_0002-1546971386405-hadoop2-input_105_104%2D000-1546971480930-1-9-SUCCEEDED-default-1546971409569.jhist_tmp
2019-01-08 20:17:45,445 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/history/done_intermediate/hadoop2/job_1546970280036_0002-1546971386405-hadoop2-input_105_104%2D000-1546971480930-1-9-SUCCEEDED-default-1546971409569.jhist_tmp is closed by DFSClient_NONMAPREDUCE_-2092162080_1
2019-01-08 20:17:45,561 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741883_1059, replicas=132.72.109.41:50010, 132.72.109.20:50010 for /tmp/hadoop-yarn/staging/history/done_intermediate/hadoop2/job_1546970280036_0002_conf.xml_tmp
2019-01-08 20:17:45,673 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/history/done_intermediate/hadoop2/job_1546970280036_0002_conf.xml_tmp is closed by DFSClient_NONMAPREDUCE_-2092162080_1
2019-01-08 20:17:53,493 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741884_1060, replicas=132.72.109.41:50010, 132.72.109.20:50010 for /app-logs/hadoop2/logs/application_1546970280036_0002/razoldslave2_40557.tmp
2019-01-08 20:17:54,012 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /app-logs/hadoop2/logs/application_1546970280036_0002/razoldslave2_40557.tmp is closed by DFSClient_NONMAPREDUCE_-940707108_148
2019-01-08 20:17:54,053 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741885_1061, replicas=132.72.109.20:50010, 132.72.109.41:50010 for /app-logs/hadoop2/logs/application_1546970280036_0002/master_39349.tmp
2019-01-08 20:17:54,269 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /app-logs/hadoop2/logs/application_1546970280036_0002/master_39349.tmp is closed by DFSClient_NONMAPREDUCE_-147494400_172
2019-01-08 20:18:24,583 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 426 Total time for transactions(ms): 48 Number of transactions batched in Syncs: 153 Number of syncs: 273 SyncTimes(ms): 9735 
2019-01-08 21:01:31,488 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 437 Total time for transactions(ms): 146 Number of transactions batched in Syncs: 158 Number of syncs: 279 SyncTimes(ms): 10118 
2019-01-08 21:01:31,681 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741886_1062, replicas=132.72.109.20:50010, 132.72.109.41:50010 for /tmp/hadoop-yarn/staging/hadoop2/.staging/job_1546970280036_0003/job.jar
2019-01-08 21:01:36,034 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/hadoop2/.staging/job_1546970280036_0003/job.jar is closed by DFSClient_NONMAPREDUCE_1050584424_1
2019-01-08 21:01:36,176 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Increasing replication from 3 to 10 for /tmp/hadoop-yarn/staging/hadoop2/.staging/job_1546970280036_0003/job.jar
2019-01-08 21:01:36,735 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Increasing replication from 3 to 10 for /tmp/hadoop-yarn/staging/hadoop2/.staging/job_1546970280036_0003/job.split
2019-01-08 21:01:36,751 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741887_1063, replicas=132.72.109.20:50010, 132.72.109.41:50010 for /tmp/hadoop-yarn/staging/hadoop2/.staging/job_1546970280036_0003/job.split
2019-01-08 21:01:36,792 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/hadoop2/.staging/job_1546970280036_0003/job.split is closed by DFSClient_NONMAPREDUCE_1050584424_1
2019-01-08 21:01:36,823 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741888_1064, replicas=132.72.109.20:50010, 132.72.109.41:50010 for /tmp/hadoop-yarn/staging/hadoop2/.staging/job_1546970280036_0003/job.splitmetainfo
2019-01-08 21:01:36,850 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/hadoop2/.staging/job_1546970280036_0003/job.splitmetainfo is closed by DFSClient_NONMAPREDUCE_1050584424_1
2019-01-08 21:01:37,520 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741889_1065, replicas=132.72.109.20:50010, 132.72.109.41:50010 for /tmp/hadoop-yarn/staging/hadoop2/.staging/job_1546970280036_0003/job.xml
2019-01-08 21:01:37,574 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/hadoop2/.staging/job_1546970280036_0003/job.xml is closed by DFSClient_NONMAPREDUCE_1050584424_1
2019-01-08 21:01:45,064 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741890_1066, replicas=132.72.109.41:50010, 132.72.109.20:50010 for /tmp/hadoop-yarn/staging/hadoop2/.staging/job_1546970280036_0003/job_1546970280036_0003_1_conf.xml
2019-01-08 21:01:45,140 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/hadoop2/.staging/job_1546970280036_0003/job_1546970280036_0003_1_conf.xml is closed by DFSClient_NONMAPREDUCE_1302788802_1
2019-01-08 21:01:51,838 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741891_1067, replicas=132.72.109.41:50010, 132.72.109.20:50010 for /mappersLocations
2019-01-08 21:01:51,915 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /mappersLocations is closed by DFSClient_NONMAPREDUCE_1302788802_1
2019-01-08 21:01:51,949 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741892_1068, replicas=132.72.109.41:50010, 132.72.109.20:50010 for /reducersLocations
2019-01-08 21:01:51,994 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /reducersLocations is closed by DFSClient_NONMAPREDUCE_1302788802_1
2019-01-08 21:02:08,864 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741893_1069, replicas=132.72.109.41:50010, 132.72.109.20:50010 for /tmp/hadoop-yarn/staging/hadoop2/.staging/job_1546970280036_0003/job_1546970280036_0003_1.jhist
2019-01-08 21:02:08,968 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* fsync: /tmp/hadoop-yarn/staging/hadoop2/.staging/job_1546970280036_0003/job_1546970280036_0003_1.jhist for DFSClient_NONMAPREDUCE_1302788802_1
2019-01-08 21:02:10,665 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741894_1070, replicas=132.72.109.41:50010, 132.72.109.20:50010 for /user/hadoop2/output/input_105_104-9-2/0/_temporary/1/_temporary/attempt_1546970280036_0003_r_000002_0/part-r-00002
2019-01-08 21:02:11,116 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/hadoop2/output/input_105_104-9-2/0/_temporary/1/_temporary/attempt_1546970280036_0003_r_000002_0/part-r-00002 is closed by DFSClient_attempt_1546970280036_0003_r_000002_0_-1416815126_1
2019-01-08 21:02:11,133 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741895_1071, replicas=132.72.109.41:50010, 132.72.109.20:50010 for /user/hadoop2/output/input_105_104-9-2/0/_temporary/1/_temporary/attempt_1546970280036_0003_r_000004_0/part-r-00004
2019-01-08 21:02:11,208 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741896_1072, replicas=132.72.109.41:50010, 132.72.109.20:50010 for /user/hadoop2/output/input_105_104-9-2/0/_temporary/1/_temporary/attempt_1546970280036_0003_r_000006_0/part-r-00006
2019-01-08 21:02:11,322 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741897_1073, replicas=132.72.109.41:50010, 132.72.109.20:50010 for /user/hadoop2/output/input_105_104-9-2/0/_temporary/1/_temporary/attempt_1546970280036_0003_r_000008_0/part-r-00008
2019-01-08 21:02:11,746 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/hadoop2/output/input_105_104-9-2/0/_temporary/1/_temporary/attempt_1546970280036_0003_r_000004_0/part-r-00004 is closed by DFSClient_attempt_1546970280036_0003_r_000004_0_-1115698403_1
2019-01-08 21:02:11,874 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/hadoop2/output/input_105_104-9-2/0/_temporary/1/_temporary/attempt_1546970280036_0003_r_000006_0/part-r-00006 is closed by DFSClient_attempt_1546970280036_0003_r_000006_0_-529298767_1
2019-01-08 21:02:11,948 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/hadoop2/output/input_105_104-9-2/0/_temporary/1/_temporary/attempt_1546970280036_0003_r_000008_0/part-r-00008 is closed by DFSClient_attempt_1546970280036_0003_r_000008_0_1132863081_1
2019-01-08 21:02:11,966 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741898_1074, replicas=132.72.109.41:50010, 132.72.109.20:50010 for /user/hadoop2/output/input_105_104-9-2/0/_temporary/1/_temporary/attempt_1546970280036_0003_r_000000_0/part-r-00000
2019-01-08 21:02:12,515 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/hadoop2/output/input_105_104-9-2/0/_temporary/1/_temporary/attempt_1546970280036_0003_r_000000_0/part-r-00000 is closed by DFSClient_attempt_1546970280036_0003_r_000000_0_1635176432_1
2019-01-08 21:02:13,538 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741899_1075, replicas=132.72.109.20:50010, 132.72.109.41:50010 for /user/hadoop2/output/input_105_104-9-2/0/_temporary/1/_temporary/attempt_1546970280036_0003_r_000003_0/part-r-00003
2019-01-08 21:02:13,558 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741900_1076, replicas=132.72.109.20:50010, 132.72.109.41:50010 for /user/hadoop2/output/input_105_104-9-2/0/_temporary/1/_temporary/attempt_1546970280036_0003_r_000007_0/part-r-00007
2019-01-08 21:02:13,559 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741901_1077, replicas=132.72.109.20:50010, 132.72.109.41:50010 for /user/hadoop2/output/input_105_104-9-2/0/_temporary/1/_temporary/attempt_1546970280036_0003_r_000001_0/part-r-00001
2019-01-08 21:02:13,562 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741902_1078, replicas=132.72.109.20:50010, 132.72.109.41:50010 for /user/hadoop2/output/input_105_104-9-2/0/_temporary/1/_temporary/attempt_1546970280036_0003_r_000005_0/part-r-00005
2019-01-08 21:02:14,334 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/hadoop2/output/input_105_104-9-2/0/_temporary/1/_temporary/attempt_1546970280036_0003_r_000005_0/part-r-00005 is closed by DFSClient_attempt_1546970280036_0003_r_000005_0_1030702452_1
2019-01-08 21:02:14,340 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/hadoop2/output/input_105_104-9-2/0/_temporary/1/_temporary/attempt_1546970280036_0003_r_000007_0/part-r-00007 is closed by DFSClient_attempt_1546970280036_0003_r_000007_0_1096948872_1
2019-01-08 21:02:14,344 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/hadoop2/output/input_105_104-9-2/0/_temporary/1/_temporary/attempt_1546970280036_0003_r_000003_0/part-r-00003 is closed by DFSClient_attempt_1546970280036_0003_r_000003_0_1414071523_1
2019-01-08 21:02:14,366 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/hadoop2/output/input_105_104-9-2/0/_temporary/1/_temporary/attempt_1546970280036_0003_r_000001_0/part-r-00001 is closed by DFSClient_attempt_1546970280036_0003_r_000001_0_658085211_1
2019-01-08 21:02:14,884 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/hadoop2/.staging/job_1546970280036_0003/COMMIT_STARTED is closed by DFSClient_NONMAPREDUCE_1302788802_1
2019-01-08 21:02:15,336 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/hadoop2/output/input_105_104-9-2/0/_SUCCESS is closed by DFSClient_NONMAPREDUCE_1302788802_1
2019-01-08 21:02:15,470 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/hadoop2/.staging/job_1546970280036_0003/COMMIT_SUCCESS is closed by DFSClient_NONMAPREDUCE_1302788802_1
2019-01-08 21:02:15,535 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/hadoop2/.staging/job_1546970280036_0003/job_1546970280036_0003_1.jhist is closed by DFSClient_NONMAPREDUCE_1302788802_1
2019-01-08 21:02:15,589 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741903_1079, replicas=132.72.109.41:50010, 132.72.109.20:50010 for /tmp/hadoop-yarn/staging/history/done_intermediate/hadoop2/job_1546970280036_0003.summary_tmp
2019-01-08 21:02:15,686 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/history/done_intermediate/hadoop2/job_1546970280036_0003.summary_tmp is closed by DFSClient_NONMAPREDUCE_1302788802_1
2019-01-08 21:02:16,176 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741904_1080, replicas=132.72.109.41:50010, 132.72.109.20:50010 for /tmp/hadoop-yarn/staging/history/done_intermediate/hadoop2/job_1546970280036_0003-1546974097937-hadoop2-input_105_104%2D000-1546974151379-1-9-SUCCEEDED-default-1546974120535.jhist_tmp
2019-01-08 21:02:16,302 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/history/done_intermediate/hadoop2/job_1546970280036_0003-1546974097937-hadoop2-input_105_104%2D000-1546974151379-1-9-SUCCEEDED-default-1546974120535.jhist_tmp is closed by DFSClient_NONMAPREDUCE_1302788802_1
2019-01-08 21:02:16,383 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741905_1081, replicas=132.72.109.41:50010, 132.72.109.20:50010 for /tmp/hadoop-yarn/staging/history/done_intermediate/hadoop2/job_1546970280036_0003_conf.xml_tmp
2019-01-08 21:02:16,442 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/history/done_intermediate/hadoop2/job_1546970280036_0003_conf.xml_tmp is closed by DFSClient_NONMAPREDUCE_1302788802_1
2019-01-08 21:02:19,219 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741906_1082, replicas=132.72.109.20:50010, 132.72.109.41:50010 for /tmp/hadoop-yarn/staging/hadoop2/.staging/job_1546970280036_0004/job.jar
2019-01-08 21:02:23,463 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/hadoop2/.staging/job_1546970280036_0004/job.jar is closed by DFSClient_NONMAPREDUCE_1050584424_1
2019-01-08 21:02:23,474 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Increasing replication from 3 to 10 for /tmp/hadoop-yarn/staging/hadoop2/.staging/job_1546970280036_0004/job.jar
2019-01-08 21:02:23,507 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Increasing replication from 3 to 10 for /tmp/hadoop-yarn/staging/hadoop2/.staging/job_1546970280036_0004/job.split
2019-01-08 21:02:23,524 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741907_1083, replicas=132.72.109.20:50010, 132.72.109.41:50010 for /tmp/hadoop-yarn/staging/hadoop2/.staging/job_1546970280036_0004/job.split
2019-01-08 21:02:23,554 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/hadoop2/.staging/job_1546970280036_0004/job.split is closed by DFSClient_NONMAPREDUCE_1050584424_1
2019-01-08 21:02:23,582 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741908_1084, replicas=132.72.109.20:50010, 132.72.109.41:50010 for /tmp/hadoop-yarn/staging/hadoop2/.staging/job_1546970280036_0004/job.splitmetainfo
2019-01-08 21:02:23,605 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/hadoop2/.staging/job_1546970280036_0004/job.splitmetainfo is closed by DFSClient_NONMAPREDUCE_1050584424_1
2019-01-08 21:02:23,823 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741909_1085, replicas=132.72.109.20:50010, 132.72.109.41:50010 for /app-logs/hadoop2/logs/application_1546970280036_0003/master_39349.tmp
2019-01-08 21:02:23,904 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /app-logs/hadoop2/logs/application_1546970280036_0003/master_39349.tmp is closed by DFSClient_NONMAPREDUCE_-1518398220_224
2019-01-08 21:02:23,914 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741910_1086, replicas=132.72.109.20:50010, 132.72.109.41:50010 for /tmp/hadoop-yarn/staging/hadoop2/.staging/job_1546970280036_0004/job.xml
2019-01-08 21:02:23,968 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/hadoop2/.staging/job_1546970280036_0004/job.xml is closed by DFSClient_NONMAPREDUCE_1050584424_1
2019-01-08 21:02:24,271 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741911_1087, replicas=132.72.109.41:50010, 132.72.109.20:50010 for /app-logs/hadoop2/logs/application_1546970280036_0003/razoldslave2_40557.tmp
2019-01-08 21:02:24,338 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /app-logs/hadoop2/logs/application_1546970280036_0003/razoldslave2_40557.tmp is closed by DFSClient_NONMAPREDUCE_-1918018566_200
2019-01-08 21:02:31,532 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741912_1088, replicas=132.72.109.41:50010, 132.72.109.20:50010 for /tmp/hadoop-yarn/staging/hadoop2/.staging/job_1546970280036_0004/job_1546970280036_0004_1_conf.xml
2019-01-08 21:02:31,533 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 643 Total time for transactions(ms): 161 Number of transactions batched in Syncs: 223 Number of syncs: 418 SyncTimes(ms): 14195 
2019-01-08 21:02:31,620 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/hadoop2/.staging/job_1546970280036_0004/job_1546970280036_0004_1_conf.xml is closed by DFSClient_NONMAPREDUCE_-1818472075_1
2019-01-08 21:02:37,364 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741913_1089, replicas=132.72.109.41:50010, 132.72.109.20:50010 for /mappersLocations
2019-01-08 21:02:37,501 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /mappersLocations is closed by DFSClient_NONMAPREDUCE_-1818472075_1
2019-01-08 21:02:37,614 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741914_1090, replicas=132.72.109.41:50010, 132.72.109.20:50010 for /reducersLocations
2019-01-08 21:02:37,687 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /reducersLocations is closed by DFSClient_NONMAPREDUCE_-1818472075_1
2019-01-08 21:02:54,559 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741915_1091, replicas=132.72.109.41:50010, 132.72.109.20:50010 for /tmp/hadoop-yarn/staging/hadoop2/.staging/job_1546970280036_0004/job_1546970280036_0004_1.jhist
2019-01-08 21:02:54,720 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* fsync: /tmp/hadoop-yarn/staging/hadoop2/.staging/job_1546970280036_0004/job_1546970280036_0004_1.jhist for DFSClient_NONMAPREDUCE_-1818472075_1
2019-01-08 21:02:56,616 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741916_1092, replicas=132.72.109.41:50010, 132.72.109.20:50010 for /user/hadoop2/output/input_105_104-9-2/1/_temporary/1/_temporary/attempt_1546970280036_0004_r_000004_0/part-r-00004
2019-01-08 21:02:56,643 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741917_1093, replicas=132.72.109.41:50010, 132.72.109.20:50010 for /user/hadoop2/output/input_105_104-9-2/1/_temporary/1/_temporary/attempt_1546970280036_0004_r_000000_0/part-r-00000
2019-01-08 21:02:57,112 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741918_1094, replicas=132.72.109.41:50010, 132.72.109.20:50010 for /user/hadoop2/output/input_105_104-9-2/1/_temporary/1/_temporary/attempt_1546970280036_0004_r_000006_0/part-r-00006
2019-01-08 21:02:57,159 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/hadoop2/output/input_105_104-9-2/1/_temporary/1/_temporary/attempt_1546970280036_0004_r_000004_0/part-r-00004 is closed by DFSClient_attempt_1546970280036_0004_r_000004_0_-217882537_1
2019-01-08 21:02:57,254 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/hadoop2/output/input_105_104-9-2/1/_temporary/1/_temporary/attempt_1546970280036_0004_r_000000_0/part-r-00000 is closed by DFSClient_attempt_1546970280036_0004_r_000000_0_-1931187121_1
2019-01-08 21:02:57,337 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741919_1095, replicas=132.72.109.20:50010, 132.72.109.41:50010 for /user/hadoop2/output/input_105_104-9-2/1/_temporary/1/_temporary/attempt_1546970280036_0004_r_000005_0/part-r-00005
2019-01-08 21:02:57,386 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741920_1096, replicas=132.72.109.41:50010, 132.72.109.20:50010 for /user/hadoop2/output/input_105_104-9-2/1/_temporary/1/_temporary/attempt_1546970280036_0004_r_000002_0/part-r-00002
2019-01-08 21:02:57,587 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741921_1097, replicas=132.72.109.20:50010, 132.72.109.41:50010 for /user/hadoop2/output/input_105_104-9-2/1/_temporary/1/_temporary/attempt_1546970280036_0004_r_000001_0/part-r-00001
2019-01-08 21:02:57,674 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741922_1098, replicas=132.72.109.20:50010, 132.72.109.41:50010 for /user/hadoop2/output/input_105_104-9-2/1/_temporary/1/_temporary/attempt_1546970280036_0004_r_000007_0/part-r-00007
2019-01-08 21:02:57,758 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741923_1099, replicas=132.72.109.20:50010, 132.72.109.41:50010 for /user/hadoop2/output/input_105_104-9-2/1/_temporary/1/_temporary/attempt_1546970280036_0004_r_000003_0/part-r-00003
2019-01-08 21:02:57,809 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/hadoop2/output/input_105_104-9-2/1/_temporary/1/_temporary/attempt_1546970280036_0004_r_000006_0/part-r-00006 is closed by DFSClient_attempt_1546970280036_0004_r_000006_0_-621589973_1
2019-01-08 21:02:57,834 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/hadoop2/output/input_105_104-9-2/1/_temporary/1/_temporary/attempt_1546970280036_0004_r_000005_0/part-r-00005 is closed by DFSClient_attempt_1546970280036_0004_r_000005_0_835518937_1
2019-01-08 21:02:57,873 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/hadoop2/output/input_105_104-9-2/1/_temporary/1/_temporary/attempt_1546970280036_0004_r_000002_0/part-r-00002 is closed by DFSClient_attempt_1546970280036_0004_r_000002_0_-1541001874_1
2019-01-08 21:02:58,077 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/hadoop2/output/input_105_104-9-2/1/_temporary/1/_temporary/attempt_1546970280036_0004_r_000001_0/part-r-00001 is closed by DFSClient_attempt_1546970280036_0004_r_000001_0_-640980836_1
2019-01-08 21:02:58,134 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/hadoop2/output/input_105_104-9-2/1/_temporary/1/_temporary/attempt_1546970280036_0004_r_000007_0/part-r-00007 is closed by DFSClient_attempt_1546970280036_0004_r_000007_0_1737433741_1
2019-01-08 21:02:58,229 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/hadoop2/output/input_105_104-9-2/1/_temporary/1/_temporary/attempt_1546970280036_0004_r_000003_0/part-r-00003 is closed by DFSClient_attempt_1546970280036_0004_r_000003_0_2100765111_1
2019-01-08 21:02:58,394 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741924_1100, replicas=132.72.109.41:50010, 132.72.109.20:50010 for /user/hadoop2/output/input_105_104-9-2/1/_temporary/1/_temporary/attempt_1546970280036_0004_r_000008_0/part-r-00008
2019-01-08 21:02:58,602 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/hadoop2/output/input_105_104-9-2/1/_temporary/1/_temporary/attempt_1546970280036_0004_r_000008_0/part-r-00008 is closed by DFSClient_attempt_1546970280036_0004_r_000008_0_359820999_1
2019-01-08 21:02:58,809 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/hadoop2/.staging/job_1546970280036_0004/COMMIT_STARTED is closed by DFSClient_NONMAPREDUCE_-1818472075_1
2019-01-08 21:02:59,018 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/hadoop2/output/input_105_104-9-2/1/_SUCCESS is closed by DFSClient_NONMAPREDUCE_-1818472075_1
2019-01-08 21:02:59,034 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/hadoop2/.staging/job_1546970280036_0004/COMMIT_SUCCESS is closed by DFSClient_NONMAPREDUCE_-1818472075_1
2019-01-08 21:02:59,080 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/hadoop2/.staging/job_1546970280036_0004/job_1546970280036_0004_1.jhist is closed by DFSClient_NONMAPREDUCE_-1818472075_1
2019-01-08 21:02:59,096 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741925_1101, replicas=132.72.109.41:50010, 132.72.109.20:50010 for /tmp/hadoop-yarn/staging/history/done_intermediate/hadoop2/job_1546970280036_0004.summary_tmp
2019-01-08 21:02:59,128 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/history/done_intermediate/hadoop2/job_1546970280036_0004.summary_tmp is closed by DFSClient_NONMAPREDUCE_-1818472075_1
2019-01-08 21:02:59,180 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741926_1102, replicas=132.72.109.41:50010, 132.72.109.20:50010 for /tmp/hadoop-yarn/staging/history/done_intermediate/hadoop2/job_1546970280036_0004-1546974144011-hadoop2-input_105_104%2D000-1546974194910-1-9-SUCCEEDED-default-1546974167008.jhist_tmp
2019-01-08 21:02:59,212 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/history/done_intermediate/hadoop2/job_1546970280036_0004-1546974144011-hadoop2-input_105_104%2D000-1546974194910-1-9-SUCCEEDED-default-1546974167008.jhist_tmp is closed by DFSClient_NONMAPREDUCE_-1818472075_1
2019-01-08 21:02:59,256 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741927_1103, replicas=132.72.109.41:50010, 132.72.109.20:50010 for /tmp/hadoop-yarn/staging/history/done_intermediate/hadoop2/job_1546970280036_0004_conf.xml_tmp
2019-01-08 21:02:59,297 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /tmp/hadoop-yarn/staging/history/done_intermediate/hadoop2/job_1546970280036_0004_conf.xml_tmp is closed by DFSClient_NONMAPREDUCE_-1818472075_1
2019-01-08 21:03:06,215 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741928_1104, replicas=132.72.109.20:50010, 132.72.109.41:50010 for /app-logs/hadoop2/logs/application_1546970280036_0004/master_39349.tmp
2019-01-08 21:03:06,275 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /app-logs/hadoop2/logs/application_1546970280036_0004/master_39349.tmp is closed by DFSClient_NONMAPREDUCE_1707087021_267
2019-01-08 21:03:07,073 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741929_1105, replicas=132.72.109.41:50010, 132.72.109.20:50010 for /app-logs/hadoop2/logs/application_1546970280036_0004/razoldslave2_40557.tmp
2019-01-08 21:03:07,256 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /app-logs/hadoop2/logs/application_1546970280036_0004/razoldslave2_40557.tmp is closed by DFSClient_NONMAPREDUCE_-1598481545_273
2019-01-08 21:05:54,257 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 132.72.109.20
2019-01-08 21:05:54,257 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2019-01-08 21:05:54,257 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 3, 781
2019-01-08 21:05:54,257 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 780 Total time for transactions(ms): 166 Number of transactions batched in Syncs: 262 Number of syncs: 518 SyncTimes(ms): 16027 
2019-01-08 21:05:54,272 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 780 Total time for transactions(ms): 166 Number of transactions batched in Syncs: 262 Number of syncs: 519 SyncTimes(ms): 16041 
2019-01-08 21:05:54,278 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /usr/local/hadoop/data/hadoop-data/nn/current/edits_inprogress_0000000000000000003 -> /usr/local/hadoop/data/hadoop-data/nn/current/edits_0000000000000000003-0000000000000000782
2019-01-08 21:05:54,279 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 783
2019-01-08 21:05:54,456 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Sending fileName: /usr/local/hadoop/data/hadoop-data/nn/current/edits_0000000000000000003-0000000000000000782, fileSize: 107934. Sent total: 107934 bytes. Size of last segment intended to send: -1 bytes.
2019-01-08 21:05:55,081 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Combined time for fsimage download and fsync to all disks took 0.00s. The fsimage download took 0.00s at 7000.00 KB/s. Synchronous (fsync) write to disk of /usr/local/hadoop/data/hadoop-data/nn/current/fsimage.ckpt_0000000000000000782 took 0.00s.
2019-01-08 21:05:55,081 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000000782 size 7616 bytes.
2019-01-08 21:05:55,132 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 2
2019-01-08 21:05:55,133 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/usr/local/hadoop/data/hadoop-data/nn/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2019-01-08 22:06:02,437 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 132.72.109.20
2019-01-08 22:06:02,691 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2019-01-08 22:06:02,691 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 783, 783
2019-01-08 22:06:02,746 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 55 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 72 
2019-01-08 22:06:03,068 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 55 Number of transactions batched in Syncs: 0 Number of syncs: 3 SyncTimes(ms): 394 
2019-01-08 22:06:03,104 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /usr/local/hadoop/data/hadoop-data/nn/current/edits_inprogress_0000000000000000783 -> /usr/local/hadoop/data/hadoop-data/nn/current/edits_0000000000000000783-0000000000000000784
2019-01-08 22:06:03,156 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 785
2019-01-08 22:06:06,283 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Sending fileName: /usr/local/hadoop/data/hadoop-data/nn/current/edits_0000000000000000783-0000000000000000784, fileSize: 42. Sent total: 42 bytes. Size of last segment intended to send: -1 bytes.
2019-01-08 22:06:07,653 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Combined time for fsimage download and fsync to all disks took 0.00s. The fsimage download took 0.00s at 7000.00 KB/s. Synchronous (fsync) write to disk of /usr/local/hadoop/data/hadoop-data/nn/current/fsimage.ckpt_0000000000000000784 took 0.00s.
2019-01-08 22:06:07,653 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000000784 size 7616 bytes.
2019-01-08 22:06:07,787 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 782
2019-01-08 22:06:07,787 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/usr/local/hadoop/data/hadoop-data/nn/current/fsimage_0000000000000000002, cpktTxId=0000000000000000002)
2019-01-08 23:00:27,229 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1150ms
No GCs detected
2019-01-08 23:06:42,189 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 132.72.109.20
2019-01-08 23:06:42,211 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2019-01-08 23:06:42,212 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 785, 785
2019-01-08 23:06:42,225 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 13 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 325 
2019-01-08 23:06:42,321 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 13 Number of transactions batched in Syncs: 0 Number of syncs: 3 SyncTimes(ms): 421 
2019-01-08 23:06:42,326 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /usr/local/hadoop/data/hadoop-data/nn/current/edits_inprogress_0000000000000000785 -> /usr/local/hadoop/data/hadoop-data/nn/current/edits_0000000000000000785-0000000000000000786
2019-01-08 23:06:42,368 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 787
2019-01-08 23:06:43,709 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Sending fileName: /usr/local/hadoop/data/hadoop-data/nn/current/edits_0000000000000000785-0000000000000000786, fileSize: 42. Sent total: 42 bytes. Size of last segment intended to send: -1 bytes.
2019-01-08 23:06:47,864 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Combined time for fsimage download and fsync to all disks took 0.00s. The fsimage download took 0.00s at 7000.00 KB/s. Synchronous (fsync) write to disk of /usr/local/hadoop/data/hadoop-data/nn/current/fsimage.ckpt_0000000000000000786 took 0.00s.
2019-01-08 23:06:47,864 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000000786 size 7616 bytes.
2019-01-08 23:06:47,937 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 784
2019-01-08 23:06:47,938 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/usr/local/hadoop/data/hadoop-data/nn/current/fsimage_0000000000000000782, cpktTxId=0000000000000000782)
2019-01-08 23:21:46,886 ERROR org.apache.hadoop.hdfs.server.namenode.NameNode: RECEIVED SIGNAL 15: SIGTERM
2019-01-08 23:21:46,931 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down NameNode at master/132.72.109.20
************************************************************/
